# pages/29_å„æ™‚æ®µä½œæ¥­æ•ˆç‡.py
# -*- coding: utf-8 -*-
import io
import os
from io import StringIO
from datetime import datetime, date
from zoneinfo import ZoneInfo

import numpy as np
import pandas as pd
import streamlit as st
import altair as alt
from openpyxl import load_workbook
from openpyxl.styles import PatternFill, Alignment

# ---- å¥—ç”¨å¹³å°é¢¨æ ¼ï¼ˆæœ‰å°±ç”¨ï¼Œæ²’æœ‰å°±é€€å›åŸç”Ÿï¼‰----
try:
    from common_ui import inject_logistics_theme, set_page, card_open, card_close
    HAS_COMMON_UI = True
except Exception:
    HAS_COMMON_UI = False

TPE = ZoneInfo("Asia/Taipei")

STATUS_PASS = "é”æ¨™"
STATUS_FAIL = "æœªé”æ¨™"
STATUS_NA = "æœªåˆ¤æ–·"

# âœ… ç‰¹æ®Šå·¥æ™‚ï¼ˆåˆ†é˜ï¼‰ï¼š12é»ã€13é»åªæœ‰ 30 åˆ†é˜
WORK_MINUTES_BY_HOUR = {12: 30, 13: 30}


# =============================
# è®€æª”ï¼šCSV/Excel å¼·éŸŒè®€å–
# =============================
def read_table_robust(file_name: str, raw: bytes, label: str = "æª”æ¡ˆ") -> pd.DataFrame:
    ext = os.path.splitext(file_name)[1].lower()

    if ext in (".xlsx", ".xlsm", ".xltx", ".xltm", ".xls"):
        try:
            return pd.read_excel(io.BytesIO(raw))
        except Exception as e:
            raise ValueError(f"{label} è®€å– Excel å¤±æ•—ï¼š{e}")

    encodings = ["utf-8-sig", "utf-8", "cp950", "big5", "ms950", "gb18030", "latin1"]
    seps = [",", "\t", ";", "|"]

    last_err = None
    for enc in encodings:
        for sep in seps:
            try:
                df = pd.read_csv(io.BytesIO(raw), encoding=enc, sep=sep, engine="python", low_memory=False)
                if df.shape[1] <= 1:
                    continue
                return df
            except Exception as e:
                last_err = e

    try:
        text = raw.decode("utf-8", errors="replace")
        df = pd.read_csv(StringIO(text), sep=None, engine="python", low_memory=False)
        if df.shape[1] <= 1:
            raise ValueError("åµæ¸¬ä¸åˆ°æœ‰æ•ˆåˆ†éš”ç¬¦ï¼Œè«‹ç¢ºèªæª”æ¡ˆæ˜¯å¦ç‚ºçœŸæ­£ CSVã€‚")
        return df
    except Exception as e:
        raise ValueError(f"{label} è®€å– CSV å¤±æ•—ï¼ˆå·²å˜—è©¦å¤šç¨®ç·¨ç¢¼/åˆ†éš”ç¬¦ï¼‰ï¼š{last_err} / æœ€çµ‚ï¼š{e}")


def require_columns(df: pd.DataFrame, required: list, label: str):
    missing = [c for c in required if c not in df.columns]
    if missing:
        raise ValueError(f"{label} ç¼ºå°‘æ¬„ä½ï¼š{missing}\nç›®å‰æ¬„ä½ï¼š{list(df.columns)}")


def _norm_cols(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    return df


def clean_line(series: pd.Series) -> pd.Series:
    return series.astype(str).str.strip()


def clean_zone_1to4(series: pd.Series) -> pd.Series:
    z = pd.to_numeric(series, errors="coerce").astype("Int64")
    return z.where(z.between(1, 4, inclusive="both"))


def _safe_time(s: str) -> str:
    s = str(s).strip()
    if not s:
        return "08:00"
    try:
        datetime.strptime(s, "%H:%M")
        return s
    except Exception:
        return "08:00"


def _bytes_sig(b: bytes) -> str:
    if b is None:
        return "0"
    n = len(b)
    head = b[:128]
    tail = b[-128:] if n >= 128 else b
    return f"{n}-{hash(head)}-{hash(tail)}"


def _slot_minutes(hour: int) -> int:
    return int(WORK_MINUTES_BY_HOUR.get(int(hour), 60))


# =============================
# KPI è¨ˆæ•¸ï¼ˆæŸå°æ™‚ï¼‰
# =============================
def _kpi_counts(dist_df: pd.DataFrame):
    if dist_df is None or dist_df.empty:
        return 0, 0, None
    p = int(dist_df.loc[dist_df["ç‹€æ…‹"] == STATUS_PASS, "count"].sum())
    f = int(dist_df.loc[dist_df["ç‹€æ…‹"] == STATUS_FAIL, "count"].sum())
    rate = (p / (p + f) * 100.0) if (p + f) > 0 else None
    return p, f, rate


# =============================
# âœ… Heatmapï¼šX=æ¯å°æ™‚ï¼Œæ ¼å…§=é‡é«”ï¼Œè‰²=é”æ¨™/æœªé”æ¨™/æœªåˆ¤æ–·
# =============================
def render_hourly_heatmap(df_line_hourly: pd.DataFrame, hour_cols, title: str):
    if df_line_hourly is None or df_line_hourly.empty:
        st.info("æ²’æœ‰å¯å‘ˆç¾çš„åœ–ã€‚")
        return

    hour_cols = [int(h) for h in list(hour_cols)]

    plot = df_line_hourly.copy()
    plot["æ®µæ•¸"] = pd.to_numeric(plot["æ®µæ•¸"], errors="coerce").fillna(0).astype(int)
    plot["å°æ™‚"] = pd.to_numeric(plot["å°æ™‚"], errors="coerce").fillna(0).astype(int)
    plot["ç•¶å°æ™‚åŠ æ¬ŠPCS"] = pd.to_numeric(plot["ç•¶å°æ™‚åŠ æ¬ŠPCS"], errors="coerce").fillna(0.0)
    plot["æœ¬å°æ™‚ç›®æ¨™"] = pd.to_numeric(plot["æœ¬å°æ™‚ç›®æ¨™"], errors="coerce").fillna(0.0)

    plot["label"] = plot["æ®µæ•¸"].astype(str) + "æ®µï½œ" + plot["å§“å"].astype(str)
    plot["ç‹€æ…‹_è‰²"] = plot["ç‹€æ…‹"].fillna(STATUS_NA)
    plot["é¡¯ç¤ºé‡"] = plot["ç•¶å°æ™‚åŠ æ¬ŠPCS"].apply(lambda x: "" if abs(float(x)) < 1e-12 else f"{float(x):.2f}")

    order = (
        plot[["label", "æ®µæ•¸", "å§“å"]]
        .drop_duplicates()
        .sort_values(["æ®µæ•¸", "å§“å"])["label"]
        .tolist()
    )

    color_enc = alt.Color(
        "ç‹€æ…‹_è‰²:N",
        scale=alt.Scale(domain=[STATUS_PASS, STATUS_FAIL, STATUS_NA], range=["#2E7D32", "#C62828", "#D0D5DD"]),
        legend=alt.Legend(title="ç‹€æ…‹"),
    )

    base = alt.Chart(plot).encode(
        x=alt.X("å°æ™‚:O", sort=[str(h) for h in hour_cols], title="æ¯å°æ™‚"),
        y=alt.Y("label:N", sort=order, title="æ®µæ•¸ï½œå§“å"),
        tooltip=[
            alt.Tooltip("label:N", title="æ®µæ•¸ï½œå§“å"),
            alt.Tooltip("å°æ™‚:O", title="å°æ™‚"),
            alt.Tooltip("ç•¶å°æ™‚åŠ æ¬ŠPCS:Q", title="ç•¶å°æ™‚åŠ æ¬ŠPCS", format=",.4f"),
            alt.Tooltip("æœ¬å°æ™‚ç›®æ¨™:Q", title="æœ¬å°æ™‚ç›®æ¨™", format=",.2f"),
            alt.Tooltip("ç‹€æ…‹:N", title="ç‹€æ…‹"),
        ],
    )

    rect = base.mark_rect(cornerRadius=4).encode(color=color_enc)
    text = base.mark_text(fontSize=12, fontWeight=900).encode(text="é¡¯ç¤ºé‡:N")

    n_rows = max(1, plot["label"].nunique())
    height = min(42 * n_rows + 80, 900)
    st.altair_chart((rect + text).properties(title=title, height=height), use_container_width=True)


# =============================
# âœ… è¡¨æ ¼ï¼ˆæ¯æ ¼=é‡é«”ï¼›è‰²=é”æ¨™/æœªé”æ¨™/æœªåˆ¤æ–·ï¼‰+ âœ… åŠ ç¸½ï¼ˆä¹Ÿä¸Šè‰²ï¼‰
# =============================
def render_grid_table_with_total(df_line: pd.DataFrame, hour_cols, title: str):
    if df_line is None or df_line.empty:
        st.info("æ­¤ç·šåˆ¥æ²’æœ‰è³‡æ–™å¯å‘ˆç¾ã€‚")
        return

    hour_cols = [int(h) for h in list(hour_cols)]

    base = df_line[["æ®µæ•¸", "å§“å", "å°æ™‚", "ç•¶å°æ™‚åŠ æ¬ŠPCS", "æœ¬å°æ™‚ç›®æ¨™", "ç‹€æ…‹"]].copy()
    base["æ®µæ•¸"] = pd.to_numeric(base["æ®µæ•¸"], errors="coerce").fillna(0).astype(int)
    base["å°æ™‚"] = pd.to_numeric(base["å°æ™‚"], errors="coerce").fillna(0).astype(int)
    base["ç•¶å°æ™‚åŠ æ¬ŠPCS"] = pd.to_numeric(base["ç•¶å°æ™‚åŠ æ¬ŠPCS"], errors="coerce").fillna(0.0)
    base["æœ¬å°æ™‚ç›®æ¨™"] = pd.to_numeric(base["æœ¬å°æ™‚ç›®æ¨™"], errors="coerce").fillna(0.0)

    vol = base.pivot_table(index=["æ®µæ•¸", "å§“å"], columns="å°æ™‚", values="ç•¶å°æ™‚åŠ æ¬ŠPCS", aggfunc="first")
    tar = base.pivot_table(index=["æ®µæ•¸", "å§“å"], columns="å°æ™‚", values="æœ¬å°æ™‚ç›®æ¨™", aggfunc="first")
    stat = base.pivot_table(index=["æ®µæ•¸", "å§“å"], columns="å°æ™‚", values="ç‹€æ…‹", aggfunc="first")

    for h in hour_cols:
        if h not in vol.columns:
            vol[h] = 0.0
        if h not in tar.columns:
            tar[h] = 0.0
        if h not in stat.columns:
            stat[h] = None

    vol = vol[hour_cols]
    tar = tar[hour_cols]
    stat = stat[hour_cols]

    total_pcs = vol.sum(axis=1)
    total_tar = tar.sum(axis=1)
    total_stat = np.where(total_tar <= 0, None, np.where(total_pcs >= total_tar, STATUS_PASS, STATUS_FAIL))

    vol2 = vol.reset_index().copy()
    stat2 = stat.reset_index().copy()

    show = vol2.copy()
    for h in hour_cols:
        show[h] = show[h].apply(lambda x: "" if abs(float(x)) < 1e-12 else f"{float(x):.2f}")

    # âœ… æ¬„åç”¨ã€ŒåŠ ç¸½ã€ï¼ˆè·Ÿä½ æˆªåœ–ä¸€è‡´ï¼‰
    show["åŠ ç¸½"] = total_pcs.values
    show["åŠ ç¸½"] = show["åŠ ç¸½"].apply(lambda x: "" if abs(float(x)) < 1e-12 else f"{float(x):.4f}")
    total_stat_list = list(total_stat)

    def _style(_df: pd.DataFrame):
        styles = pd.DataFrame("", index=_df.index, columns=_df.columns)
        if "æ®µæ•¸" in styles.columns:
            styles["æ®µæ•¸"] = "text-align:center;font-weight:800;"
        if "å§“å" in styles.columns:
            styles["å§“å"] = "text-align:left;font-weight:800;"

        for h in hour_cols:
            if h not in styles.columns:
                continue
            for i in range(len(_df)):
                s = None
                try:
                    s = stat2.at[i, h]
                except Exception:
                    s = None
                if s == STATUS_PASS:
                    styles.at[i, h] = "background-color:#C6EFCE;color:#1b4332;font-weight:900;text-align:center;"
                elif s == STATUS_FAIL:
                    styles.at[i, h] = "background-color:#FFC7CE;color:#7a0019;font-weight:900;text-align:center;"
                else:
                    styles.at[i, h] = "background-color:#F2F4F7;color:#667085;text-align:center;"

        # âœ… åŠ ç¸½ä¸Šè‰²
        if "åŠ ç¸½" in styles.columns:
            for i in range(len(_df)):
                s = total_stat_list[i] if i < len(total_stat_list) else None
                if s == STATUS_PASS:
                    styles.at[i, "åŠ ç¸½"] = "background-color:#C6EFCE;color:#1b4332;font-weight:950;text-align:center;"
                elif s == STATUS_FAIL:
                    styles.at[i, "åŠ ç¸½"] = "background-color:#FFC7CE;color:#7a0019;font-weight:950;text-align:center;"
                else:
                    styles.at[i, "åŠ ç¸½"] = "background-color:#F2F4F7;color:#667085;font-weight:900;text-align:center;"

        return styles

    st.markdown(f"#### {title}")
    st.dataframe(show.style.apply(_style, axis=None), use_container_width=True, hide_index=True)


# =============================
# Excelï¼šè¼¸å‡ºã€Œæ¯å°æ™‚PCSã€+ã€ŒåŠ ç¸½ã€ï¼Œé¡è‰²çš†å¥—ç”¨é”æ¨™/æœªé”æ¨™
# =============================
def build_excel_bytes_volume(matrix_vol: pd.DataFrame, matrix_stat: pd.DataFrame, hour_cols: list[int]) -> bytes:
    out_df = matrix_vol.copy()

    bio = io.BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        out_df.to_excel(writer, index=False, sheet_name="æ™‚æ®µé‡é«”_é”æ¨™è‰²å¡Š")
    bio.seek(0)

    wb = load_workbook(bio)
    ws = wb.active

    fill_ok = PatternFill(start_color="C6EFCE", end_color="C6EFCE", fill_type="solid")
    fill_ng = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")

    base_cols = ["ç·šåˆ¥", "æ®µæ•¸", "å§“å", "é–‹å§‹æ™‚é–“"]
    hour_cols = [int(h) for h in hour_cols]

    # å°æ™‚æ¬„ä½åœ¨ Excel çš„èµ·è¿„
    min_col = len(base_cols) + 1
    max_col = len(base_cols) + len(hour_cols)

    # æ‰¾ã€ŒåŠ ç¸½ã€æ¬„ä½
    headers = [c.value for c in ws[1]]
    total_col_idx = None
    for name in ("åŠ ç¸½", "åŠ ç¸½PCS"):
        if name in headers:
            total_col_idx = headers.index(name) + 1
            break

    # æ ¼å¼
    end_col = total_col_idx if total_col_idx is not None else max_col
    for r in ws.iter_rows(min_row=2, min_col=min_col, max_col=end_col):
        for c in r:
            c.alignment = Alignment(horizontal="center", vertical="center")
            c.number_format = "0.0000"

    # å°æ™‚æ ¼å­è‘—è‰²
    stat_values = matrix_stat[hour_cols].values.tolist()
    for i, r in enumerate(ws.iter_rows(min_row=2, min_col=min_col, max_col=max_col)):
        for j, c in enumerate(r):
            stat = stat_values[i][j] if i < len(stat_values) and j < len(stat_values[i]) else None
            if stat == STATUS_PASS:
                c.fill = fill_ok
            elif stat == STATUS_FAIL:
                c.fill = fill_ng

    # âœ… åŠ ç¸½æ¬„ä½è‘—è‰²ï¼ˆç”¨ matrix_stat["åŠ ç¸½ç‹€æ…‹"]ï¼‰
    if total_col_idx is not None and "åŠ ç¸½ç‹€æ…‹" in matrix_stat.columns:
        total_stats = matrix_stat["åŠ ç¸½ç‹€æ…‹"].tolist()
        for i in range(2, ws.max_row + 1):
            stat = total_stats[i - 2] if (i - 2) < len(total_stats) else None
            cell = ws.cell(row=i, column=total_col_idx)
            cell.number_format = "0.0000"
            cell.alignment = Alignment(horizontal="center", vertical="center")
            if stat == STATUS_PASS:
                cell.fill = fill_ok
            elif stat == STATUS_FAIL:
                cell.fill = fill_ng

    out = io.BytesIO()
    wb.save(out)
    return out.getvalue()


def main():
    st.set_page_config(page_title="å¤§è±ç‰©æµ - å‡ºè²¨èª²ï½œå„æ™‚æ®µä½œæ¥­æ•ˆç‡", page_icon="â±ï¸", layout="wide")
    if HAS_COMMON_UI:
        inject_logistics_theme()
        set_page("ğŸ“¦ å‡ºè²¨èª²", "â±ï¸ 29ï½œå„æ™‚æ®µä½œæ¥­æ•ˆç‡")

    st.markdown("### â±ï¸ å„æ™‚æ®µä½œæ¥­æ•ˆç‡ï¼ˆæ¯æ ¼é¡¯ç¤ºé‡é«”ï½œé¡è‰²=é”æ¨™/æœªé”æ¨™ï½œå«åŠ ç¸½ä¸Šè‰²ï¼‰")

    fixed_time_map = {
        'èŒƒæ˜ä¿Š': '08:00', 'é˜®ç‰å': '08:00', 'æèŒ‚éŠ“': '08:00', 'æ²³æ–‡å¼·': '08:00',
        'è”¡éº—ç ': '08:00', 'æ½˜æ–‡ä¸€': '08:00', 'é˜®ä¼Šé»ƒ': '08:00', 'è‘‰æ¬²å¼˜': '09:00',
        'é˜®æ­¦ç‰ç„': '08:00', 'å³é»ƒé‡‘ç ': '08:30', 'æ½˜æ°é’æ±Ÿ': '08:00', 'é™³åœ‹æ…¶': '08:30',
        'æ¥Šå¿ƒå¦‚': '08:00', 'é˜®ç‘ç¾é»ƒç·£': '08:00', 'å‘¨èŠ¸è“': '08:00', 'é»æ°ç“Š': '08:00',
        'ç‹æ–‡æ¥·': '08:30', 'æ½˜æ°æ…¶å¹³': '08:00', 'é˜®æ°ç¾éº—': '08:00', 'å²³å­æ†': '08:30',
        'éƒ­é›™ç‡•': '08:30', 'é˜®å­Ÿå‹‡': '08:00', 'å»–æ°¸æˆ': '08:30', 'æ¥Šæµ©å‚‘': '08:30', 'é»ƒæ—¥åº·': '08:30',
        'è”£é‡‘å¦®': '08:30', 'æŸ´å®¶æ¬£': '08:30',
    }

    with st.sidebar:
        st.markdown("### è¨­å®š")
        target_hr = st.number_input("æ¯å°æ™‚ç›®æ¨™ï¼ˆåŠ æ¬ŠPCS/å°æ™‚ï¼‰", min_value=1.0, value=790.0, step=10.0)
        hour_min = st.number_input("èµ·å§‹å°æ™‚", min_value=0, max_value=23, value=8, step=1)

        use_now = st.toggle("ç”¨ç¾åœ¨æ™‚é–“ä½œç‚ºåˆ¤æ–·æˆªæ­¢ï¼ˆå°åŒ—æ™‚é–“ï¼‰", value=True)
        if use_now:
            now = datetime.now(TPE)
        else:
            t_in = st.time_input("åˆ¤æ–·æˆªæ­¢æ™‚é–“ï¼ˆå°åŒ—æ™‚é–“ï¼‰", value=datetime.now(TPE).time())
            now = datetime.combine(date.today(), t_in).replace(tzinfo=TPE)

        st.caption(f"ç›®å‰æ¡ç”¨æ™‚é–“ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')} (Asia/Taipei)")

        auto_calc = st.toggle("ä¸Šå‚³/è¨­å®šè®Šæ›´å¾Œè‡ªå‹•æ›´æ–°", value=True)
        show_table = st.toggle("é¡¯ç¤ºè¡¨æ ¼ï¼ˆå«åŠ ç¸½ï¼‰", value=True)

    c1, c2 = st.columns(2)
    with c1:
        prod_file = st.file_uploader("â‘  ä¸Šå‚³ã€åŸå§‹ç”Ÿç”¢è³‡æ–™ã€(CSV/Excel)", type=["csv", "xlsx", "xlsm", "xls"])
    with c2:
        mem_file = st.file_uploader("â‘¡ ä¸Šå‚³ã€äººå“¡åå–®ã€(CSV/Excel)", type=["csv", "xlsx", "xlsm", "xls"])

    manual = st.button("ğŸš€ ç«‹å³æ›´æ–°/é‡ç®—", type="primary", use_container_width=True)

    if prod_file is None or mem_file is None:
        st.info("è«‹å…ˆä¸Šå‚³å…©å€‹æª”æ¡ˆï¼šç”Ÿç”¢è³‡æ–™ + äººå“¡åå–®ã€‚")
        return

    prod_sig = _bytes_sig(prod_file.getvalue())
    mem_sig = _bytes_sig(mem_file.getvalue())
    settings_sig = f"{target_hr}-{hour_min}-{use_now}-{now.hour}-{now.minute}-{show_table}"

    last = st.session_state.get("_29_last_sig", None)
    cur_sig = (prod_sig, mem_sig, settings_sig)
    should_run = manual or (auto_calc and (last != cur_sig))
    if not should_run:
        st.caption("ï¼ˆç›®å‰çµæœå·²æ˜¯æœ€æ–°ï¼›å¦‚æœ‰æ›´æ–°æª”æ¡ˆ/è¨­å®šæœƒè‡ªå‹•åŒæ­¥ï¼‰")
        return
    st.session_state["_29_last_sig"] = cur_sig

    try:
        # ========= 1) äººå“¡åå–® =========
        df_mem_raw = _norm_cols(read_table_robust(mem_file.name, mem_file.getvalue(), label="äººå“¡åå–®æª”æ¡ˆ"))

        line_col_candidates = ["LINEID", "ç·šåˆ¥", "LineID", "LINE Id", "Line Id"]
        line_col = next((c for c in line_col_candidates if c in df_mem_raw.columns), None)
        if line_col is None:
            raise ValueError("äººå“¡åå–®æ‰¾ä¸åˆ°ç·šåˆ¥æ¬„ä½ï¼ˆéœ€è¦ LINEID æˆ– ç·šåˆ¥ï¼‰ã€‚")

        seg_cols = {1: "ç¬¬ä¸€æ®µ", 2: "ç¬¬äºŒæ®µ", 3: "ç¬¬ä¸‰æ®µ", 4: "ç¬¬å››æ®µ"}
        for _, colname in seg_cols.items():
            if colname not in df_mem_raw.columns:
                raise ValueError(f"äººå“¡åå–®ç¼ºå°‘æ¬„ä½ï¼š{colname}ï¼ˆéœ€è¦ ç¬¬ä¸€æ®µï½ç¬¬å››æ®µï¼‰")

        member_list = []
        for _, row in df_mem_raw.iterrows():
            line_id = str(row.get(line_col, "")).strip()
            if not line_id or line_id.lower() == "nan":
                continue
            for zid, colname in seg_cols.items():
                name = row.get(colname, None)
                if pd.notna(name) and str(name).strip() != "":
                    n_str = str(name).strip()
                    st_time = _safe_time(fixed_time_map.get(n_str, "08:00"))
                    member_list.append({"ç·šåˆ¥": line_id, "æ®µæ•¸": zid, "å§“å": n_str, "é–‹å§‹æ™‚é–“": st_time})

        df_members = pd.DataFrame(member_list)
        if df_members.empty:
            raise ValueError("äººå“¡åå–®è§£æå¾Œç‚ºç©ºï¼šè«‹ç¢ºèª ç¬¬ä¸€æ®µï½ç¬¬å››æ®µ å…§æœ‰å§“åã€‚")

        df_members["ç·šåˆ¥"] = clean_line(df_members["ç·šåˆ¥"])
        df_members["æ®µæ•¸"] = clean_zone_1to4(df_members["æ®µæ•¸"])
        df_members = df_members[df_members["æ®µæ•¸"].notna()].copy()

        # âœ… åŒç·šåˆ¥+æ®µæ•¸åªå–ç¬¬ä¸€ç­†ï¼Œé¿å… merge å±•é–‹
        df_members = df_members.drop_duplicates(["ç·šåˆ¥", "æ®µæ•¸"], keep="first").copy()

        # ========= 2) ç”Ÿç”¢è³‡æ–™ï¼ˆå»é‡å¾ŒåŠ æ¬ŠPCSï¼‰ =========
        df_raw = read_table_robust(prod_file.name, prod_file.getvalue(), label="ç”Ÿç”¢è³‡æ–™æª”æ¡ˆ")
        require_columns(df_raw, ["PICKDATE", "LINEID", "ZONEID", "PACKQTY", "Cweight"], "ç”Ÿç”¢è³‡æ–™æª”æ¡ˆ")

        df_raw["PICKDATE"] = pd.to_datetime(df_raw["PICKDATE"], errors="coerce")
        df_raw = df_raw[df_raw["PICKDATE"].notna()].copy()

        df_raw = df_raw.rename(columns={"LINEID": "ç·šåˆ¥", "ZONEID": "æ®µæ•¸"})
        df_raw["ç·šåˆ¥"] = clean_line(df_raw["ç·šåˆ¥"])
        df_raw["æ®µæ•¸"] = clean_zone_1to4(df_raw["æ®µæ•¸"])
        df_raw = df_raw[df_raw["æ®µæ•¸"].notna()].copy()
        if df_raw.empty:
            raise ValueError("ç”Ÿç”¢è³‡æ–™æ¸…ç†å¾Œç‚ºç©ºï¼šè«‹ç¢ºèª ZONEID æ˜¯å¦ç‚º 1~4ã€‚")

        df_raw["PACKQTY"] = pd.to_numeric(df_raw["PACKQTY"], errors="coerce").fillna(0)
        df_raw["Cweight"] = pd.to_numeric(df_raw["Cweight"], errors="coerce").fillna(0)
        df_raw["åŠ æ¬ŠPCS"] = df_raw["PACKQTY"] * df_raw["Cweight"]

        # âœ… å”¯ä¸€æŒ‡ç´‹å»é‡ï¼ˆé¿å…ç¿»å€ï¼‰
        rid_cols = [c for c in df_raw.columns if c not in ("å§“å", "é–‹å§‹æ™‚é–“", "å°æ™‚", "__rid")]
        df_raw["__rid"] = pd.util.hash_pandas_object(df_raw[rid_cols], index=False)

        df = pd.merge(df_raw, df_members, on=["ç·šåˆ¥", "æ®µæ•¸"], how="left", validate="m:1")
        df["å§“å"] = df["å§“å"].fillna("æœªè¨­å®š")
        df["é–‹å§‹æ™‚é–“"] = df["é–‹å§‹æ™‚é–“"].fillna("08:00").map(_safe_time)
        df = df.drop_duplicates("__rid", keep="first").copy()

        # é–‹å§‹æ™‚é–“éæ¿¾
        pick_minutes = df["PICKDATE"].dt.hour * 60 + df["PICKDATE"].dt.minute
        st_parts = df["é–‹å§‹æ™‚é–“"].astype(str).str.split(":", n=1, expand=True)
        st_h = pd.to_numeric(st_parts[0], errors="coerce").fillna(8).astype(int)
        st_m = pd.to_numeric(st_parts[1], errors="coerce").fillna(0).astype(int)
        st_minutes = st_h * 60 + st_m
        df = df[pick_minutes >= st_minutes].copy()
        if df.empty:
            raise ValueError("å¥—ç”¨é–‹å§‹æ™‚é–“éæ¿¾å¾Œæ²’æœ‰è³‡æ–™ï¼šè«‹ç¢ºèª PICKDATE èˆ‡é–‹å§‹æ™‚é–“è¨­å®šã€‚")

        # ========= 3) æ¯å°æ™‚é‡é«” =========
        df["å°æ™‚"] = df["PICKDATE"].dt.hour
        base_cols = ["ç·šåˆ¥", "æ®µæ•¸", "å§“å", "é–‹å§‹æ™‚é–“"]

        hourly_sum = df.groupby(base_cols + ["å°æ™‚"], as_index=False)["åŠ æ¬ŠPCS"].sum()
        hourly_sum = hourly_sum.rename(columns={"åŠ æ¬ŠPCS": "ç•¶å°æ™‚åŠ æ¬ŠPCS"})

        cur_h, cur_m = now.hour, now.minute
        if int(cur_h) >= int(hour_min):
            hour_cols = list(range(int(hour_min), int(cur_h) + 1))
        else:
            hour_cols = [int(cur_h)]  # é¿å…ç©º range

        keys = df_members[base_cols].drop_duplicates().copy()
        grid_hours = keys.assign(_k=1).merge(pd.DataFrame({"å°æ™‚": hour_cols, "_k": 1}), on="_k").drop(columns=["_k"])

        hourly_full = grid_hours.merge(hourly_sum, on=base_cols + ["å°æ™‚"], how="left")
        hourly_full["ç•¶å°æ™‚åŠ æ¬ŠPCS"] = pd.to_numeric(hourly_full["ç•¶å°æ™‚åŠ æ¬ŠPCS"], errors="coerce").fillna(0.0)

        # ========= 4) âœ… æ¯å°æ™‚åˆ¤æ–·ï¼ˆæœ¬å°æ™‚ç›®æ¨™ï¼‰ =========
        parts = hourly_full["é–‹å§‹æ™‚é–“"].astype(str).str.split(":", n=1, expand=True)
        s_h = pd.to_numeric(parts[0], errors="coerce").fillna(8).astype(int)
        s_m = pd.to_numeric(parts[1], errors="coerce").fillna(0).astype(int)

        hh = pd.to_numeric(hourly_full["å°æ™‚"], errors="coerce").fillna(0).astype(int)
        slot = hh.map(lambda x: _slot_minutes(int(x))).astype(int)

        # end_mï¼šè‹¥æ˜¯ç›®å‰å°æ™‚ï¼Œç”¨ç¾åœ¨åˆ†é˜ï¼Œä½† cap åˆ° slotï¼ˆ12/13æœ€å¤š 30ï¼‰
        end_m = np.where(hh == cur_h, np.minimum(cur_m, slot), slot).astype(int)

        # minutes_worked in this hour:
        minutes_worked = np.where(
            hh > cur_h, 0,
            np.where(
                hh < s_h, 0,
                np.where(
                    hh == s_h, np.maximum(0, end_m - s_m),
                    end_m
                )
            )
        ).astype(float)

        hourly_full["æœ¬å°æ™‚æœ‰æ•ˆåˆ†é˜"] = minutes_worked
        hourly_full["æœ¬å°æ™‚ç›®æ¨™"] = (minutes_worked / 60.0) * float(target_hr)

        hourly_full["ç‹€æ…‹"] = np.where(
            hourly_full["æœ¬å°æ™‚æœ‰æ•ˆåˆ†é˜"] <= 0,
            None,
            np.where(hourly_full["ç•¶å°æ™‚åŠ æ¬ŠPCS"] >= hourly_full["æœ¬å°æ™‚ç›®æ¨™"], STATUS_PASS, STATUS_FAIL)
        )

        # KPIï¼ˆæŸå°æ™‚ï¼‰
        dist = (
            hourly_full[hourly_full["ç‹€æ…‹"].isin([STATUS_PASS, STATUS_FAIL])]
            .groupby(["ç·šåˆ¥", "å°æ™‚", "ç‹€æ…‹"], as_index=False)
            .size()
            .rename(columns={"size": "count"})
        )

        # ========= 5) âœ… åŒ¯å‡ºçŸ©é™£ + âœ… åŠ ç¸½ï¼ˆé€åˆ—ç›¸åŠ ï¼Œä¿è­‰æœ‰å€¼ï¼‰ =========
        matrix_vol = hourly_full.pivot(index=base_cols, columns="å°æ™‚", values="ç•¶å°æ™‚åŠ æ¬ŠPCS").reset_index()
        matrix_stat = hourly_full.pivot(index=base_cols, columns="å°æ™‚", values="ç‹€æ…‹").reset_index()
        matrix_tar = hourly_full.pivot(index=base_cols, columns="å°æ™‚", values="æœ¬å°æ™‚ç›®æ¨™").reset_index()

        matrix_vol.columns = [int(c) if str(c).isdigit() else c for c in matrix_vol.columns]
        matrix_stat.columns = [int(c) if str(c).isdigit() else c for c in matrix_stat.columns]
        matrix_tar.columns = [int(c) if str(c).isdigit() else c for c in matrix_tar.columns]

        for h in hour_cols:
            if h not in matrix_vol.columns:
                matrix_vol[h] = 0.0
            if h not in matrix_stat.columns:
                matrix_stat[h] = None
            if h not in matrix_tar.columns:
                matrix_tar[h] = 0.0

        matrix_vol = matrix_vol[base_cols + hour_cols]
        matrix_stat = matrix_stat[base_cols + hour_cols]
        matrix_tar = matrix_tar[base_cols + hour_cols]

        # âœ… åŠ ç¸½ï¼ˆæ¬„å=åŠ ç¸½ï¼Œè·Ÿä½ æˆªåœ–ä¸€è‡´ï¼‰
        matrix_vol["åŠ ç¸½"] = (
            matrix_vol[hour_cols]
            .apply(pd.to_numeric, errors="coerce")
            .fillna(0.0)
            .sum(axis=1)
        )

        total_target = (
            matrix_tar[hour_cols]
            .apply(pd.to_numeric, errors="coerce")
            .fillna(0.0)
            .sum(axis=1)
        )

        matrix_stat["åŠ ç¸½ç‹€æ…‹"] = np.where(
            total_target <= 0,
            None,
            np.where(matrix_vol["åŠ ç¸½"] >= total_target, STATUS_PASS, STATUS_FAIL)
        )

        st.success("è¨ˆç®—å®Œæˆ âœ…ï¼ˆåŠ ç¸½å·²ç¢ºä¿è¨ˆç®—ï¼›åŠ ç¸½ä¹Ÿæœƒä¸Šè‰²ï¼›12/13=30åˆ†ï¼‰")
        st.markdown("## ğŸ“Š KPIï¼ˆæ¯ç·šï¼šæ®µ1~æ®µ4ï¼‰")

        eff_hour = int(cur_h)
        lines = sorted(keys["ç·šåˆ¥"].dropna().unique().tolist())

        for line in lines:
            if HAS_COMMON_UI:
                card_open(f"ğŸ“¦ {line}")
            else:
                st.markdown(f"### ğŸ“¦ {line}")

            dist_now = dist[(dist["ç·šåˆ¥"] == line) & (dist["å°æ™‚"] == eff_hour)]
            p, f, rate = _kpi_counts(dist_now)

            c1, c2, c3, c4 = st.columns(4)
            c1.metric("åˆ¤æ–·å°æ™‚", f"{eff_hour} é»")
            c2.metric("é”æ¨™ æ®µæ•¸", p)
            c3.metric("æœªé”æ¨™ æ®µæ•¸", f)
            c4.metric("é”æ¨™ ç‡", (f"{rate:.1f}%" if rate is not None else "â€”"))

            df_line = hourly_full[hourly_full["ç·šåˆ¥"] == line][
                ["æ®µæ•¸", "å§“å", "å°æ™‚", "ç•¶å°æ™‚åŠ æ¬ŠPCS", "æœ¬å°æ™‚ç›®æ¨™", "ç‹€æ…‹"]
            ].copy()

            st.markdown("#### ğŸ“Œ æ¯å°æ™‚é‡é«”æ ¼ï¼ˆé¡è‰²=é”æ¨™/æœªé”æ¨™ï½œæ ¼å…§=é‡é«”ï¼‰")
            render_hourly_heatmap(
                df_line_hourly=df_line,
                hour_cols=hour_cols,
                title=f"{line}ï½œæ¯å°æ™‚ï¼ˆ12/13=30åˆ†ï¼‰"
            )

            if show_table:
                render_grid_table_with_total(
                    df_line=df_line,
                    hour_cols=hour_cols,
                    title="æ®µ1~æ®µ4 Ã— æ¯å°æ™‚ï¼ˆè¡¨æ ¼ï¼šæ¯æ ¼=é‡é«”ï¼›æœ€å³=åŠ ç¸½ï¼Œä¸Šè‰²ï¼‰"
                )

            if HAS_COMMON_UI:
                card_close()

        st.markdown("## â¬‡ï¸ ä¸‹è¼‰")
        xlsx_bytes = build_excel_bytes_volume(matrix_vol, matrix_stat, hour_cols)
        filename = f"ç”¢èƒ½æ™‚æ®µ_é‡é«”é”æ¨™è‰²å¡Š_å«åŠ ç¸½_{datetime.now(TPE).strftime('%H%M')}.xlsx"
        st.download_button(
            "â¬‡ï¸ ä¸‹è¼‰ Excelï¼ˆæ¯æ ¼=ç•¶å°æ™‚åŠ æ¬ŠPCSï¼›å«åŠ ç¸½ï¼›é¡è‰²=é”æ¨™/æœªé”æ¨™ï¼‰",
            data=xlsx_bytes,
            file_name=filename,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )

    except Exception as e:
        st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")


if __name__ == "__main__":
    main()
