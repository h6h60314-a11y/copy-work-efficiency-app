# pages/29_å„æ™‚æ®µä½œæ¥­æ•ˆç‡.py
# -*- coding: utf-8 -*-
import io
import os
from io import StringIO
from datetime import datetime, date
from zoneinfo import ZoneInfo

import numpy as np
import pandas as pd
import streamlit as st
import altair as alt

from openpyxl import Workbook
from openpyxl.utils import get_column_letter
from openpyxl.styles import Alignment, Font, PatternFill
from openpyxl.formatting.rule import FormulaRule

# ---- å¥—ç”¨å¹³å°é¢¨æ ¼ï¼ˆæœ‰å°±ç”¨ï¼Œæ²’æœ‰å°±é€€å›åŸç”Ÿï¼‰----
try:
    from common_ui import inject_logistics_theme, set_page, card_open, card_close
    HAS_COMMON_UI = True
except Exception:
    HAS_COMMON_UI = False

TPE = ZoneInfo("Asia/Taipei")

STATUS_PASS = "é”æ¨™"
STATUS_FAIL = "æœªé”æ¨™"
STATUS_NA = "æœªåˆ¤æ–·"

# âœ… ç‰¹æ®Šå·¥æ™‚ï¼ˆåˆ†é˜ï¼‰ï¼š12é»ã€13é»åªæœ‰ 30 åˆ†é˜
WORK_MINUTES_BY_HOUR = {12: 30, 13: 30}


# =============================
# æ¬„ä½æ•´ç† / æª¢æŸ¥
# =============================
def _norm_cols(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    return df


def require_columns(df: pd.DataFrame, required: list, label: str):
    missing = [c for c in required if c not in df.columns]
    if missing:
        raise ValueError(f"{label} ç¼ºå°‘æ¬„ä½ï¼š{missing}\nç›®å‰æ¬„ä½ï¼š{list(df.columns)}")


def clean_line(series: pd.Series) -> pd.Series:
    return series.astype(str).str.strip()


def clean_zone_1to4(series: pd.Series) -> pd.Series:
    z = pd.to_numeric(series, errors="coerce").astype("Int64")
    return z.where(z.between(1, 4, inclusive="both"))


def _safe_time(s: str) -> str:
    s = str(s).strip()
    if not s:
        return "08:00"
    try:
        datetime.strptime(s, "%H:%M")
        return s
    except Exception:
        return "08:00"


def _bytes_sig(b: bytes) -> str:
    if b is None:
        return "0"
    n = len(b)
    head = b[:128]
    tail = b[-128:] if n >= 128 else b
    return f"{n}-{hash(head)}-{hash(tail)}"


def _slot_minutes(hour: int) -> int:
    return int(WORK_MINUTES_BY_HOUR.get(int(hour), 60))


# =============================
# âœ… è®€æª”ï¼šCSV/TSV/Excelï¼ˆå« .xls å‡æª”ï¼‰å¼·éŸŒè®€å–
#   - ä½ çš„ .xls å…¶å¯¦æ˜¯ TSVï¼šæª”é ­åƒ b'BOXID\\tOR...'
#   - ä¿®æ­£ï¼špython engine ä¸æ”¯æ´ low_memory â†’ ä¸å†å‚³å…¥
# =============================
def _looks_like_html(raw: bytes) -> bool:
    head = raw[:4096].lstrip().lower()
    return (b"<html" in head) or (b"<!doctype" in head) or (b"<table" in head)


def _read_html_table(raw: bytes) -> pd.DataFrame:
    for enc in ["utf-8-sig", "utf-8", "cp950", "big5", "ms950", "latin1", "gb18030"]:
        try:
            text = raw.decode(enc, errors="ignore")
            tables = pd.read_html(StringIO(text))
            tables = [t for t in tables if isinstance(t, pd.DataFrame) and t.shape[1] >= 2]
            if not tables:
                continue
            return max(tables, key=lambda x: x.shape[0] * x.shape[1])
        except Exception:
            continue
    raise ValueError("åµæ¸¬ç‚º HTML ä½†è§£æè¡¨æ ¼å¤±æ•—ï¼ˆread_html å¤±æ•—ï¼‰ã€‚")


def _read_csv_guess(raw: bytes) -> pd.DataFrame:
    encodings = ["utf-8-sig", "utf-8", "cp950", "big5", "ms950", "gb18030", "latin1"]
    seps = ["\t", ",", ";", "|"]  # âœ… tab æ”¾ç¬¬ä¸€å„ªå…ˆ
    last_err = None

    for enc in encodings:
        for sep in seps:
            # å…ˆç”¨ C engineï¼ˆæœ€å¿«ã€æœ€ç©©ï¼‰ï¼Œå¤±æ•—å†æ› python
            for engine in ["c", "python"]:
                try:
                    kwargs = dict(encoding=enc, sep=sep, engine=engine)

                    # âœ… low_memory åªæœ‰ C engine æ‰èƒ½ç”¨ï¼›python engine ä¸èƒ½å¸¶
                    if engine == "c":
                        kwargs["low_memory"] = False

                    df = pd.read_csv(io.BytesIO(raw), **kwargs)
                    if df.shape[1] <= 1:
                        continue
                    return df
                except Exception as e:
                    last_err = e

    # æœ€å¾Œï¼šè®“ pandas è‡ªå·±çŒœåˆ†éš”ç¬¦ï¼ˆsep=None åªèƒ½ç”¨ pythonï¼‰
    try:
        text = raw.decode("utf-8", errors="replace")
        df = pd.read_csv(StringIO(text), sep=None, engine="python")
        if df.shape[1] <= 1:
            raise ValueError("åµæ¸¬ä¸åˆ°æœ‰æ•ˆåˆ†éš”ç¬¦ï¼Œè«‹ç¢ºèªæª”æ¡ˆå…§å®¹ã€‚")
        return df
    except Exception as e:
        raise ValueError(f"è®€å–ç‚º CSV/TSV å¤±æ•—ï¼š{last_err} / æœ€çµ‚ï¼š{e}")


def read_table_robust(file_name: str, raw: bytes, label: str = "æª”æ¡ˆ") -> pd.DataFrame:
    ext = os.path.splitext(file_name)[1].lower()
    head = raw[:2048]
    looks_tsv = (b"\t" in head) and (head.count(b"\t") >= 2)

    # ---- xlsx é¡ ----
    if ext in (".xlsx", ".xlsm", ".xltx", ".xltm"):
        try:
            return pd.read_excel(io.BytesIO(raw), engine="openpyxl")
        except Exception:
            # æœ‰äº›è¢«æ”¹å‰¯æª”å â†’ ç•¶æ–‡å­—æª”è®€
            if _looks_like_html(raw):
                return _read_html_table(raw)
            return _read_csv_guess(raw)

    # ---- .xlsï¼šå…ˆç•¶æ–‡å­—æª”ï¼ˆä½ é€™ç¨®æœ€å¸¸è¦‹ï¼‰----
    if ext == ".xls":
        # 1) å„ªå…ˆ TSV/CSVï¼ˆä½ çš„æª”é ­ BOXID\tOR...ï¼‰
        try:
            if looks_tsv:
                for enc in ["utf-8-sig", "utf-8", "cp950", "big5", "ms950", "latin1", "gb18030"]:
                    try:
                        df = pd.read_csv(io.BytesIO(raw), sep="\t", encoding=enc, engine="c", low_memory=False)
                        if df.shape[1] > 1:
                            return df
                    except Exception:
                        pass
            # ä¸æ˜¯æ˜é¡¯ TSV æˆ–ä¸Šé¢å¤±æ•— â†’ äº¤çµ¦çŒœæ¸¬å™¨
            return _read_csv_guess(raw)
        except Exception as e_text:
            # 2) å†å˜—è©¦çœŸæ­£ xlsï¼ˆéœ€è¦ xlrdï¼Œä¸”æª”æ¡ˆçœŸçš„æ˜¯ BIFF xlsï¼‰
            try:
                import xlrd  # noqa: F401
                return pd.read_excel(io.BytesIO(raw), engine="xlrd")
            except Exception as e_xls:
                if _looks_like_html(raw):
                    try:
                        return _read_html_table(raw)
                    except Exception:
                        pass
                raise ValueError(
                    f"{label} è®€å– .xls å¤±æ•—ï¼š\n"
                    f"- æ–‡å­—æª”(TSV/CSV) è§£æå¤±æ•—ï¼š{e_text}\n"
                    f"- Excel(xlrd) è§£æå¤±æ•—ï¼š{e_xls}\n"
                    f"ï¼ˆæ­¤æª”å¾ˆå¯èƒ½æ˜¯ TSV æ–‡å­—æª”ï¼Œåªæ˜¯å‰¯æª”åå« .xlsï¼‰"
                )

    # ---- å…¶ä»–ï¼šå…ˆç•¶æ–‡å­—æª” ----
    if _looks_like_html(raw):
        return _read_html_table(raw)
    return _read_csv_guess(raw)


# =============================
# KPI è¨ˆæ•¸ï¼ˆæŸå°æ™‚ï¼‰
# =============================
def _kpi_counts(dist_df: pd.DataFrame):
    if dist_df is None or dist_df.empty:
        return 0, 0, None
    p = int(dist_df.loc[dist_df["ç‹€æ…‹"] == STATUS_PASS, "count"].sum())
    f = int(dist_df.loc[dist_df["ç‹€æ…‹"] == STATUS_FAIL, "count"].sum())
    rate = (p / (p + f) * 100.0) if (p + f) > 0 else None
    return p, f, rate


# =============================
# Heatmapï¼ˆStreamlit é¡¯ç¤ºç”¨ï¼‰
# =============================
def render_hourly_heatmap(df_line_hourly: pd.DataFrame, hour_cols, title: str):
    if df_line_hourly is None or df_line_hourly.empty:
        st.info("æ²’æœ‰å¯å‘ˆç¾çš„åœ–ã€‚")
        return

    hour_cols = [int(h) for h in list(hour_cols)]
    plot = df_line_hourly.copy()

    plot["æ®µæ•¸"] = pd.to_numeric(plot["æ®µæ•¸"], errors="coerce").fillna(0).astype(int)
    plot["å°æ™‚"] = pd.to_numeric(plot["å°æ™‚"], errors="coerce").fillna(0).astype(int)
    plot["ç•¶å°æ™‚åŠ æ¬ŠPCS"] = pd.to_numeric(plot["ç•¶å°æ™‚åŠ æ¬ŠPCS"], errors="coerce").fillna(0.0)
    plot["æœ¬å°æ™‚ç›®æ¨™"] = pd.to_numeric(plot["æœ¬å°æ™‚ç›®æ¨™"], errors="coerce").fillna(0.0)

    plot["label"] = plot["æ®µæ•¸"].astype(str) + "æ®µï½œ" + plot["å§“å"].astype(str)
    plot["ç‹€æ…‹_è‰²"] = plot["ç‹€æ…‹"].fillna(STATUS_NA)
    plot["é¡¯ç¤ºé‡"] = plot["ç•¶å°æ™‚åŠ æ¬ŠPCS"].apply(lambda x: "" if abs(float(x)) < 1e-12 else f"{float(x):.2f}")

    order = (
        plot[["label", "æ®µæ•¸", "å§“å"]]
        .drop_duplicates()
        .sort_values(["æ®µæ•¸", "å§“å"])["label"]
        .tolist()
    )

    color_enc = alt.Color(
        "ç‹€æ…‹_è‰²:N",
        scale=alt.Scale(domain=[STATUS_PASS, STATUS_FAIL, STATUS_NA], range=["#2E7D32", "#C62828", "#D0D5DD"]),
        legend=alt.Legend(title="ç‹€æ…‹"),
    )

    base = alt.Chart(plot).encode(
        x=alt.X("å°æ™‚:O", sort=[str(h) for h in hour_cols], title="æ¯å°æ™‚"),
        y=alt.Y("label:N", sort=order, title="æ®µæ•¸ï½œå§“å"),
        tooltip=[
            alt.Tooltip("ç·šåˆ¥:N", title="ç·šåˆ¥"),
            alt.Tooltip("label:N", title="æ®µæ•¸ï½œå§“å"),
            alt.Tooltip("å°æ™‚:O", title="å°æ™‚"),
            alt.Tooltip("ç•¶å°æ™‚åŠ æ¬ŠPCS:Q", title="ç•¶å°æ™‚åŠ æ¬ŠPCS", format=",.4f"),
            alt.Tooltip("æœ¬å°æ™‚ç›®æ¨™:Q", title="æœ¬å°æ™‚ç›®æ¨™", format=",.2f"),
            alt.Tooltip("ç‹€æ…‹:N", title="ç‹€æ…‹"),
        ],
    )

    rect = base.mark_rect(cornerRadius=4).encode(color=color_enc)
    text = base.mark_text(fontSize=12, fontWeight=900).encode(text="é¡¯ç¤ºé‡:N")

    n_rows = max(1, plot["label"].nunique())
    height = min(42 * n_rows + 80, 900)
    st.altair_chart((rect + text).properties(title=title, height=height), use_container_width=True)


# =============================
# âœ… Excelï¼šä¿ç•™å…¬å¼ + è‰²å¡Šï¼ˆæ¢ä»¶æ ¼å¼ï¼‰
# âœ… ä¸ä½¿ç”¨ LET()ï¼ˆèˆŠ Excel ä¹Ÿèƒ½ç®—ï¼‰
# =============================
def build_excel_bytes_with_formulas_and_colors(
    detail_df: pd.DataFrame,
    roster_df: pd.DataFrame,
    hour_cols: list[int],
    target_hr: float,
    now_h: int,
    now_m: int,
) -> bytes:
    wb = Workbook()
    ws_detail = wb.active
    ws_detail.title = "å®Œæ•´æ˜ç´°_å»é‡å¾Œ"
    ws_mat = wb.create_sheet("æ™‚æ®µé‡é«”_å…¬å¼")
    ws_param = wb.create_sheet("åƒæ•¸")

    # åƒæ•¸è¡¨
    ws_param["A1"] = "now_h"; ws_param["B1"] = int(now_h)
    ws_param["A2"] = "now_m"; ws_param["B2"] = int(now_m)
    ws_param["A3"] = "target_hr"; ws_param["B3"] = float(target_hr)
    for r in range(1, 4):
        ws_param[f"A{r}"].font = Font(bold=True)

    # Sheet1ï¼šå®Œæ•´æ˜ç´°
    cols = list(detail_df.columns)
    for c_idx, col in enumerate(cols, start=1):
        ws_detail.cell(row=1, column=c_idx, value=col).font = Font(bold=True)

    col_pack = cols.index("PACKQTY") + 1 if "PACKQTY" in cols else None
    col_w = cols.index("Cweight") + 1 if "Cweight" in cols else None
    col_aw = cols.index("åŠ æ¬ŠPCS") + 1 if "åŠ æ¬ŠPCS" in cols else None

    for r_idx, row in enumerate(detail_df.itertuples(index=False), start=2):
        for c_idx, col in enumerate(cols, start=1):
            v = getattr(row, col) if hasattr(row, col) else None
            ws_detail.cell(row=r_idx, column=c_idx, value=v)

        if col_pack and col_w and col_aw:
            p_cell = f"{get_column_letter(col_pack)}{r_idx}"
            w_cell = f"{get_column_letter(col_w)}{r_idx}"
            ws_detail.cell(row=r_idx, column=col_aw, value=f"={p_cell}*{w_cell}")
            ws_detail.cell(row=r_idx, column=col_aw).number_format = "0.0000"

    # SUMIFS å®šä½
    detail_header_to_col = {ws_detail.cell(row=1, column=i).value: i for i in range(1, ws_detail.max_column + 1)}
    need = ["ç·šåˆ¥", "æ®µæ•¸", "å°æ™‚", "åŠ æ¬ŠPCS", "ç´å…¥è¨ˆç®—"]
    for k in need:
        if k not in detail_header_to_col:
            raise ValueError(f"æ˜ç´°ç¼ºå°‘æ¬„ä½ã€Œ{k}ã€ï¼Œç„¡æ³•å»ºç«‹ SUMIFS å…¬å¼ã€‚")

    d_line = get_column_letter(detail_header_to_col["ç·šåˆ¥"])
    d_zone = get_column_letter(detail_header_to_col["æ®µæ•¸"])
    d_hour = get_column_letter(detail_header_to_col["å°æ™‚"])
    d_aw = get_column_letter(detail_header_to_col["åŠ æ¬ŠPCS"])
    d_in = get_column_letter(detail_header_to_col["ç´å…¥è¨ˆç®—"])
    d_first, d_last = 2, ws_detail.max_row

    # Sheet2ï¼šæ™‚æ®µé‡é«”ï¼ˆæ¯å°æ™‚ï¼šé‡é«”/ç›®æ¨™/ç‹€æ…‹ï¼‰
    base_cols = ["ç·šåˆ¥", "æ®µæ•¸", "å§“å", "é–‹å§‹æ™‚é–“"]
    hour_cols = [int(h) for h in hour_cols]

    headers = base_cols[:]
    for h in hour_cols:
        headers += [str(h), f"{h}_ç›®æ¨™", f"{h}_ç‹€æ…‹"]
    headers += ["åŠ ç¸½", "åŠ ç¸½ç›®æ¨™", "åŠ ç¸½ç‹€æ…‹"]

    for c_idx, h in enumerate(headers, start=1):
        ws_mat.cell(row=1, column=c_idx, value=h).font = Font(bold=True)

    fill_ok = PatternFill(start_color="C6EFCE", end_color="C6EFCE", fill_type="solid")
    fill_ng = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")
    fill_na = PatternFill(start_color="F2F4F7", end_color="F2F4F7", fill_type="solid")

    now_h_cell = "åƒæ•¸!$B$1"
    now_m_cell = "åƒæ•¸!$B$2"
    target_hr_cell = "åƒæ•¸!$B$3"

    for r_idx, row in enumerate(roster_df.itertuples(index=False), start=2):
        ws_mat.cell(row=r_idx, column=1, value=row.ç·šåˆ¥)
        ws_mat.cell(row=r_idx, column=2, value=int(row.æ®µæ•¸))
        ws_mat.cell(row=r_idx, column=3, value=str(row.å§“å))

        hh, mm = str(row.é–‹å§‹æ™‚é–“).split(":")
        ws_mat.cell(row=r_idx, column=4, value=f"=TIME({int(hh)},{int(mm)},0)")

        start_time_cell = f"$D{r_idx}"

        col_ptr = 5
        sum_cells = []
        tgt_cells = []

        for h in hour_cols:
            vol_col = col_ptr
            tgt_col = col_ptr + 1
            st_col = col_ptr + 2

            vol_cell = f"{get_column_letter(vol_col)}{r_idx}"
            tgt_cell = f"{get_column_letter(tgt_col)}{r_idx}"

            line_cell = f"$A{r_idx}"
            zone_cell = f"$B{r_idx}"
            vol_formula = (
                f'=SUMIFS('
                f'\'{ws_detail.title}\'!${d_aw}${d_first}:${d_aw}${d_last},'
                f'\'{ws_detail.title}\'!${d_line}${d_first}:${d_line}${d_last},{line_cell},'
                f'\'{ws_detail.title}\'!${d_zone}${d_first}:${d_zone}${d_last},{zone_cell},'
                f'\'{ws_detail.title}\'!${d_hour}${d_first}:${d_hour}${d_last},{h},'
                f'\'{ws_detail.title}\'!${d_in}${d_first}:${d_in}${d_last},TRUE)'
            )
            ws_mat.cell(row=r_idx, column=vol_col, value=vol_formula)
            ws_mat.cell(row=r_idx, column=vol_col).number_format = "0.0000"

            slot = f'IF(OR({h}=12,{h}=13),30,60)'
            endm = f'IF({h}={now_h_cell},MIN({now_m_cell},{slot}),{slot})'
            sh = f'HOUR({start_time_cell})'
            sm = f'MINUTE({start_time_cell})'
            mins = f'IF({h}>{now_h_cell},0,IF({h}<{sh},0,IF({h}={sh},MAX(0,{endm}-{sm}),{endm})))'
            tgt_formula = f'={target_hr_cell}*({mins})/60'
            ws_mat.cell(row=r_idx, column=tgt_col, value=tgt_formula)
            ws_mat.cell(row=r_idx, column=tgt_col).number_format = "0.0000"

            st_formula = f'=IF({tgt_cell}<=0,"",IF({vol_cell}>={tgt_cell},"{STATUS_PASS}","{STATUS_FAIL}"))'
            ws_mat.cell(row=r_idx, column=st_col, value=st_formula)

            sum_cells.append(vol_cell)
            tgt_cells.append(tgt_cell)
            col_ptr += 3

        sum_col = col_ptr
        sum_tgt_col = col_ptr + 1
        sum_st_col = col_ptr + 2

        sum_cell = f"{get_column_letter(sum_col)}{r_idx}"
        sum_tgt_cell = f"{get_column_letter(sum_tgt_col)}{r_idx}"

        ws_mat.cell(row=r_idx, column=sum_col, value=f"=SUM({','.join(sum_cells)})")
        ws_mat.cell(row=r_idx, column=sum_col).number_format = "0.0000"

        ws_mat.cell(row=r_idx, column=sum_tgt_col, value=f"=SUM({','.join(tgt_cells)})")
        ws_mat.cell(row=r_idx, column=sum_tgt_col).number_format = "0.0000"

        ws_mat.cell(
            row=r_idx,
            column=sum_st_col,
            value=f'=IF({sum_tgt_cell}<=0,"",IF({sum_cell}>={sum_tgt_cell},"{STATUS_PASS}","{STATUS_FAIL}"))',
        )

    # æ¬„å¯¬ / å°é½Š
    ws_mat.column_dimensions["A"].width = 10
    ws_mat.column_dimensions["B"].width = 6
    ws_mat.column_dimensions["C"].width = 14
    ws_mat.column_dimensions["D"].width = 10

    for row in ws_mat.iter_rows(min_row=1, max_row=ws_mat.max_row, min_col=1, max_col=ws_mat.max_column):
        for cell in row:
            cell.alignment = Alignment(horizontal="center", vertical="center")

    # éš±è—ç›®æ¨™/ç‹€æ…‹æ¬„ï¼Œåªç•™é‡é«” + åŠ ç¸½
    start_col = 5
    for i, _h in enumerate(hour_cols):
        vol_col = start_col + i * 3
        tgt_col = vol_col + 1
        st_col = vol_col + 2
        ws_mat.column_dimensions[get_column_letter(tgt_col)].hidden = True
        ws_mat.column_dimensions[get_column_letter(st_col)].hidden = True
        ws_mat.column_dimensions[get_column_letter(vol_col)].width = 10

    sum_col = start_col + len(hour_cols) * 3
    sum_tgt_col = sum_col + 1
    sum_st_col = sum_col + 2
    ws_mat.column_dimensions[get_column_letter(sum_col)].width = 12
    ws_mat.column_dimensions[get_column_letter(sum_tgt_col)].hidden = True
    ws_mat.column_dimensions[get_column_letter(sum_st_col)].hidden = True

    # âœ… æ¢ä»¶æ ¼å¼ï¼šä¾éš±è—ç‹€æ…‹æ¬„ â†’ æŠŠé‡é«”æ¬„ä¸Šè‰²
    max_r = ws_mat.max_row
    for i, _h in enumerate(hour_cols):
        vol_col = start_col + i * 3
        st_col = vol_col + 2

        vol_letter = get_column_letter(vol_col)
        st_letter = get_column_letter(st_col)
        rng = f"{vol_letter}2:{vol_letter}{max_r}"

        ws_mat.conditional_formatting.add(
            rng,
            FormulaRule(formula=[f'${st_letter}2="{STATUS_PASS}"'], fill=fill_ok, stopIfTrue=True),
        )
        ws_mat.conditional_formatting.add(
            rng,
            FormulaRule(formula=[f'${st_letter}2="{STATUS_FAIL}"'], fill=fill_ng, stopIfTrue=True),
        )
        ws_mat.conditional_formatting.add(
            rng,
            FormulaRule(formula=[f'${st_letter}2=""'], fill=fill_na, stopIfTrue=True),
        )

    # åŠ ç¸½æ¬„ä¹Ÿä¸Šè‰²
    sum_letter = get_column_letter(sum_col)
    sum_st_letter = get_column_letter(sum_st_col)
    sum_rng = f"{sum_letter}2:{sum_letter}{max_r}"

    ws_mat.conditional_formatting.add(
        sum_rng,
        FormulaRule(formula=[f'${sum_st_letter}2="{STATUS_PASS}"'], fill=fill_ok, stopIfTrue=True),
    )
    ws_mat.conditional_formatting.add(
        sum_rng,
        FormulaRule(formula=[f'${sum_st_letter}2="{STATUS_FAIL}"'], fill=fill_ng, stopIfTrue=True),
    )
    ws_mat.conditional_formatting.add(
        sum_rng,
        FormulaRule(formula=[f'${sum_st_letter}2=""'], fill=fill_na, stopIfTrue=True),
    )

    out = io.BytesIO()
    wb.save(out)
    return out.getvalue()


def main():
    st.set_page_config(page_title="å¤§è±ç‰©æµ - å‡ºè²¨èª²ï½œå„æ™‚æ®µä½œæ¥­æ•ˆç‡", page_icon="â±ï¸", layout="wide")
    if HAS_COMMON_UI:
        inject_logistics_theme()
        set_page("ğŸ“¦ å‡ºè²¨èª²", "â±ï¸ 29ï½œå„æ™‚æ®µä½œæ¥­æ•ˆç‡")

    st.markdown("### â±ï¸ å„æ™‚æ®µä½œæ¥­æ•ˆç‡ï¼ˆExcelï¼šä¿ç•™å…¬å¼ï¼‹è‰²å¡Šè‡ªå‹•æ›´æ–°ï¼›æ”¯æ´èˆŠ Excelï¼‰")

    fixed_time_map = {
        "èŒƒæ˜ä¿Š": "08:00", "é˜®ç‰å": "08:00", "æèŒ‚éŠ“": "08:00", "æ²³æ–‡å¼·": "08:00",
        "è”¡éº—ç ": "08:00", "æ½˜æ–‡ä¸€": "08:00", "é˜®ä¼Šé»ƒ": "08:00", "è‘‰æ¬²å¼˜": "09:00",
        "é˜®æ­¦ç‰ç„": "08:00", "å³é»ƒé‡‘ç ": "08:30", "æ½˜æ°é’æ±Ÿ": "08:00", "é™³åœ‹æ…¶": "08:30",
        "æ¥Šå¿ƒå¦‚": "08:00", "é˜®ç‘ç¾é»ƒç·£": "08:00", "å‘¨èŠ¸è“": "08:00", "é»æ°ç“Š": "08:00",
        "ç‹æ–‡æ¥·": "08:30", "æ½˜æ°æ…¶å¹³": "08:00", "é˜®æ°ç¾éº—": "08:00", "å²³å­æ†": "08:30",
        "éƒ­é›™ç‡•": "08:30", "é˜®å­Ÿå‹‡": "08:00", "å»–æ°¸æˆ": "08:30", "æ¥Šæµ©å‚‘": "08:30",
        "é»ƒæ—¥åº·": "08:30", "è”£é‡‘å¦®": "08:30", "æŸ´å®¶æ¬£": "08:30", "é‚±æ€æ·": "09:00",
        "ç‹å»ºæˆ": "09:00",
    }

    with st.sidebar:
        st.markdown("### è¨­å®š")
        target_hr = st.number_input("æ¯å°æ™‚ç›®æ¨™ï¼ˆåŠ æ¬ŠPCS/å°æ™‚ï¼‰", min_value=1.0, value=790.0, step=10.0)
        hour_min = st.number_input("èµ·å§‹å°æ™‚", min_value=0, max_value=23, value=8, step=1)

        use_now = st.toggle("ç”¨ç¾åœ¨æ™‚é–“ä½œç‚ºåˆ¤æ–·æˆªæ­¢ï¼ˆå°åŒ—æ™‚é–“ï¼‰", value=True)
        if use_now:
            now = datetime.now(TPE)
        else:
            t_in = st.time_input("åˆ¤æ–·æˆªæ­¢æ™‚é–“ï¼ˆå°åŒ—æ™‚é–“ï¼‰", value=datetime.now(TPE).time())
            now = datetime.combine(date.today(), t_in).replace(tzinfo=TPE)

        st.caption(f"ç›®å‰æ¡ç”¨æ™‚é–“ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')} (Asia/Taipei)")
        auto_calc = st.toggle("ä¸Šå‚³/è¨­å®šè®Šæ›´å¾Œè‡ªå‹•æ›´æ–°", value=True)

    c1, c2 = st.columns(2)
    with c1:
        prod_file = st.file_uploader("â‘  ä¸Šå‚³ã€åŸå§‹ç”Ÿç”¢è³‡æ–™ã€(CSV/Excel)", type=["csv", "xlsx", "xlsm", "xls"])
    with c2:
        mem_file = st.file_uploader("â‘¡ ä¸Šå‚³ã€äººå“¡åå–®ã€(CSV/Excel)", type=["csv", "xlsx", "xlsm", "xls"])

    manual = st.button("ğŸš€ ç«‹å³æ›´æ–°/é‡ç®—", type="primary", use_container_width=True)

    if prod_file is None or mem_file is None:
        st.info("è«‹å…ˆä¸Šå‚³å…©å€‹æª”æ¡ˆï¼šç”Ÿç”¢è³‡æ–™ + äººå“¡åå–®ã€‚")
        return

    prod_sig = _bytes_sig(prod_file.getvalue())
    mem_sig = _bytes_sig(mem_file.getvalue())
    settings_sig = f"{target_hr}-{hour_min}-{use_now}-{now.hour}-{now.minute}"

    last = st.session_state.get("_29_last_sig", None)
    cur_sig = (prod_sig, mem_sig, settings_sig)
    should_run = manual or (auto_calc and (last != cur_sig))
    if not should_run:
        st.caption("ï¼ˆç›®å‰çµæœå·²æ˜¯æœ€æ–°ï¼›å¦‚æœ‰æ›´æ–°æª”æ¡ˆ/è¨­å®šæœƒè‡ªå‹•åŒæ­¥ï¼‰")
        return
    st.session_state["_29_last_sig"] = cur_sig

    try:
        # äººå“¡åå–®
        df_mem_raw = _norm_cols(read_table_robust(mem_file.name, mem_file.getvalue(), label="äººå“¡åå–®æª”æ¡ˆ"))

        line_col_candidates = ["LINEID", "ç·šåˆ¥", "LineID", "LINE Id", "Line Id"]
        line_col = next((c for c in line_col_candidates if c in df_mem_raw.columns), None)
        if line_col is None:
            raise ValueError("äººå“¡åå–®æ‰¾ä¸åˆ°ç·šåˆ¥æ¬„ä½ï¼ˆéœ€è¦ LINEID æˆ– ç·šåˆ¥ï¼‰ã€‚")

        seg_cols = {1: "ç¬¬ä¸€æ®µ", 2: "ç¬¬äºŒæ®µ", 3: "ç¬¬ä¸‰æ®µ", 4: "ç¬¬å››æ®µ"}
        for _, colname in seg_cols.items():
            if colname not in df_mem_raw.columns:
                raise ValueError(f"äººå“¡åå–®ç¼ºå°‘æ¬„ä½ï¼š{colname}ï¼ˆéœ€è¦ ç¬¬ä¸€æ®µï½ç¬¬å››æ®µï¼‰")

        member_list = []
        for _, row in df_mem_raw.iterrows():
            line_id = str(row.get(line_col, "")).strip()
            if not line_id or line_id.lower() == "nan":
                continue
            for zid, colname in seg_cols.items():
                name = row.get(colname, None)
                if pd.notna(name) and str(name).strip() != "":
                    n_str = str(name).strip()
                    st_time = _safe_time(fixed_time_map.get(n_str, "08:00"))
                    member_list.append({"ç·šåˆ¥": line_id, "æ®µæ•¸": zid, "å§“å": n_str, "é–‹å§‹æ™‚é–“": st_time})

        roster_df = pd.DataFrame(member_list)
        if roster_df.empty:
            raise ValueError("äººå“¡åå–®è§£æå¾Œç‚ºç©ºï¼šè«‹ç¢ºèª ç¬¬ä¸€æ®µï½ç¬¬å››æ®µ å…§æœ‰å§“åã€‚")

        roster_df["ç·šåˆ¥"] = clean_line(roster_df["ç·šåˆ¥"])
        roster_df["æ®µæ•¸"] = clean_zone_1to4(roster_df["æ®µæ•¸"])
        roster_df = roster_df[roster_df["æ®µæ•¸"].notna()].copy()
        roster_df = roster_df.drop_duplicates(["ç·šåˆ¥", "æ®µæ•¸"], keep="first").copy()
        roster_df = roster_df[["ç·šåˆ¥", "æ®µæ•¸", "å§“å", "é–‹å§‹æ™‚é–“"]].copy()

        # ç”Ÿç”¢è³‡æ–™ï¼ˆâœ… é€™è£¡å·²æ”¯æ´ .xls å‡æª” TSVï¼‰
        df_raw = read_table_robust(prod_file.name, prod_file.getvalue(), label="ç”Ÿç”¢è³‡æ–™æª”æ¡ˆ")
        df_raw = _norm_cols(df_raw)  # âœ… é¿å…æ¬„ä½å°¾å·´ç©ºç™½

        require_columns(df_raw, ["PICKDATE", "LINEID", "ZONEID", "PACKQTY", "Cweight"], "ç”Ÿç”¢è³‡æ–™æª”æ¡ˆ")

        df_raw["PICKDATE"] = pd.to_datetime(df_raw["PICKDATE"], errors="coerce")
        df_raw = df_raw[df_raw["PICKDATE"].notna()].copy()

        df_raw = df_raw.rename(columns={"LINEID": "ç·šåˆ¥", "ZONEID": "æ®µæ•¸"})
        df_raw["ç·šåˆ¥"] = clean_line(df_raw["ç·šåˆ¥"])
        df_raw["æ®µæ•¸"] = clean_zone_1to4(df_raw["æ®µæ•¸"])
        df_raw = df_raw[df_raw["æ®µæ•¸"].notna()].copy()

        df_raw["PACKQTY"] = pd.to_numeric(df_raw["PACKQTY"], errors="coerce").fillna(0)
        df_raw["Cweight"] = pd.to_numeric(df_raw["Cweight"], errors="coerce").fillna(0)

        # å»é‡
        rid_cols = [c for c in df_raw.columns if c not in ("__rid",)]
        df_raw["__rid"] = pd.util.hash_pandas_object(df_raw[rid_cols], index=False)
        df_raw = df_raw.drop_duplicates("__rid", keep="first").copy()

        df = pd.merge(df_raw, roster_df, on=["ç·šåˆ¥", "æ®µæ•¸"], how="left", validate="m:1")
        df["å§“å"] = df["å§“å"].fillna("æœªè¨­å®š")
        df["é–‹å§‹æ™‚é–“"] = df["é–‹å§‹æ™‚é–“"].fillna("08:00").map(_safe_time)

        df["å°æ™‚"] = df["PICKDATE"].dt.hour
        df["PICK_MIN"] = df["PICKDATE"].dt.hour * 60 + df["PICKDATE"].dt.minute

        st_parts = df["é–‹å§‹æ™‚é–“"].astype(str).str.split(":", n=1, expand=True)
        st_h = pd.to_numeric(st_parts[0], errors="coerce").fillna(8).astype(int)
        st_m = pd.to_numeric(st_parts[1], errors="coerce").fillna(0).astype(int)
        df["é–‹å§‹åˆ†é˜"] = st_h * 60 + st_m

        df["ç´å…¥è¨ˆç®—"] = df["PICK_MIN"] >= df["é–‹å§‹åˆ†é˜"]
        df["æ’é™¤åŸå› "] = np.where(df["ç´å…¥è¨ˆç®—"], "", "æ—©æ–¼é–‹å§‹æ™‚é–“")

        df["åŠ æ¬ŠPCS"] = df["PACKQTY"] * df["Cweight"]

        # Streamlit é¡¯ç¤º
        cur_h, cur_m = now.hour, now.minute
        hour_cols = list(range(int(hour_min), int(cur_h) + 1)) if int(cur_h) >= int(hour_min) else [int(cur_h)]
        base_cols = ["ç·šåˆ¥", "æ®µæ•¸", "å§“å", "é–‹å§‹æ™‚é–“"]

        df_calc = df[df["ç´å…¥è¨ˆç®—"]].copy()
        hourly_sum = df_calc.groupby(base_cols + ["å°æ™‚"], as_index=False)["åŠ æ¬ŠPCS"].sum()
        hourly_sum = hourly_sum.rename(columns={"åŠ æ¬ŠPCS": "ç•¶å°æ™‚åŠ æ¬ŠPCS"})

        keys = roster_df[base_cols].drop_duplicates().copy()
        grid_hours = keys.assign(_k=1).merge(pd.DataFrame({"å°æ™‚": hour_cols, "_k": 1}), on="_k").drop(columns=["_k"])
        hourly_full = grid_hours.merge(hourly_sum, on=base_cols + ["å°æ™‚"], how="left")
        hourly_full["ç•¶å°æ™‚åŠ æ¬ŠPCS"] = pd.to_numeric(hourly_full["ç•¶å°æ™‚åŠ æ¬ŠPCS"], errors="coerce").fillna(0.0)

        parts = hourly_full["é–‹å§‹æ™‚é–“"].astype(str).str.split(":", n=1, expand=True)
        s_h = pd.to_numeric(parts[0], errors="coerce").fillna(8).astype(int)
        s_m = pd.to_numeric(parts[1], errors="coerce").fillna(0).astype(int)
        hh = pd.to_numeric(hourly_full["å°æ™‚"], errors="coerce").fillna(0).astype(int)
        slot = hh.map(lambda x: _slot_minutes(int(x))).astype(int)
        end_m = np.where(hh == cur_h, np.minimum(cur_m, slot), slot).astype(int)

        minutes_worked = np.where(
            hh > cur_h, 0,
            np.where(
                hh < s_h, 0,
                np.where(
                    hh == s_h, np.maximum(0, end_m - s_m),
                    end_m
                )
            )
        ).astype(float)

        hourly_full["æœ¬å°æ™‚æœ‰æ•ˆåˆ†é˜"] = minutes_worked
        hourly_full["æœ¬å°æ™‚ç›®æ¨™"] = (minutes_worked / 60.0) * float(target_hr)
        hourly_full["ç‹€æ…‹"] = np.where(
            hourly_full["æœ¬å°æ™‚æœ‰æ•ˆåˆ†é˜"] <= 0,
            None,
            np.where(hourly_full["ç•¶å°æ™‚åŠ æ¬ŠPCS"] >= hourly_full["æœ¬å°æ™‚ç›®æ¨™"], STATUS_PASS, STATUS_FAIL)
        )

        dist = (
            hourly_full[hourly_full["ç‹€æ…‹"].isin([STATUS_PASS, STATUS_FAIL])]
            .groupby(["ç·šåˆ¥", "å°æ™‚", "ç‹€æ…‹"], as_index=False)
            .size()
            .rename(columns={"size": "count"})
        )

        st.success("è¨ˆç®—å®Œæˆ âœ…ï¼ˆExcelï¼šå…¬å¼ï¼‹è‰²å¡Šæœƒè‡ªå‹•æ›´æ–°ï¼‰")

        eff_hour = int(cur_h)
        lines = sorted(keys["ç·šåˆ¥"].dropna().unique().tolist())
        for line in lines:
            if HAS_COMMON_UI:
                card_open(f"ğŸ“¦ {line}")
            else:
                st.markdown(f"### ğŸ“¦ {line}")

            dist_now = dist[(dist["ç·šåˆ¥"] == line) & (dist["å°æ™‚"] == eff_hour)]
            p, f, rate = _kpi_counts(dist_now)

            a, b, c, d = st.columns(4)
            a.metric("åˆ¤æ–·å°æ™‚", f"{eff_hour} é»")
            b.metric("é”æ¨™ æ®µæ•¸", p)
            c.metric("æœªé”æ¨™ æ®µæ•¸", f)
            d.metric("é”æ¨™ ç‡", (f"{rate:.1f}%" if rate is not None else "â€”"))

            df_line = hourly_full[hourly_full["ç·šåˆ¥"] == line][
                ["ç·šåˆ¥", "æ®µæ•¸", "å§“å", "å°æ™‚", "ç•¶å°æ™‚åŠ æ¬ŠPCS", "æœ¬å°æ™‚ç›®æ¨™", "ç‹€æ…‹"]
            ].copy()
            render_hourly_heatmap(df_line, hour_cols, title=f"{line}ï½œæ¯å°æ™‚ï¼ˆ12/13=30åˆ†ï¼‰")

            if HAS_COMMON_UI:
                card_close()

        # æ˜ç´°è¼¸å‡ºï¼ˆExcel æœƒç”¨å…¬å¼é‡ç®—åŠ æ¬ŠPCSï¼‰
        detail_df = df.copy().sort_values(["ç·šåˆ¥", "æ®µæ•¸", "PICKDATE"]).reset_index(drop=True)
        if "åŠ æ¬ŠPCS" not in detail_df.columns:
            detail_df["åŠ æ¬ŠPCS"] = np.nan

        xlsx_bytes = build_excel_bytes_with_formulas_and_colors(
            detail_df=detail_df,
            roster_df=roster_df,
            hour_cols=hour_cols,
            target_hr=float(target_hr),
            now_h=int(cur_h),
            now_m=int(cur_m),
        )
        filename = f"ç”¢èƒ½æ™‚æ®µ_å…¬å¼_è‰²å¡Š_{datetime.now(TPE).strftime('%H%M')}.xlsx"
        st.download_button(
            "â¬‡ï¸ ä¸‹è¼‰ Excelï¼ˆä¿ç•™å…¬å¼ï¼‹è‰²å¡Šè‡ªå‹•è®Šè‰²ï¼‰",
            data=xlsx_bytes,
            file_name=filename,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )

    except Exception as e:
        st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")


if __name__ == "__main__":
    main()
