# pages/29_å„æ™‚æ®µä½œæ¥­æ•ˆç‡.py
# -*- coding: utf-8 -*-
import io
import os
from io import StringIO
from datetime import datetime, date
from zoneinfo import ZoneInfo

import numpy as np
import pandas as pd
import streamlit as st
import altair as alt
from openpyxl import load_workbook
from openpyxl.styles import PatternFill, Alignment

# ---- å¥—ç”¨å¹³å°é¢¨æ ¼ï¼ˆæœ‰å°±ç”¨ï¼Œæ²’æœ‰å°±é€€å›åŸç”Ÿï¼‰----
try:
    from common_ui import inject_logistics_theme, set_page, card_open, card_close
    HAS_COMMON_UI = True
except Exception:
    HAS_COMMON_UI = False

TPE = ZoneInfo("Asia/Taipei")

STATUS_PASS = "é”æ¨™"
STATUS_FAIL = "æœªé”æ¨™"


# =============================
# è®€æª”
# =============================
def read_table_robust(file_name: str, raw: bytes, label: str = "æª”æ¡ˆ") -> pd.DataFrame:
    ext = os.path.splitext(file_name)[1].lower()

    if ext in (".xlsx", ".xlsm", ".xltx", ".xltm", ".xls"):
        try:
            return pd.read_excel(io.BytesIO(raw))
        except Exception as e:
            raise ValueError(f"{label} è®€å– Excel å¤±æ•—ï¼š{e}")

    encodings = ["utf-8-sig", "utf-8", "cp950", "big5", "ms950", "gb18030", "latin1"]
    seps = [",", "\t", ";", "|"]

    last_err = None
    for enc in encodings:
        for sep in seps:
            try:
                df = pd.read_csv(io.BytesIO(raw), encoding=enc, sep=sep, engine="python", low_memory=False)
                if df.shape[1] <= 1:
                    continue
                return df
            except Exception as e:
                last_err = e

    try:
        text = raw.decode("utf-8", errors="replace")
        df = pd.read_csv(StringIO(text), sep=None, engine="python", low_memory=False)
        if df.shape[1] <= 1:
            raise ValueError("åµæ¸¬ä¸åˆ°æœ‰æ•ˆåˆ†éš”ç¬¦ï¼Œè«‹ç¢ºèªæª”æ¡ˆæ˜¯å¦ç‚ºçœŸæ­£ CSVã€‚")
        return df
    except Exception as e:
        raise ValueError(f"{label} è®€å– CSV å¤±æ•—ï¼ˆå·²å˜—è©¦å¤šç¨®ç·¨ç¢¼/åˆ†éš”ç¬¦ï¼‰ï¼š{last_err} / æœ€çµ‚ï¼š{e}")


def require_columns(df: pd.DataFrame, required: list, label: str):
    missing = [c for c in required if c not in df.columns]
    if missing:
        raise ValueError(f"{label} ç¼ºå°‘æ¬„ä½ï¼š{missing}\nç›®å‰æ¬„ä½ï¼š{list(df.columns)}")


def _norm_cols(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    return df


def clean_line(series: pd.Series) -> pd.Series:
    return series.astype(str).str.strip()


def clean_zone_1to4(series: pd.Series) -> pd.Series:
    z = pd.to_numeric(series, errors="coerce").astype("Int64")
    return z.where(z.between(1, 4, inclusive="both"))


def _safe_time(s: str) -> str:
    s = str(s).strip()
    if not s:
        return "08:00"
    try:
        datetime.strptime(s, "%H:%M")
        return s
    except Exception:
        return "08:00"


# =============================
# Excelï¼šè¼¸å‡ºã€Œç•¶å°æ™‚åŠ æ¬ŠPCSã€ï¼Œé¡è‰²ç”¨é”æ¨™/æœªé”æ¨™
# =============================
def build_excel_bytes_volume(matrix_vol: pd.DataFrame, matrix_stat: pd.DataFrame, hour_cols: list[int]) -> bytes:
    out_df = matrix_vol.copy()
    # ç©ºç™½è™•ç†
    for h in hour_cols:
        if h in out_df.columns:
            out_df[h] = out_df[h].where(pd.notna(out_df[h]), "")

    bio = io.BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        out_df.to_excel(writer, index=False, sheet_name="æ™‚æ®µé‡é«”_é”æ¨™è‰²å¡Š")
    bio.seek(0)

    wb = load_workbook(bio)
    ws = wb.active

    fill_ok = PatternFill(start_color="C6EFCE", end_color="C6EFCE", fill_type="solid")
    fill_ng = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")

    base_cols = ["ç·šåˆ¥", "æ®µæ•¸", "å§“å", "é–‹å§‹æ™‚é–“"]
    min_col = len(base_cols) + 1
    max_col = len(base_cols) + len(hour_cols)

    # è®“æ•¸å­—å¥½çœ‹
    for r in ws.iter_rows(min_row=2, min_col=min_col, max_col=max_col):
        for c in r:
            c.alignment = Alignment(horizontal="center", vertical="center")

    # ä¾ç‹€æ…‹è‘—è‰²
    # matrix_stat èˆ‡ matrix_vol æ¬„ä½ä¸€è‡´ï¼ˆåŒ indexï¼‰
    # é€™è£¡ç›´æ¥ç”¨ DataFrame ä½ç½®å»æ˜ å°„ Excel å„²å­˜æ ¼ï¼ˆè¡Œåˆ—å°é½Šï¼‰
    stat_values = matrix_stat[hour_cols].values.tolist()
    for i, r in enumerate(ws.iter_rows(min_row=2, min_col=min_col, max_col=max_col)):
        for j, c in enumerate(r):
            stat = stat_values[i][j] if i < len(stat_values) and j < len(stat_values[i]) else None
            if stat == STATUS_PASS:
                c.fill = fill_ok
                c.number_format = "0.0000"
            elif stat == STATUS_FAIL:
                c.fill = fill_ng
                c.number_format = "0.0000"
            else:
                # æœªåˆ¤æ–·/æœªåˆ°æ™‚æ®µ -> ä¸ä¸Šè‰²
                pass

    out = io.BytesIO()
    wb.save(out)
    return out.getvalue()


# =============================
# KPI è¨ˆæ•¸
# =============================
def _kpi_counts(dist_df: pd.DataFrame):
    if dist_df is None or dist_df.empty:
        return 0, 0, None
    p = int(dist_df.loc[dist_df["ç‹€æ…‹"] == STATUS_PASS, "count"].sum())
    f = int(dist_df.loc[dist_df["ç‹€æ…‹"] == STATUS_FAIL, "count"].sum())
    rate = (p / (p + f) * 100.0) if (p + f) > 0 else None
    return p, f, rate


# =============================
# é•·æ¢åœ–çŸ©é™£ï¼ˆå–ä»£è¡¨æ ¼ï¼‰
# æ¯ä¸€æ ¼é¡¯ç¤ºã€Œç•¶å°æ™‚åŠ æ¬ŠPCSã€ï¼Œé¡è‰²è¡¨ç¤ºé”æ¨™/æœªé”æ¨™
# =============================
def render_hourly_matrix_bars(df_line: pd.DataFrame, hour_cols: list[int], title: str):
    """
    df_line: columns = æ®µæ•¸, å§“å, å°æ™‚, ç•¶å°æ™‚åŠ æ¬ŠPCS, ç‹€æ…‹
    """
    if df_line is None or df_line.empty:
        st.info("æ­¤ç·šåˆ¥æ²’æœ‰è³‡æ–™å¯å‘ˆç¾ã€‚")
        return

    plot = df_line.copy()
    plot["æ®µæ•¸"] = pd.to_numeric(plot["æ®µæ•¸"], errors="coerce").fillna(0).astype(int)
    plot["row_label"] = plot["æ®µæ•¸"].astype(str) + "æ®µï½œ" + plot["å§“å"].astype(str)
    plot["å°æ™‚"] = pd.to_numeric(plot["å°æ™‚"], errors="coerce").astype(int)

    # é¡¯ç¤ºæ–‡å­—ï¼šé‡é«”ï¼ˆ0 å°±ä¸é¡¯ç¤ºï¼Œé¿å…å¤ªäº‚ï¼‰
    def _fmt(v):
        try:
            v = float(v)
        except Exception:
            return ""
        return "" if abs(v) < 1e-12 else f"{v:.2f}"

    plot["é¡¯ç¤ºé‡"] = plot["ç•¶å°æ™‚åŠ æ¬ŠPCS"].apply(_fmt)

    # é¡è‰²ï¼šé”æ¨™/æœªé”æ¨™/æœªåˆ¤æ–·
    color_cond = alt.condition(
        alt.datum["ç‹€æ…‹"] == STATUS_PASS,
        alt.value("#2E7D32"),
        alt.condition(
            alt.datum["ç‹€æ…‹"] == STATUS_FAIL,
            alt.value("#C62828"),
            alt.value("#D0D5DD"),  # æœªåˆ¤æ–·/æœªåˆ°æ™‚æ®µ
        ),
    )

    base = alt.Chart(plot).encode(
        x=alt.X("å°æ™‚:O", sort=[str(h) for h in hour_cols], title="å°æ™‚"),
        tooltip=[
            alt.Tooltip("row_label:N", title="æ®µæ•¸ï½œå§“å"),
            alt.Tooltip("å°æ™‚:O", title="å°æ™‚"),
            alt.Tooltip("ç•¶å°æ™‚åŠ æ¬ŠPCS:Q", title="ç•¶å°æ™‚åŠ æ¬ŠPCS", format=",.4f"),
            alt.Tooltip("ç‹€æ…‹:N", title="ç‹€æ…‹"),
        ],
    )

    bars = base.mark_bar(size=20).encode(
        y=alt.Y("ç•¶å°æ™‚åŠ æ¬ŠPCS:Q", title="ç•¶å°æ™‚åŠ æ¬ŠPCS"),
        color=color_cond,
    )

    labels = base.mark_text(dy=-10, fontSize=11).encode(
        y=alt.Y("ç•¶å°æ™‚åŠ æ¬ŠPCS:Q"),
        text=alt.Text("é¡¯ç¤ºé‡:N"),
    )

    layered = (bars + labels).properties(height=120)

    # æ¯å€‹äººä¸€åˆ—ï¼ˆæ®µ1~æ®µ4ï¼‰ï¼Œç”¨ facet row
    chart = layered.facet(
        row=alt.Row("row_label:N", sort=alt.SortField(field="æ®µæ•¸", order="ascending"), header=alt.Header(title=None)),
        spacing=8,
    ).resolve_scale(
        y="independent"
    ).properties(
        title=title
    )

    st.altair_chart(chart, use_container_width=True)


def _render_hbar_person(dist_person: pd.DataFrame, title: str):
    if dist_person is None or dist_person.empty:
        st.info("æ²’æœ‰å¯å‘ˆç¾çš„æ©«æ¢åœ–ã€‚")
        return
    labels = dist_person["label"].drop_duplicates().tolist()
    height = min(26 * len(labels) + 40, 520)

    chart = (
        alt.Chart(dist_person)
        .mark_bar()
        .encode(
            y=alt.Y("label:N", sort=alt.SortField(field="total", order="descending"), title="æ®µæ•¸ï½œå§“å"),
            x=alt.X("count:Q", title="æ™‚æ®µæ•¸ï¼ˆå°æ™‚æ ¼æ•¸ï¼‰", stack="zero"),
            color=alt.Color(
                "ç‹€æ…‹:N",
                scale=alt.Scale(domain=[STATUS_PASS, STATUS_FAIL], range=["#2E7D32", "#C62828"]),
                legend=alt.Legend(title="ç‹€æ…‹"),
            ),
            tooltip=[
                alt.Tooltip("label:N", title="æ®µæ•¸ï½œå§“å"),
                alt.Tooltip("ç‹€æ…‹:N"),
                alt.Tooltip("count:Q", title="æ™‚æ®µæ•¸"),
            ],
        )
        .properties(title=title, height=height)
    )
    st.altair_chart(chart, use_container_width=True)


def _render_hbar_lines(dist_line: pd.DataFrame, title: str):
    if dist_line is None or dist_line.empty:
        st.info("æ²’æœ‰å¯å‘ˆç¾çš„å…¨ç·šæ©«æ¢åœ–ã€‚")
        return
    height = min(26 * dist_line["ç·šåˆ¥"].nunique() + 40, 520)
    chart = (
        alt.Chart(dist_line)
        .mark_bar()
        .encode(
            y=alt.Y("ç·šåˆ¥:N", sort=alt.SortField(field="total", order="descending"), title="ç·šåˆ¥"),
            x=alt.X("count:Q", title="æ™‚æ®µæ•¸ï¼ˆå°æ™‚æ ¼æ•¸ï¼‰", stack="zero"),
            color=alt.Color(
                "ç‹€æ…‹:N",
                scale=alt.Scale(domain=[STATUS_PASS, STATUS_FAIL], range=["#2E7D32", "#C62828"]),
                legend=alt.Legend(title="ç‹€æ…‹"),
            ),
            tooltip=[alt.Tooltip("ç·šåˆ¥:N"), alt.Tooltip("ç‹€æ…‹:N"), alt.Tooltip("count:Q", title="æ™‚æ®µæ•¸")],
        )
        .properties(title=title, height=height)
    )
    st.altair_chart(chart, use_container_width=True)


def main():
    st.set_page_config(page_title="å¤§è±ç‰©æµ - å‡ºè²¨èª²ï½œå„æ™‚æ®µä½œæ¥­æ•ˆç‡", page_icon="â±ï¸", layout="wide")
    if HAS_COMMON_UI:
        inject_logistics_theme()
        set_page("ğŸ“¦ å‡ºè²¨èª²", "â±ï¸ 29ï½œå„æ™‚æ®µä½œæ¥­æ•ˆç‡")

    st.markdown("### â±ï¸ å„æ™‚æ®µä½œæ¥­æ•ˆç‡ï¼ˆé‡é«”ï¼‹é”æ¨™è‰²å¡Šï½œæ®µ1~æ®µ4ï¼‰")

    fixed_time_map = {
        'èŒƒæ˜ä¿Š': '08:00', 'é˜®ç‰å': '08:00', 'æèŒ‚éŠ“': '08:00', 'æ²³æ–‡å¼·': '08:00',
        'è”¡éº—ç ': '08:00', 'æ½˜æ–‡ä¸€': '08:00', 'é˜®ä¼Šé»ƒ': '08:00', 'è‘‰æ¬²å¼˜': '09:00',
        'é˜®æ­¦ç‰ç„': '08:00', 'å³é»ƒé‡‘ç ': '08:30', 'æ½˜æ°é’æ±Ÿ': '08:00', 'é™³åœ‹æ…¶': '08:30',
        'æ¥Šå¿ƒå¦‚': '08:00', 'é˜®ç‘ç¾é»ƒç·£': '08:00', 'å‘¨èŠ¸è“': '08:00', 'é»æ°ç“Š': '08:00',
        'ç‹æ–‡æ¥·': '08:30', 'æ½˜æ°æ…¶å¹³': '08:00', 'é˜®æ°ç¾éº—': '08:00', 'å²³å­æ†': '08:30',
        'éƒ­é›™ç‡•': '08:30', 'é˜®å­Ÿå‹‡': '08:00', 'å»–æ°¸æˆ':'08:30', 'æ¥Šæµ©å‚‘':'08:30', 'é»ƒæ—¥åº·':'08:30',
        'è”£é‡‘å¦®':'08:30', 'æŸ´å®¶æ¬£':'08:30',
    }

    with st.sidebar:
        st.markdown("### è¨­å®š")
        target_hr = st.number_input("æ¯å°æ™‚ç›®æ¨™ï¼ˆåŠ æ¬ŠPCS/å°æ™‚ï¼‰", min_value=1.0, value=790.0, step=10.0)
        hour_min = st.number_input("èµ·å§‹å°æ™‚", min_value=0, max_value=23, value=8, step=1)

        use_now = st.toggle("ç”¨ç¾åœ¨æ™‚é–“ä½œç‚ºåˆ¤æ–·æˆªæ­¢ï¼ˆå°åŒ—æ™‚é–“ï¼‰", value=True)
        if use_now:
            now = datetime.now(TPE)
        else:
            t_in = st.time_input("åˆ¤æ–·æˆªæ­¢æ™‚é–“ï¼ˆå°åŒ—æ™‚é–“ï¼‰", value=datetime.now(TPE).time())
            now = datetime.combine(date.today(), t_in).replace(tzinfo=TPE)

        st.caption(f"ç›®å‰æ¡ç”¨æ™‚é–“ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')} (Asia/Taipei)")

    c1, c2 = st.columns(2)
    with c1:
        prod_file = st.file_uploader("â‘  ä¸Šå‚³ã€åŸå§‹ç”Ÿç”¢è³‡æ–™ã€(CSV/Excel)", type=["csv", "xlsx", "xlsm", "xls"])
    with c2:
        mem_file = st.file_uploader("â‘¡ ä¸Šå‚³ã€äººå“¡åå–®ã€(CSV/Excel)", type=["csv", "xlsx", "xlsm", "xls"])

    run = st.button("ğŸš€ é–‹å§‹è¨ˆç®—", type="primary", use_container_width=True)
    if not run:
        return
    if prod_file is None or mem_file is None:
        st.error("è«‹å…ˆä¸Šå‚³å…©å€‹æª”æ¡ˆï¼šç”Ÿç”¢è³‡æ–™ + äººå“¡åå–®ã€‚")
        return

    try:
        # 1) äººå“¡åå–®
        df_mem_raw = _norm_cols(read_table_robust(mem_file.name, mem_file.getvalue(), label="äººå“¡åå–®æª”æ¡ˆ"))
        line_col_candidates = ["LINEID", "ç·šåˆ¥", "LineID", "LINE Id", "Line Id"]
        line_col = next((c for c in line_col_candidates if c in df_mem_raw.columns), None)
        if line_col is None:
            raise ValueError("äººå“¡åå–®æ‰¾ä¸åˆ°ç·šåˆ¥æ¬„ä½ï¼ˆéœ€è¦ LINEID æˆ– ç·šåˆ¥ï¼‰ã€‚")

        seg_cols = {1: "ç¬¬ä¸€æ®µ", 2: "ç¬¬äºŒæ®µ", 3: "ç¬¬ä¸‰æ®µ", 4: "ç¬¬å››æ®µ"}
        for _, colname in seg_cols.items():
            if colname not in df_mem_raw.columns:
                raise ValueError(f"äººå“¡åå–®ç¼ºå°‘æ¬„ä½ï¼š{colname}ï¼ˆéœ€è¦ ç¬¬ä¸€æ®µï½ç¬¬å››æ®µï¼‰")

        member_list = []
        for _, row in df_mem_raw.iterrows():
            line_id = str(row.get(line_col, "")).strip()
            if not line_id or line_id.lower() == "nan":
                continue
            for zid, colname in seg_cols.items():
                name = row.get(colname, None)
                if pd.notna(name) and str(name).strip() != "":
                    n_str = str(name).strip()
                    st_time = _safe_time(fixed_time_map.get(n_str, "08:00"))
                    member_list.append({"ç·šåˆ¥": line_id, "æ®µæ•¸": zid, "å§“å": n_str, "é–‹å§‹æ™‚é–“": st_time})

        df_members = pd.DataFrame(member_list)
        if df_members.empty:
            raise ValueError("äººå“¡åå–®è§£æå¾Œç‚ºç©ºï¼šè«‹ç¢ºèª ç¬¬ä¸€æ®µï½ç¬¬å››æ®µ å…§æœ‰å§“åã€‚")

        df_members["ç·šåˆ¥"] = clean_line(df_members["ç·šåˆ¥"])
        df_members["æ®µæ•¸"] = clean_zone_1to4(df_members["æ®µæ•¸"])
        df_members = df_members[df_members["æ®µæ•¸"].notna()].copy()
        df_members = df_members.drop_duplicates(["ç·šåˆ¥", "æ®µæ•¸"], keep="first").copy()

        # 2) ç”Ÿç”¢è³‡æ–™ï¼ˆå»é‡å¾ŒåŠ æ¬ŠPCSï¼‰
        df_raw = read_table_robust(prod_file.name, prod_file.getvalue(), label="ç”Ÿç”¢è³‡æ–™æª”æ¡ˆ")
        require_columns(df_raw, ["PICKDATE", "LINEID", "ZONEID", "PACKQTY", "Cweight"], "ç”Ÿç”¢è³‡æ–™æª”æ¡ˆ")

        df_raw["PICKDATE"] = pd.to_datetime(df_raw["PICKDATE"], errors="coerce")
        df_raw = df_raw[df_raw["PICKDATE"].notna()].copy()

        df_raw = df_raw.rename(columns={"LINEID": "ç·šåˆ¥", "ZONEID": "æ®µæ•¸"})
        df_raw["ç·šåˆ¥"] = clean_line(df_raw["ç·šåˆ¥"])
        df_raw["æ®µæ•¸"] = clean_zone_1to4(df_raw["æ®µæ•¸"])
        df_raw = df_raw[df_raw["æ®µæ•¸"].notna()].copy()
        if df_raw.empty:
            raise ValueError("ç”Ÿç”¢è³‡æ–™æ¸…ç†å¾Œç‚ºç©ºï¼šè«‹ç¢ºèª ZONEID æ˜¯å¦ç‚º 1~4ã€‚")

        df_raw["PACKQTY"] = pd.to_numeric(df_raw["PACKQTY"], errors="coerce").fillna(0)
        df_raw["Cweight"] = pd.to_numeric(df_raw["Cweight"], errors="coerce").fillna(0)
        df_raw["åŠ æ¬ŠPCS"] = df_raw["PACKQTY"] * df_raw["Cweight"]

        rid_cols = [c for c in df_raw.columns if c not in ("å§“å", "é–‹å§‹æ™‚é–“", "å°æ™‚", "__rid")]
        df_raw["__rid"] = pd.util.hash_pandas_object(df_raw[rid_cols], index=False)

        df = pd.merge(df_raw, df_members, on=["ç·šåˆ¥", "æ®µæ•¸"], how="left", validate="m:1")
        df["å§“å"] = df["å§“å"].fillna("æœªè¨­å®š")
        df["é–‹å§‹æ™‚é–“"] = df["é–‹å§‹æ™‚é–“"].fillna("08:00").map(_safe_time)
        df = df.drop_duplicates("__rid", keep="first").copy()

        # é–‹å§‹æ™‚é–“éæ¿¾ï¼ˆåŸå§‹ç´€éŒ„ï¼‰
        pick_minutes = df["PICKDATE"].dt.hour * 60 + df["PICKDATE"].dt.minute
        st_parts = df["é–‹å§‹æ™‚é–“"].astype(str).str.split(":", n=1, expand=True)
        st_h = pd.to_numeric(st_parts[0], errors="coerce").fillna(8).astype(int)
        st_m = pd.to_numeric(st_parts[1], errors="coerce").fillna(0).astype(int)
        st_minutes = st_h * 60 + st_m
        df = df[pick_minutes >= st_minutes].copy()
        if df.empty:
            raise ValueError("å¥—ç”¨é–‹å§‹æ™‚é–“éæ¿¾å¾Œæ²’æœ‰è³‡æ–™ï¼šè«‹ç¢ºèª PICKDATE èˆ‡é–‹å§‹æ™‚é–“è¨­å®šã€‚")

        # 3) æ¯å°æ™‚åŠ ç¸½ï¼ˆç•¶å°æ™‚é‡ï¼‰
        df["å°æ™‚"] = df["PICKDATE"].dt.hour
        base_cols = ["ç·šåˆ¥", "æ®µæ•¸", "å§“å", "é–‹å§‹æ™‚é–“"]

        hourly_sum = df.groupby(base_cols + ["å°æ™‚"], as_index=False)["åŠ æ¬ŠPCS"].sum()
        hourly_sum = hourly_sum.rename(columns={"åŠ æ¬ŠPCS": "ç•¶å°æ™‚åŠ æ¬ŠPCS"})

        # âœ… è£œé½Šæ¯å°æ™‚ï¼ˆå°±ç®—è©²å°æ™‚æ²’æœ‰è³‡æ–™ï¼Œä¹Ÿè¦æœ‰ 0 æ‰èƒ½åˆ¤æ–·æœªé”æ¨™ï¼‰
        cur_h, cur_m = now.hour, now.minute
        hour_cols = list(range(int(hour_min), int(cur_h) + 1))

        keys = df_members[base_cols].drop_duplicates().copy()
        grid_hours = keys.assign(_k=1).merge(pd.DataFrame({"å°æ™‚": hour_cols, "_k": 1}), on="_k").drop(columns=["_k"])

        hourly_full = grid_hours.merge(hourly_sum, on=base_cols + ["å°æ™‚"], how="left")
        hourly_full["ç•¶å°æ™‚åŠ æ¬ŠPCS"] = pd.to_numeric(hourly_full["ç•¶å°æ™‚åŠ æ¬ŠPCS"], errors="coerce").fillna(0.0)

        hourly_full = hourly_full.sort_values(base_cols + ["å°æ™‚"]).reset_index(drop=True)
        hourly_full["ç´¯è¨ˆå¯¦éš›é‡"] = hourly_full.groupby(["ç·šåˆ¥", "æ®µæ•¸", "å§“å"])["ç•¶å°æ™‚åŠ æ¬ŠPCS"].cumsum()

        # åˆ¤æ–·é”æ¨™/æœªé”æ¨™ï¼ˆç”¨ç´¯è¨ˆï¼‰
        st_parts2 = hourly_full["é–‹å§‹æ™‚é–“"].astype(str).str.split(":", n=1, expand=True)
        s_h = pd.to_numeric(st_parts2[0], errors="coerce").fillna(8).astype(float)
        s_m = pd.to_numeric(st_parts2[1], errors="coerce").fillna(0).astype(float)
        h = hourly_full["å°æ™‚"].astype(float)

        elapsed = np.where(
            h < cur_h,
            (h - s_h + 1.0) - (s_m / 60.0),
            np.where(
                h == cur_h,
                (h - s_h) + ((cur_m - s_m) / 60.0),
                np.nan
            )
        )

        # âœ… elapsed <= 0 ä»£è¡¨å°šæœªé–‹å§‹ï¼ˆä¾‹å¦‚ 08:30 åœ¨ 08:00ï¼‰
        valid = (~np.isnan(elapsed)) & (elapsed > 0)
        target = np.where(valid, elapsed * float(target_hr), np.nan)

        status = np.where(
            ~valid,
            None,
            np.where(hourly_full["ç´¯è¨ˆå¯¦éš›é‡"].values >= target, STATUS_PASS, STATUS_FAIL)
        )
        hourly_full["ç‹€æ…‹"] = status

        # ä¾› KPI è¨ˆæ•¸ä½¿ç”¨
        dist = (
            hourly_full[hourly_full["ç‹€æ…‹"].isin([STATUS_PASS, STATUS_FAIL])]
            .groupby(["ç·šåˆ¥", "å°æ™‚", "ç‹€æ…‹"], as_index=False)
            .size()
            .rename(columns={"size": "count"})
            .sort_values(["ç·šåˆ¥", "å°æ™‚", "ç‹€æ…‹"])
        )

        # ä¸‹è¼‰ç”¨ï¼šè¼¸å‡ºã€Œç•¶å°æ™‚åŠ æ¬ŠPCSã€çŸ©é™£ + ç‹€æ…‹çŸ©é™£ï¼ˆç”¨æ–¼ä¸Šè‰²ï¼‰
        matrix_vol = hourly_full.pivot(index=base_cols, columns="å°æ™‚", values="ç•¶å°æ™‚åŠ æ¬ŠPCS").reset_index()
        matrix_stat = hourly_full.pivot(index=base_cols, columns="å°æ™‚", values="ç‹€æ…‹").reset_index()

        matrix_vol.columns = [int(c) if str(c).isdigit() else c for c in matrix_vol.columns]
        matrix_stat.columns = [int(c) if str(c).isdigit() else c for c in matrix_stat.columns]
        for hh in hour_cols:
            if hh not in matrix_vol.columns:
                matrix_vol[hh] = np.nan
            if hh not in matrix_stat.columns:
                matrix_stat[hh] = None
        matrix_vol = matrix_vol[base_cols + hour_cols]
        matrix_stat = matrix_stat[base_cols + hour_cols]

        st.success("è¨ˆç®—å®Œæˆ âœ…ï¼ˆæ¯æ ¼é¡¯ç¤ºï¼šç•¶å°æ™‚åŠ æ¬ŠPCSï¼›é¡è‰²ï¼šé”æ¨™/æœªé”æ¨™ï¼‰")
        st.markdown("## ğŸ“Š KPIï¼ˆæ¯ç·šï¼šæ®µ1~æ®µ4ï¼‰")

        eff_hour = int(cur_h)
        lines = sorted(keys["ç·šåˆ¥"].dropna().unique().tolist())

        for line in lines:
            if HAS_COMMON_UI:
                card_open(f"ğŸ“¦ {line}")
            else:
                st.markdown(f"### ğŸ“¦ {line}")

            dist_now = dist[(dist["ç·šåˆ¥"] == line) & (dist["å°æ™‚"] == eff_hour)]
            p, f, rate = _kpi_counts(dist_now)

            c1, c2, c3, c4 = st.columns(4)
            c1.metric("åˆ¤æ–·å°æ™‚", f"{eff_hour} é»")
            c2.metric("é”æ¨™ æ®µæ•¸", p)
            c3.metric("æœªé”æ¨™ æ®µæ•¸", f)
            c4.metric("é”æ¨™ ç‡", (f"{rate:.1f}%" if rate is not None else "â€”"))

            # âœ… ç”¨é•·æ¢åœ–çŸ©é™£å–ä»£è¡¨æ ¼
            df_line = hourly_full[hourly_full["ç·šåˆ¥"] == line][["æ®µæ•¸", "å§“å", "å°æ™‚", "ç•¶å°æ™‚åŠ æ¬ŠPCS", "ç‹€æ…‹"]].copy()
            render_hourly_matrix_bars(df_line, hour_cols, title=f"{line}ï½œæ®µ1~æ®µ4 Ã— æ¯å°æ™‚ï¼ˆé‡é«”ï¼‹é”æ¨™è‰²å¡Šï¼‰")

            # ä½ åŸæœ¬è¦çš„æ©«æ¢åœ–ï¼ˆä»ä¿ç•™ï¼‰
            dist_person = (
                hourly_full[(hourly_full["ç·šåˆ¥"] == line) & (hourly_full["ç‹€æ…‹"].isin([STATUS_PASS, STATUS_FAIL]))]
                .groupby(["æ®µæ•¸", "å§“å", "ç‹€æ…‹"], as_index=False)
                .size()
                .rename(columns={"size": "count"})
            )
            if not dist_person.empty:
                dist_person["label"] = dist_person["æ®µæ•¸"].astype(int).astype(str) + "æ®µï½œ" + dist_person["å§“å"].astype(str)
                totals = dist_person.groupby("label", as_index=False)["count"].sum().rename(columns={"count": "total"})
                dist_person = dist_person.merge(totals, on="label", how="left")

            st.markdown("#### ğŸ“Œ æ©«æ¢åœ–ï¼ˆæ®µ1~æ®µ4ï½œå§“åï¼šé”æ¨™/æœªé”æ¨™æ¬¡æ•¸ï¼‰")
            _render_hbar_person(dist_person, title=f"{line}ï½œæ®µ1~æ®µ4ï¼ˆå«å§“åï¼‰é”æ¨™/æœªé”æ¨™ æ¬¡æ•¸")

            if HAS_COMMON_UI:
                card_close()

        # å…¨ä½œæ¥­ç·šç¸½å’Œ
        st.markdown("## ğŸ§¾ å…¨ä½œæ¥­ç·šç¸½å’Œï¼ˆé”æ¨™/æœªé”æ¨™ï¼‰")
        dist_all_now = dist[dist["å°æ™‚"] == eff_hour]
        p_all, f_all, rate_all = _kpi_counts(dist_all_now)

        c1, c2, c3, c4 = st.columns(4)
        c1.metric("åˆ¤æ–·å°æ™‚", f"{eff_hour} é»")
        c2.metric("é”æ¨™ æ®µæ•¸", p_all)
        c3.metric("æœªé”æ¨™ æ®µæ•¸", f_all)
        c4.metric("é”æ¨™ ç‡", (f"{rate_all:.1f}%" if rate_all is not None else "â€”"))

        dist_lines = (
            hourly_full[hourly_full["ç‹€æ…‹"].isin([STATUS_PASS, STATUS_FAIL])]
            .groupby(["ç·šåˆ¥", "ç‹€æ…‹"], as_index=False)
            .size()
            .rename(columns={"size": "count"})
        )
        if not dist_lines.empty:
            totals = dist_lines.groupby("ç·šåˆ¥", as_index=False)["count"].sum().rename(columns={"count": "total"})
            dist_lines = dist_lines.merge(totals, on="ç·šåˆ¥", how="left")

        st.markdown("#### ğŸ“Œ æ©«æ¢åœ–ï¼ˆå„ç·šï¼šé”æ¨™/æœªé”æ¨™æ¬¡æ•¸ï¼‰")
        _render_hbar_lines(dist_lines, title="å…¨ä½œæ¥­ç·šï½œå„ç·šé”æ¨™/æœªé”æ¨™ æ¬¡æ•¸")

        # ä¸‹è¼‰ Excelï¼ˆç¾åœ¨è¼¸å‡ºé‡é«”ï¼Œé¡è‰²è¡¨ç¤ºé”æ¨™/æœªé”æ¨™ï¼‰
        st.markdown("## â¬‡ï¸ ä¸‹è¼‰")
        xlsx_bytes = build_excel_bytes_volume(matrix_vol, matrix_stat, hour_cols)
        filename = f"ç”¢èƒ½æ™‚æ®µ_é‡é«”é”æ¨™è‰²å¡Š_{datetime.now(TPE).strftime('%H%M')}.xlsx"
        st.download_button(
            "â¬‡ï¸ ä¸‹è¼‰ Excelï¼ˆæ¯æ ¼=ç•¶å°æ™‚åŠ æ¬ŠPCSï¼Œé¡è‰²=é”æ¨™/æœªé”æ¨™ï¼‰",
            data=xlsx_bytes,
            file_name=filename,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )

    except Exception as e:
        st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")


if __name__ == "__main__":
    main()
