# pages/29_å„æ™‚æ®µä½œæ¥­æ•ˆç‡.py
# -*- coding: utf-8 -*-
import io
import os
from io import StringIO
from datetime import datetime, date
from zoneinfo import ZoneInfo

import numpy as np
import pandas as pd
import streamlit as st
import altair as alt
from openpyxl import Workbook
from openpyxl.utils import get_column_letter
from openpyxl.styles import PatternFill, Alignment, Font

# ---- å¥—ç”¨å¹³å°é¢¨æ ¼ï¼ˆæœ‰å°±ç”¨ï¼Œæ²’æœ‰å°±é€€å›åŸç”Ÿï¼‰----
try:
    from common_ui import inject_logistics_theme, set_page, card_open, card_close
    HAS_COMMON_UI = True
except Exception:
    HAS_COMMON_UI = False

TPE = ZoneInfo("Asia/Taipei")

STATUS_PASS = "é”æ¨™"
STATUS_FAIL = "æœªé”æ¨™"
STATUS_NA = "æœªåˆ¤æ–·"

# âœ… ç‰¹æ®Šå·¥æ™‚ï¼ˆåˆ†é˜ï¼‰ï¼š12é»ã€13é»åªæœ‰ 30 åˆ†é˜
WORK_MINUTES_BY_HOUR = {12: 30, 13: 30}


# =============================
# è®€æª”ï¼šCSV/Excel å¼·éŸŒè®€å–
# =============================
def read_table_robust(file_name: str, raw: bytes, label: str = "æª”æ¡ˆ") -> pd.DataFrame:
    ext = os.path.splitext(file_name)[1].lower()

    if ext in (".xlsx", ".xlsm", ".xltx", ".xltm", ".xls"):
        try:
            return pd.read_excel(io.BytesIO(raw))
        except Exception as e:
            raise ValueError(f"{label} è®€å– Excel å¤±æ•—ï¼š{e}")

    encodings = ["utf-8-sig", "utf-8", "cp950", "big5", "ms950", "gb18030", "latin1"]
    seps = [",", "\t", ";", "|"]

    last_err = None
    for enc in encodings:
        for sep in seps:
            try:
                df = pd.read_csv(io.BytesIO(raw), encoding=enc, sep=sep, engine="python", low_memory=False)
                if df.shape[1] <= 1:
                    continue
                return df
            except Exception as e:
                last_err = e

    try:
        text = raw.decode("utf-8", errors="replace")
        df = pd.read_csv(StringIO(text), sep=None, engine="python", low_memory=False)
        if df.shape[1] <= 1:
            raise ValueError("åµæ¸¬ä¸åˆ°æœ‰æ•ˆåˆ†éš”ç¬¦ï¼Œè«‹ç¢ºèªæª”æ¡ˆæ˜¯å¦ç‚ºçœŸæ­£ CSVã€‚")
        return df
    except Exception as e:
        raise ValueError(f"{label} è®€å– CSV å¤±æ•—ï¼ˆå·²å˜—è©¦å¤šç¨®ç·¨ç¢¼/åˆ†éš”ç¬¦ï¼‰ï¼š{last_err} / æœ€çµ‚ï¼š{e}")


def require_columns(df: pd.DataFrame, required: list, label: str):
    missing = [c for c in required if c not in df.columns]
    if missing:
        raise ValueError(f"{label} ç¼ºå°‘æ¬„ä½ï¼š{missing}\nç›®å‰æ¬„ä½ï¼š{list(df.columns)}")


def _norm_cols(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    return df


def clean_line(series: pd.Series) -> pd.Series:
    return series.astype(str).str.strip()


def clean_zone_1to4(series: pd.Series) -> pd.Series:
    z = pd.to_numeric(series, errors="coerce").astype("Int64")
    return z.where(z.between(1, 4, inclusive="both"))


def _safe_time(s: str) -> str:
    s = str(s).strip()
    if not s:
        return "08:00"
    try:
        datetime.strptime(s, "%H:%M")
        return s
    except Exception:
        return "08:00"


def _bytes_sig(b: bytes) -> str:
    if b is None:
        return "0"
    n = len(b)
    head = b[:128]
    tail = b[-128:] if n >= 128 else b
    return f"{n}-{hash(head)}-{hash(tail)}"


def _slot_minutes(hour: int) -> int:
    return int(WORK_MINUTES_BY_HOUR.get(int(hour), 60))


# =============================
# KPI è¨ˆæ•¸ï¼ˆæŸå°æ™‚ï¼‰
# =============================
def _kpi_counts(dist_df: pd.DataFrame):
    if dist_df is None or dist_df.empty:
        return 0, 0, None
    p = int(dist_df.loc[dist_df["ç‹€æ…‹"] == STATUS_PASS, "count"].sum())
    f = int(dist_df.loc[dist_df["ç‹€æ…‹"] == STATUS_FAIL, "count"].sum())
    rate = (p / (p + f) * 100.0) if (p + f) > 0 else None
    return p, f, rate


# =============================
# Heatmapï¼ˆStreamlit é¡¯ç¤ºç”¨ï¼šPython è¨ˆç®—ï¼‰
# =============================
def render_hourly_heatmap(df_line_hourly: pd.DataFrame, hour_cols, title: str):
    if df_line_hourly is None or df_line_hourly.empty:
        st.info("æ²’æœ‰å¯å‘ˆç¾çš„åœ–ã€‚")
        return

    hour_cols = [int(h) for h in list(hour_cols)]
    plot = df_line_hourly.copy()

    plot["æ®µæ•¸"] = pd.to_numeric(plot["æ®µæ•¸"], errors="coerce").fillna(0).astype(int)
    plot["å°æ™‚"] = pd.to_numeric(plot["å°æ™‚"], errors="coerce").fillna(0).astype(int)
    plot["ç•¶å°æ™‚åŠ æ¬ŠPCS"] = pd.to_numeric(plot["ç•¶å°æ™‚åŠ æ¬ŠPCS"], errors="coerce").fillna(0.0)
    plot["æœ¬å°æ™‚ç›®æ¨™"] = pd.to_numeric(plot["æœ¬å°æ™‚ç›®æ¨™"], errors="coerce").fillna(0.0)

    plot["label"] = plot["æ®µæ•¸"].astype(str) + "æ®µï½œ" + plot["å§“å"].astype(str)
    plot["ç‹€æ…‹_è‰²"] = plot["ç‹€æ…‹"].fillna(STATUS_NA)
    plot["é¡¯ç¤ºé‡"] = plot["ç•¶å°æ™‚åŠ æ¬ŠPCS"].apply(lambda x: "" if abs(float(x)) < 1e-12 else f"{float(x):.2f}")

    order = (
        plot[["label", "æ®µæ•¸", "å§“å"]]
        .drop_duplicates()
        .sort_values(["æ®µæ•¸", "å§“å"])["label"]
        .tolist()
    )

    color_enc = alt.Color(
        "ç‹€æ…‹_è‰²:N",
        scale=alt.Scale(domain=[STATUS_PASS, STATUS_FAIL, STATUS_NA], range=["#2E7D32", "#C62828", "#D0D5DD"]),
        legend=alt.Legend(title="ç‹€æ…‹"),
    )

    base = alt.Chart(plot).encode(
        x=alt.X("å°æ™‚:O", sort=[str(h) for h in hour_cols], title="æ¯å°æ™‚"),
        y=alt.Y("label:N", sort=order, title="æ®µæ•¸ï½œå§“å"),
        tooltip=[
            alt.Tooltip("ç·šåˆ¥:N", title="ç·šåˆ¥"),
            alt.Tooltip("label:N", title="æ®µæ•¸ï½œå§“å"),
            alt.Tooltip("å°æ™‚:O", title="å°æ™‚"),
            alt.Tooltip("ç•¶å°æ™‚åŠ æ¬ŠPCS:Q", title="ç•¶å°æ™‚åŠ æ¬ŠPCS", format=",.4f"),
            alt.Tooltip("æœ¬å°æ™‚ç›®æ¨™:Q", title="æœ¬å°æ™‚ç›®æ¨™", format=",.2f"),
            alt.Tooltip("ç‹€æ…‹:N", title="ç‹€æ…‹"),
        ],
    )

    rect = base.mark_rect(cornerRadius=4).encode(color=color_enc)
    text = base.mark_text(fontSize=12, fontWeight=900).encode(text="é¡¯ç¤ºé‡:N")

    n_rows = max(1, plot["label"].nunique())
    height = min(42 * n_rows + 80, 900)
    st.altair_chart((rect + text).properties(title=title, height=height), use_container_width=True)


# =============================
# âœ… è¼¸å‡º Excelï¼ˆä¿ç•™å…¬å¼ï¼‰
#   - Sheet1: å®Œæ•´æ˜ç´°ï¼ˆåŠ æ¬ŠPCSç”¨å…¬å¼ï¼‰
#   - Sheet2: æ™‚æ®µé‡é«”ï¼ˆæ¯æ ¼SUMIFSï¼›åŠ ç¸½SUMï¼›ç‹€æ…‹IFï¼‰
# =============================
def build_excel_bytes_with_formulas(
    detail_df: pd.DataFrame,
    roster_df: pd.DataFrame,  # base_cols: ç·šåˆ¥ æ®µæ•¸ å§“å é–‹å§‹æ™‚é–“
    hour_cols: list[int],
    target_hr: float,
) -> bytes:
    wb = Workbook()
    ws_detail = wb.active
    ws_detail.title = "å®Œæ•´æ˜ç´°_å»é‡å¾Œ"

    ws_mat = wb.create_sheet("æ™‚æ®µé‡é«”_å…¬å¼")

    # ---- å¯«å…¥ Sheet1ï¼šå®Œæ•´æ˜ç´° ----
    # å¿…é ˆæ¬„ï¼šPICKDATE ç·šåˆ¥ æ®µæ•¸ PACKQTY Cweight  (å§“å/é–‹å§‹æ™‚é–“/ç´å…¥è¨ˆç®—/æ’é™¤åŸå›  ä¹Ÿæœƒå¯«)
    # å…¶ä¸­ åŠ æ¬ŠPCS ç”¨å…¬å¼ =PACKQTY*Cweight
    cols = list(detail_df.columns)
    for c_idx, col in enumerate(cols, start=1):
        ws_detail.cell(row=1, column=c_idx, value=col).font = Font(bold=True)

    # æ‰¾ PACKQTY / Cweight æ¬„ä½ä½ç½®
    try:
        col_pack = cols.index("PACKQTY") + 1
        col_w = cols.index("Cweight") + 1
    except Exception:
        col_pack, col_w = None, None

    for r_idx, row in enumerate(detail_df.itertuples(index=False), start=2):
        for c_idx, col in enumerate(cols, start=1):
            v = getattr(row, col) if hasattr(row, col) else None
            ws_detail.cell(row=r_idx, column=c_idx, value=v)

        # è‹¥æœ‰åŠ æ¬ŠPCSæ¬„ä½ -> ç”¨å…¬å¼è¦†è“‹
        if "åŠ æ¬ŠPCS" in cols and col_pack and col_w:
            col_aw = cols.index("åŠ æ¬ŠPCS") + 1
            p_cell = f"{get_column_letter(col_pack)}{r_idx}"
            w_cell = f"{get_column_letter(col_w)}{r_idx}"
            ws_detail.cell(row=r_idx, column=col_aw, value=f"={p_cell}*{w_cell}")
            ws_detail.cell(row=r_idx, column=col_aw).number_format = "0.0000"

    # åŸºæœ¬å°é½Š
    for row in ws_detail.iter_rows(min_row=1, max_row=ws_detail.max_row, min_col=1, max_col=ws_detail.max_column):
        for cell in row:
            cell.alignment = Alignment(vertical="center")

    # ---- Sheet2ï¼šæ™‚æ®µé‡é«”ï¼ˆå…¬å¼ï¼‰----
    base_cols = ["ç·šåˆ¥", "æ®µæ•¸", "å§“å", "é–‹å§‹æ™‚é–“"]
    mat_headers = base_cols + [str(h) for h in hour_cols] + ["åŠ ç¸½", "åŠ ç¸½ç‹€æ…‹"]
    for c_idx, col in enumerate(mat_headers, start=1):
        ws_mat.cell(row=1, column=c_idx, value=col).font = Font(bold=True)

    # detail sheet æ¬„ä½å­—æ¯å®šä½
    detail_header_to_col = {ws_detail.cell(row=1, column=i).value: i for i in range(1, ws_detail.max_column + 1)}

    # SUMIFS éœ€è¦çš„æ¬„ï¼šç·šåˆ¥ æ®µæ•¸ PICKDATE(å–å°æ™‚) åŠ æ¬ŠPCS ç´å…¥è¨ˆç®—
    # æˆ‘å€‘ç”¨ helper æ¬„ä½ï¼šæ˜ç´°ä¸­å·²æœ‰ "å°æ™‚" æ¬„ï¼Œè‹¥æ²’æœ‰å°±ç”¨ HOUR(PICKDATE) å…¬å¼åšä¸€æ¬„
    # é€™è£¡ç°¡åŒ–ï¼šè¦æ±‚ detail_df å…§å·²å« "å°æ™‚"ï¼ˆæˆ‘å€‘åœ¨å‰é¢æœƒåŠ ï¼‰
    need = ["ç·šåˆ¥", "æ®µæ•¸", "å°æ™‚", "åŠ æ¬ŠPCS", "ç´å…¥è¨ˆç®—"]
    for k in need:
        if k not in detail_header_to_col:
            raise ValueError(f"æ˜ç´°ç¼ºå°‘æ¬„ä½ã€Œ{k}ã€ï¼Œç„¡æ³•å»ºç«‹ SUMIFS å…¬å¼ã€‚")

    d_line = get_column_letter(detail_header_to_col["ç·šåˆ¥"])
    d_zone = get_column_letter(detail_header_to_col["æ®µæ•¸"])
    d_hour = get_column_letter(detail_header_to_col["å°æ™‚"])
    d_aw = get_column_letter(detail_header_to_col["åŠ æ¬ŠPCS"])
    d_in = get_column_letter(detail_header_to_col["ç´å…¥è¨ˆç®—"])

    d_first = 2
    d_last = ws_detail.max_row

    # roster_df å¯«å…¥ + æ¯å°æ™‚å…¬å¼
    for r_idx, row in enumerate(roster_df.itertuples(index=False), start=2):
        ws_mat.cell(row=r_idx, column=1, value=row.ç·šåˆ¥)
        ws_mat.cell(row=r_idx, column=2, value=int(row.æ®µæ•¸))
        ws_mat.cell(row=r_idx, column=3, value=str(row.å§“å))
        ws_mat.cell(row=r_idx, column=4, value=str(row.é–‹å§‹æ™‚é–“))

        # æ¯å°æ™‚ SUMIFSï¼ˆåªåŠ ç´å…¥è¨ˆç®—=TRUEï¼‰
        for j, h in enumerate(hour_cols, start=5):
            # SUMIFS(åŠ æ¬ŠPCS, ç·šåˆ¥=æœ¬åˆ—ç·šåˆ¥, æ®µæ•¸=æœ¬åˆ—æ®µæ•¸, å°æ™‚=h, ç´å…¥è¨ˆç®—=TRUE)
            line_cell = f"$A{r_idx}"
            zone_cell = f"$B{r_idx}"
            formula = (
                f'=SUMIFS('
                f'\'{ws_detail.title}\'!${d_aw}${d_first}:${d_aw}${d_last},'
                f'\'{ws_detail.title}\'!${d_line}${d_first}:${d_line}${d_last},{line_cell},'
                f'\'{ws_detail.title}\'!${d_zone}${d_first}:${d_zone}${d_last},{zone_cell},'
                f'\'{ws_detail.title}\'!${d_hour}${d_first}:${d_hour}${d_last},{h},'
                f'\'{ws_detail.title}\'!${d_in}${d_first}:${d_in}${d_last},TRUE)'
            )
            ws_mat.cell(row=r_idx, column=j, value=formula)
            ws_mat.cell(row=r_idx, column=j).number_format = "0.0000"

        # åŠ ç¸½ï¼ˆSUMï¼‰
        first_hour_col = 5
        last_hour_col = 4 + len(hour_cols)
        rng = f"{get_column_letter(first_hour_col)}{r_idx}:{get_column_letter(last_hour_col)}{r_idx}"
        ws_mat.cell(row=r_idx, column=last_hour_col + 1, value=f"=SUM({rng})")
        ws_mat.cell(row=r_idx, column=last_hour_col + 1).number_format = "0.0000"

        # åŠ ç¸½ç‹€æ…‹ï¼šç”¨ã€Œå„å°æ™‚ç›®æ¨™åŠ ç¸½ã€åˆ¤æ–·ï¼ˆå…¬å¼ï¼‰
        # ç›®æ¨™ï¼šæ¯å°æ™‚ 790*(æœ‰æ•ˆåˆ†é˜/60)ï¼›é€™è£¡ç”¨å›ºå®šè¦å‰‡ï¼šä¸€èˆ¬=790ï¼Œ12/13=790/2
        # å› ç‚ºæ¯å€‹äººé–‹å§‹æ™‚é–“ä¸åŒï¼Œç²¾æº–çš„ã€Œæœ‰æ•ˆåˆ†é˜ã€éœ€è¦å¾ˆè¤‡é›œå…¬å¼ï¼›
        # âœ… é€™è£¡æŒ‰ä½ ç›®å‰è¦å‰‡åšã€Œæ•´é»ç›®æ¨™ã€ï¼šæ¯å€‹å°æ™‚å›ºå®š 790ï¼ˆ12/13=395ï¼‰ã€‚
        # ï¼ˆä½ è‹¥è¦æŠŠé–‹å§‹æ™‚é–“åˆ†é˜ä¹Ÿç´å…¥ Excel å…¬å¼ï¼Œæˆ‘ä¹Ÿèƒ½å†å‡ç´šï¼‰
        target_terms = []
        for h in hour_cols:
            mins = _slot_minutes(h)
            target = target_hr * (mins / 60.0)
            target_terms.append(str(round(target, 6)))
        target_sum_formula = "+".join(target_terms) if target_terms else "0"
        sum_cell = f"{get_column_letter(last_hour_col + 1)}{r_idx}"
        ws_mat.cell(
            row=r_idx,
            column=last_hour_col + 2,
            value=f'=IF({sum_cell}>=({target_sum_formula}),"{STATUS_PASS}","{STATUS_FAIL}")'
        )

    # åŸºæœ¬å°é½Š
    for row in ws_mat.iter_rows(min_row=1, max_row=ws_mat.max_row, min_col=1, max_col=ws_mat.max_column):
        for cell in row:
            cell.alignment = Alignment(horizontal="center", vertical="center")

    # ---- ä¸‹è¼‰ bytes ----
    out = io.BytesIO()
    wb.save(out)
    return out.getvalue()


def main():
    st.set_page_config(page_title="å¤§è±ç‰©æµ - å‡ºè²¨èª²ï½œå„æ™‚æ®µä½œæ¥­æ•ˆç‡", page_icon="â±ï¸", layout="wide")
    if HAS_COMMON_UI:
        inject_logistics_theme()
        set_page("ğŸ“¦ å‡ºè²¨èª²", "â±ï¸ 29ï½œå„æ™‚æ®µä½œæ¥­æ•ˆç‡")

    st.markdown("### â±ï¸ å„æ™‚æ®µä½œæ¥­æ•ˆç‡ï¼ˆä¿ç•™å®Œæ•´æ˜ç´°ï¼‹è¨ˆç®—å…¬å¼ï¼›Excel å…¬å¼ä¸å­˜å€¼ï¼‰")

    fixed_time_map = {
        "èŒƒæ˜ä¿Š": "08:00",
        "é˜®ç‰å": "08:00",
        "æèŒ‚éŠ“": "08:00",
        "æ²³æ–‡å¼·": "08:00",
        "è”¡éº—ç ": "08:00",
        "æ½˜æ–‡ä¸€": "08:00",
        "é˜®ä¼Šé»ƒ": "08:00",
        "è‘‰æ¬²å¼˜": "09:00",
        "é˜®æ­¦ç‰ç„": "08:00",
        "å³é»ƒé‡‘ç ": "08:30",
        "æ½˜æ°é’æ±Ÿ": "08:00",
        "é™³åœ‹æ…¶": "08:30",
        "æ¥Šå¿ƒå¦‚": "08:00",
        "é˜®ç‘ç¾é»ƒç·£": "08:00",
        "å‘¨èŠ¸è“": "08:00",
        "é»æ°ç“Š": "08:00",
        "ç‹æ–‡æ¥·": "08:30",
        "æ½˜æ°æ…¶å¹³": "08:00",
        "é˜®æ°ç¾éº—": "08:00",
        "å²³å­æ†": "08:30",
        "éƒ­é›™ç‡•": "08:30",
        "é˜®å­Ÿå‹‡": "08:00",
        "å»–æ°¸æˆ": "08:30",
        "æ¥Šæµ©å‚‘": "08:30",
        "é»ƒæ—¥åº·": "08:30",
        "è”£é‡‘å¦®": "08:30",
        "æŸ´å®¶æ¬£": "08:30",
        "é‚±æ€æ·": "09:00",
        "ç‹å»ºæˆ": "09:00",
    }

    with st.sidebar:
        st.markdown("### è¨­å®š")
        target_hr = st.number_input("æ¯å°æ™‚ç›®æ¨™ï¼ˆåŠ æ¬ŠPCS/å°æ™‚ï¼‰", min_value=1.0, value=790.0, step=10.0)
        hour_min = st.number_input("èµ·å§‹å°æ™‚", min_value=0, max_value=23, value=8, step=1)

        use_now = st.toggle("ç”¨ç¾åœ¨æ™‚é–“ä½œç‚ºåˆ¤æ–·æˆªæ­¢ï¼ˆå°åŒ—æ™‚é–“ï¼‰", value=True)
        if use_now:
            now = datetime.now(TPE)
        else:
            t_in = st.time_input("åˆ¤æ–·æˆªæ­¢æ™‚é–“ï¼ˆå°åŒ—æ™‚é–“ï¼‰", value=datetime.now(TPE).time())
            now = datetime.combine(date.today(), t_in).replace(tzinfo=TPE)

        st.caption(f"ç›®å‰æ¡ç”¨æ™‚é–“ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')} (Asia/Taipei)")
        auto_calc = st.toggle("ä¸Šå‚³/è¨­å®šè®Šæ›´å¾Œè‡ªå‹•æ›´æ–°", value=True)

    c1, c2 = st.columns(2)
    with c1:
        prod_file = st.file_uploader("â‘  ä¸Šå‚³ã€åŸå§‹ç”Ÿç”¢è³‡æ–™ã€(CSV/Excel)", type=["csv", "xlsx", "xlsm", "xls"])
    with c2:
        mem_file = st.file_uploader("â‘¡ ä¸Šå‚³ã€äººå“¡åå–®ã€(CSV/Excel)", type=["csv", "xlsx", "xlsm", "xls"])

    manual = st.button("ğŸš€ ç«‹å³æ›´æ–°/é‡ç®—", type="primary", use_container_width=True)

    if prod_file is None or mem_file is None:
        st.info("è«‹å…ˆä¸Šå‚³å…©å€‹æª”æ¡ˆï¼šç”Ÿç”¢è³‡æ–™ + äººå“¡åå–®ã€‚")
        return

    prod_sig = _bytes_sig(prod_file.getvalue())
    mem_sig = _bytes_sig(mem_file.getvalue())
    settings_sig = f"{target_hr}-{hour_min}-{use_now}-{now.hour}-{now.minute}"

    last = st.session_state.get("_29_last_sig", None)
    cur_sig = (prod_sig, mem_sig, settings_sig)
    should_run = manual or (auto_calc and (last != cur_sig))
    if not should_run:
        st.caption("ï¼ˆç›®å‰çµæœå·²æ˜¯æœ€æ–°ï¼›å¦‚æœ‰æ›´æ–°æª”æ¡ˆ/è¨­å®šæœƒè‡ªå‹•åŒæ­¥ï¼‰")
        return
    st.session_state["_29_last_sig"] = cur_sig

    try:
        # ========= äººå“¡åå–® =========
        df_mem_raw = _norm_cols(read_table_robust(mem_file.name, mem_file.getvalue(), label="äººå“¡åå–®æª”æ¡ˆ"))

        line_col_candidates = ["LINEID", "ç·šåˆ¥", "LineID", "LINE Id", "Line Id"]
        line_col = next((c for c in line_col_candidates if c in df_mem_raw.columns), None)
        if line_col is None:
            raise ValueError("äººå“¡åå–®æ‰¾ä¸åˆ°ç·šåˆ¥æ¬„ä½ï¼ˆéœ€è¦ LINEID æˆ– ç·šåˆ¥ï¼‰ã€‚")

        seg_cols = {1: "ç¬¬ä¸€æ®µ", 2: "ç¬¬äºŒæ®µ", 3: "ç¬¬ä¸‰æ®µ", 4: "ç¬¬å››æ®µ"}
        for _, colname in seg_cols.items():
            if colname not in df_mem_raw.columns:
                raise ValueError(f"äººå“¡åå–®ç¼ºå°‘æ¬„ä½ï¼š{colname}ï¼ˆéœ€è¦ ç¬¬ä¸€æ®µï½ç¬¬å››æ®µï¼‰")

        member_list = []
        for _, row in df_mem_raw.iterrows():
            line_id = str(row.get(line_col, "")).strip()
            if not line_id or line_id.lower() == "nan":
                continue
            for zid, colname in seg_cols.items():
                name = row.get(colname, None)
                if pd.notna(name) and str(name).strip() != "":
                    n_str = str(name).strip()
                    st_time = _safe_time(fixed_time_map.get(n_str, "08:00"))
                    member_list.append({"ç·šåˆ¥": line_id, "æ®µæ•¸": zid, "å§“å": n_str, "é–‹å§‹æ™‚é–“": st_time})

        roster_df = pd.DataFrame(member_list)
        if roster_df.empty:
            raise ValueError("äººå“¡åå–®è§£æå¾Œç‚ºç©ºï¼šè«‹ç¢ºèª ç¬¬ä¸€æ®µï½ç¬¬å››æ®µ å…§æœ‰å§“åã€‚")

        roster_df["ç·šåˆ¥"] = clean_line(roster_df["ç·šåˆ¥"])
        roster_df["æ®µæ•¸"] = clean_zone_1to4(roster_df["æ®µæ•¸"])
        roster_df = roster_df[roster_df["æ®µæ•¸"].notna()].copy()
        roster_df = roster_df.drop_duplicates(["ç·šåˆ¥", "æ®µæ•¸"], keep="first").copy()
        roster_df = roster_df[["ç·šåˆ¥", "æ®µæ•¸", "å§“å", "é–‹å§‹æ™‚é–“"]].copy()

        # ========= ç”Ÿç”¢è³‡æ–™ =========
        df_raw = read_table_robust(prod_file.name, prod_file.getvalue(), label="ç”Ÿç”¢è³‡æ–™æª”æ¡ˆ")
        require_columns(df_raw, ["PICKDATE", "LINEID", "ZONEID", "PACKQTY", "Cweight"], "ç”Ÿç”¢è³‡æ–™æª”æ¡ˆ")

        df_raw["PICKDATE"] = pd.to_datetime(df_raw["PICKDATE"], errors="coerce")
        df_raw = df_raw[df_raw["PICKDATE"].notna()].copy()

        df_raw = df_raw.rename(columns={"LINEID": "ç·šåˆ¥", "ZONEID": "æ®µæ•¸"})
        df_raw["ç·šåˆ¥"] = clean_line(df_raw["ç·šåˆ¥"])
        df_raw["æ®µæ•¸"] = clean_zone_1to4(df_raw["æ®µæ•¸"])
        df_raw = df_raw[df_raw["æ®µæ•¸"].notna()].copy()

        df_raw["PACKQTY"] = pd.to_numeric(df_raw["PACKQTY"], errors="coerce").fillna(0)
        df_raw["Cweight"] = pd.to_numeric(df_raw["Cweight"], errors="coerce").fillna(0)

        # âœ… å»é‡æŒ‡ç´‹
        rid_cols = [c for c in df_raw.columns if c not in ("__rid",)]
        df_raw["__rid"] = pd.util.hash_pandas_object(df_raw[rid_cols], index=False)
        df_raw = df_raw.drop_duplicates("__rid", keep="first").copy()

        # åˆä½µå§“å/é–‹å§‹æ™‚é–“ï¼ˆç”¨æ–¼ UI é¡¯ç¤ºèˆ‡ Excel SUMIFS Keyï¼‰
        df = pd.merge(df_raw, roster_df, on=["ç·šåˆ¥", "æ®µæ•¸"], how="left", validate="m:1")
        df["å§“å"] = df["å§“å"].fillna("æœªè¨­å®š")
        df["é–‹å§‹æ™‚é–“"] = df["é–‹å§‹æ™‚é–“"].fillna("08:00").map(_safe_time)

        # âœ… æ˜ç´°æ¬„ä½ï¼šå°æ™‚ã€ç´å…¥è¨ˆç®—
        df["å°æ™‚"] = df["PICKDATE"].dt.hour
        df["PICK_MIN"] = df["PICKDATE"].dt.hour * 60 + df["PICKDATE"].dt.minute
        st_parts = df["é–‹å§‹æ™‚é–“"].astype(str).str.split(":", n=1, expand=True)
        st_h = pd.to_numeric(st_parts[0], errors="coerce").fillna(8).astype(int)
        st_m = pd.to_numeric(st_parts[1], errors="coerce").fillna(0).astype(int)
        df["é–‹å§‹åˆ†é˜"] = st_h * 60 + st_m
        df["ç´å…¥è¨ˆç®—"] = df["PICK_MIN"] >= df["é–‹å§‹åˆ†é˜"]
        df["æ’é™¤åŸå› "] = np.where(df["ç´å…¥è¨ˆç®—"], "", "æ—©æ–¼é–‹å§‹æ™‚é–“")

        # âœ… Streamlit é¡¯ç¤ºç”¨ï¼ˆPythonè¨ˆç®—ï¼‰åŠ æ¬ŠPCS
        df["åŠ æ¬ŠPCS"] = df["PACKQTY"] * df["Cweight"]

        # ========= Streamlit é¡¯ç¤ºç”¨ï¼šæ¯å°æ™‚å½™ç¸½ + ç‹€æ…‹ =========
        cur_h, cur_m = now.hour, now.minute
        hour_cols = list(range(int(hour_min), int(cur_h) + 1)) if int(cur_h) >= int(hour_min) else [int(cur_h)]
        base_cols = ["ç·šåˆ¥", "æ®µæ•¸", "å§“å", "é–‹å§‹æ™‚é–“"]

        df_calc = df[df["ç´å…¥è¨ˆç®—"]].copy()
        hourly_sum = df_calc.groupby(base_cols + ["å°æ™‚"], as_index=False)["åŠ æ¬ŠPCS"].sum()
        hourly_sum = hourly_sum.rename(columns={"åŠ æ¬ŠPCS": "ç•¶å°æ™‚åŠ æ¬ŠPCS"})

        keys = roster_df[base_cols].drop_duplicates().copy()
        grid_hours = keys.assign(_k=1).merge(pd.DataFrame({"å°æ™‚": hour_cols, "_k": 1}), on="_k").drop(columns=["_k"])
        hourly_full = grid_hours.merge(hourly_sum, on=base_cols + ["å°æ™‚"], how="left")
        hourly_full["ç•¶å°æ™‚åŠ æ¬ŠPCS"] = pd.to_numeric(hourly_full["ç•¶å°æ™‚åŠ æ¬ŠPCS"], errors="coerce").fillna(0.0)

        parts = hourly_full["é–‹å§‹æ™‚é–“"].astype(str).str.split(":", n=1, expand=True)
        s_h = pd.to_numeric(parts[0], errors="coerce").fillna(8).astype(int)
        s_m = pd.to_numeric(parts[1], errors="coerce").fillna(0).astype(int)
        hh = pd.to_numeric(hourly_full["å°æ™‚"], errors="coerce").fillna(0).astype(int)
        slot = hh.map(lambda x: _slot_minutes(int(x))).astype(int)
        end_m = np.where(hh == cur_h, np.minimum(cur_m, slot), slot).astype(int)

        minutes_worked = np.where(
            hh > cur_h, 0,
            np.where(
                hh < s_h, 0,
                np.where(
                    hh == s_h, np.maximum(0, end_m - s_m),
                    end_m
                )
            )
        ).astype(float)

        hourly_full["æœ¬å°æ™‚æœ‰æ•ˆåˆ†é˜"] = minutes_worked
        hourly_full["æœ¬å°æ™‚ç›®æ¨™"] = (minutes_worked / 60.0) * float(target_hr)
        hourly_full["ç‹€æ…‹"] = np.where(
            hourly_full["æœ¬å°æ™‚æœ‰æ•ˆåˆ†é˜"] <= 0,
            None,
            np.where(hourly_full["ç•¶å°æ™‚åŠ æ¬ŠPCS"] >= hourly_full["æœ¬å°æ™‚ç›®æ¨™"], STATUS_PASS, STATUS_FAIL)
        )

        dist = (
            hourly_full[hourly_full["ç‹€æ…‹"].isin([STATUS_PASS, STATUS_FAIL])]
            .groupby(["ç·šåˆ¥", "å°æ™‚", "ç‹€æ…‹"], as_index=False)
            .size()
            .rename(columns={"size": "count"})
        )

        st.success("è¨ˆç®—å®Œæˆ âœ…ï¼ˆä¸‹è¼‰ Excel å°‡ä¿ç•™å…¬å¼ï¼‰")

        # ---- é¡¯ç¤ºæ¯ç·šå€å¡Š ----
        eff_hour = int(cur_h)
        lines = sorted(keys["ç·šåˆ¥"].dropna().unique().tolist())
        for line in lines:
            if HAS_COMMON_UI:
                card_open(f"ğŸ“¦ {line}")
            else:
                st.markdown(f"### ğŸ“¦ {line}")

            dist_now = dist[(dist["ç·šåˆ¥"] == line) & (dist["å°æ™‚"] == eff_hour)]
            p, f, rate = _kpi_counts(dist_now)
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("åˆ¤æ–·å°æ™‚", f"{eff_hour} é»")
            c2.metric("é”æ¨™ æ®µæ•¸", p)
            c3.metric("æœªé”æ¨™ æ®µæ•¸", f)
            c4.metric("é”æ¨™ ç‡", (f"{rate:.1f}%" if rate is not None else "â€”"))

            df_line = hourly_full[hourly_full["ç·šåˆ¥"] == line][
                ["ç·šåˆ¥", "æ®µæ•¸", "å§“å", "å°æ™‚", "ç•¶å°æ™‚åŠ æ¬ŠPCS", "æœ¬å°æ™‚ç›®æ¨™", "ç‹€æ…‹"]
            ].copy()
            render_hourly_heatmap(df_line, hour_cols, title=f"{line}ï½œæ¯å°æ™‚ï¼ˆ12/13=30åˆ†ï¼‰")

            if HAS_COMMON_UI:
                card_close()

        # ---- æº–å‚™æ˜ç´°è¼¸å‡ºï¼ˆåŠ æ¬ŠPCSæ¬„ä½æ”¹æˆç©ºï¼Œè®“ Excel å…¬å¼å¡«ï¼‰----
        detail_df = df.copy()
        detail_df = detail_df.sort_values(["ç·šåˆ¥", "æ®µæ•¸", "PICKDATE"]).reset_index(drop=True)

        # ç¢ºä¿æ¬„ä½å­˜åœ¨ä¸”é †åºåˆç†
        if "åŠ æ¬ŠPCS" not in detail_df.columns:
            detail_df["åŠ æ¬ŠPCS"] = np.nan

        # ä¸‹è¼‰ Excelï¼ˆå«å…¬å¼ï¼‰
        xlsx_bytes = build_excel_bytes_with_formulas(
            detail_df=detail_df,
            roster_df=roster_df,
            hour_cols=hour_cols,
            target_hr=float(target_hr),
        )
        filename = f"ç”¢èƒ½æ™‚æ®µ_ä¿ç•™å…¬å¼_{datetime.now(TPE).strftime('%H%M')}.xlsx"
        st.download_button(
            "â¬‡ï¸ ä¸‹è¼‰ Excelï¼ˆå®Œæ•´æ˜ç´°+çŸ©é™£çš†ä¿ç•™å…¬å¼ï¼‰",
            data=xlsx_bytes,
            file_name=filename,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )

    except Exception as e:
        st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")


if __name__ == "__main__":
    main()
