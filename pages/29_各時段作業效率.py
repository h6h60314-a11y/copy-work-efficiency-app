# pages/29_å„æ™‚æ®µä½œæ¥­æ•ˆç‡.py
# -*- coding: utf-8 -*-
import io
import os
from io import StringIO
from datetime import datetime, date, time as dtime
from zoneinfo import ZoneInfo

import numpy as np
import pandas as pd
import streamlit as st
from openpyxl import load_workbook
from openpyxl.styles import PatternFill

# ---- å¥—ç”¨å¹³å°é¢¨æ ¼ï¼ˆæœ‰å°±ç”¨ï¼Œæ²’æœ‰å°±é€€å›åŸç”Ÿï¼‰----
try:
    from common_ui import inject_logistics_theme, set_page
    HAS_COMMON_UI = True
except Exception:
    HAS_COMMON_UI = False

TPE = ZoneInfo("Asia/Taipei")


# =============================
# å¼·éŸŒè®€æª”ï¼šCSV/Excel è‡ªå‹•è™•ç†ç·¨ç¢¼/åˆ†éš”ç¬¦
# =============================
def read_table_robust(file_name: str, raw: bytes, label: str = "æª”æ¡ˆ") -> pd.DataFrame:
    ext = os.path.splitext(file_name)[1].lower()

    # Excel
    if ext in (".xlsx", ".xlsm", ".xltx", ".xltm", ".xls"):
        try:
            return pd.read_excel(io.BytesIO(raw))
        except Exception as e:
            raise ValueError(f"{label} è®€å– Excel å¤±æ•—ï¼š{e}")

    # CSVï¼šå¤šç·¨ç¢¼ + å¤šåˆ†éš”ç¬¦
    encodings = ["utf-8-sig", "utf-8", "cp950", "big5", "ms950", "gb18030", "latin1"]
    seps = [",", "\t", ";", "|"]

    last_err = None
    for enc in encodings:
        for sep in seps:
            try:
                df = pd.read_csv(io.BytesIO(raw), encoding=enc, sep=sep, engine="python", low_memory=False)
                if df.shape[1] <= 1:
                    continue
                return df
            except Exception as e:
                last_err = e

    # æœ€å¾Œæ‰‹æ®µï¼šbytes -> utf-8 replaceï¼Œå†è‡ªå‹•åˆ†éš”
    try:
        text = raw.decode("utf-8", errors="replace")
        df = pd.read_csv(StringIO(text), sep=None, engine="python", low_memory=False)
        if df.shape[1] <= 1:
            raise ValueError("åµæ¸¬ä¸åˆ°æœ‰æ•ˆåˆ†éš”ç¬¦ï¼Œè«‹ç¢ºèªæª”æ¡ˆæ˜¯å¦ç‚ºçœŸæ­£ CSVã€‚")
        return df
    except Exception as e:
        raise ValueError(f"{label} è®€å– CSV å¤±æ•—ï¼ˆå·²å˜—è©¦å¤šç¨®ç·¨ç¢¼/åˆ†éš”ç¬¦ï¼‰ï¼š{last_err} / æœ€çµ‚ï¼š{e}")


def require_columns(df: pd.DataFrame, required: list, label: str):
    missing = [c for c in required if c not in df.columns]
    if missing:
        raise ValueError(f"{label} ç¼ºå°‘æ¬„ä½ï¼š{missing}\nç›®å‰æ¬„ä½ï¼š{list(df.columns)}")


def _norm_cols(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    return df


def clean_line(series: pd.Series) -> pd.Series:
    return series.astype(str).str.strip()


def clean_zone_1to4(series: pd.Series) -> pd.Series:
    z = pd.to_numeric(series, errors="coerce").astype("Int64")
    return z.where(z.between(1, 4, inclusive="both"))


def _safe_time(s: str) -> str:
    s = str(s).strip()
    if not s:
        return "08:00"
    try:
        datetime.strptime(s, "%H:%M")
        return s
    except Exception:
        return "08:00"


def build_excel_bytes(matrix: pd.DataFrame, hour_cols: list[int]) -> bytes:
    bio = io.BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        matrix.to_excel(writer, index=False, sheet_name="å„æ™‚æ®µä½œæ¥­æ•ˆç‡")
    bio.seek(0)

    wb = load_workbook(bio)
    ws = wb.active

    fill_ok = PatternFill(start_color="C6EFCE", end_color="C6EFCE", fill_type="solid")
    fill_ng = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")

    # base_cols: ç·šåˆ¥, æ®µæ•¸, å§“å, é–‹å§‹æ™‚é–“ -> 4 æ¬„
    min_col = 5
    max_col = 4 + len(hour_cols)

    for r in ws.iter_rows(min_row=2, min_col=min_col, max_col=max_col):
        for c in r:
            if c.value and "|" in str(c.value):
                val, stat = str(c.value).split("|", 1)
                try:
                    c.value = round(float(val), 4)
                except Exception:
                    c.value = None
                    continue
                c.number_format = "0.0000"
                c.fill = fill_ok if stat == "PASS" else fill_ng

    out = io.BytesIO()
    wb.save(out)
    return out.getvalue()


def main():
    st.set_page_config(page_title="å¤§è±ç‰©æµ - å‡ºè²¨èª²ï½œå„æ™‚æ®µä½œæ¥­æ•ˆç‡", page_icon="â±ï¸", layout="wide")
    if HAS_COMMON_UI:
        inject_logistics_theme()
        set_page("ğŸ“¦ å‡ºè²¨èª²", "â±ï¸ 29ï½œå„æ™‚æ®µä½œæ¥­æ•ˆç‡")

    st.markdown("### â±ï¸ å„æ™‚æ®µä½œæ¥­æ•ˆç‡ï¼ˆå»é‡å¾ŒåŠ æ¬ŠPCSï¼‰")

    # --- å›ºå®šäººå“¡é–‹å§‹æ™‚é–“è¡¨ ---
    fixed_time_map = {
        'èŒƒæ˜ä¿Š': '08:00', 'é˜®ç‰å': '08:00', 'æèŒ‚éŠ“': '08:00', 'æ²³æ–‡å¼·': '08:00',
        'è”¡éº—ç ': '08:00', 'æ½˜æ–‡ä¸€': '08:00', 'é˜®ä¼Šé»ƒ': '08:00', 'è‘‰æ¬²å¼˜': '09:00',
        'é˜®æ­¦ç‰ç„': '08:00', 'å³é»ƒé‡‘ç ': '08:30', 'æ½˜æ°é’æ±Ÿ': '08:00', 'é™³åœ‹æ…¶': '08:30',
        'æ¥Šå¿ƒå¦‚': '08:00', 'é˜®ç‘ç¾é»ƒç·£': '08:00', 'å‘¨èŠ¸è“': '08:00', 'é»æ°ç“Š': '08:00',
        'ç‹æ–‡æ¥·': '08:30', 'æ½˜æ°æ…¶å¹³': '08:00', 'é˜®æ°ç¾éº—': '08:00', 'å²³å­æ†': '08:30',
        'éƒ­é›™ç‡•': '08:30', 'é˜®å­Ÿå‹‡': '08:00', 'å»–æ°¸æˆ':'08:30', 'æ¥Šæµ©å‚‘':'08:30', 'é»ƒæ—¥åº·':'08:30',
        'è”£é‡‘å¦®':'08:30', 'æŸ´å®¶æ¬£':'08:30',
    }

    with st.sidebar:
        st.markdown("### è¨­å®š")
        target_hr = st.number_input("æ¯å°æ™‚ç›®æ¨™ï¼ˆåŠ æ¬ŠPCS/å°æ™‚ï¼‰", min_value=1.0, value=790.0, step=10.0)
        hour_min = st.number_input("èµ·å§‹å°æ™‚", min_value=0, max_value=23, value=8, step=1)

        use_now = st.toggle("ç”¨ç¾åœ¨æ™‚é–“ä½œç‚ºåˆ¤æ–·æˆªæ­¢ï¼ˆå°åŒ—æ™‚é–“ï¼‰", value=True)

        if use_now:
            now = datetime.now(TPE)  # âœ… é‡è¦ï¼šç”¨å°åŒ—æ™‚é–“
        else:
            t_in = st.time_input("åˆ¤æ–·æˆªæ­¢æ™‚é–“ï¼ˆå°åŒ—æ™‚é–“ï¼‰", value=datetime.now(TPE).time())
            now = datetime.combine(date.today(), t_in).replace(tzinfo=TPE)

        st.caption(f"ç›®å‰æ¡ç”¨æ™‚é–“ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')} (Asia/Taipei)")

    c1, c2 = st.columns(2)
    with c1:
        prod_file = st.file_uploader("â‘  ä¸Šå‚³ã€åŸå§‹ç”Ÿç”¢è³‡æ–™ã€(CSV/Excel)", type=["csv", "xlsx", "xlsm", "xls"])
    with c2:
        mem_file = st.file_uploader("â‘¡ ä¸Šå‚³ã€äººå“¡åå–®ã€(CSV/Excel)", type=["csv", "xlsx", "xlsm", "xls"])

    run = st.button("ğŸš€ é–‹å§‹è¨ˆç®—", type="primary", use_container_width=True)

    if not run:
        return
    if prod_file is None or mem_file is None:
        st.error("è«‹å…ˆä¸Šå‚³å…©å€‹æª”æ¡ˆï¼šç”Ÿç”¢è³‡æ–™ + äººå“¡åå–®ã€‚")
        return

    try:
        # =========================================================
        # 1) äººå“¡åå–®ï¼šLINEID + ç¬¬ä¸€æ®µ~ç¬¬å››æ®µ => æ®µæ•¸=ZONEID(1~4)
        # =========================================================
        df_mem_raw = _norm_cols(read_table_robust(mem_file.name, mem_file.getvalue(), label="äººå“¡åå–®æª”æ¡ˆ"))

        line_col_candidates = ["LINEID", "ç·šåˆ¥", "LineID", "LINE Id", "Line Id"]
        line_col = next((c for c in line_col_candidates if c in df_mem_raw.columns), None)
        if line_col is None:
            raise ValueError("äººå“¡åå–®æ‰¾ä¸åˆ°ç·šåˆ¥æ¬„ä½ï¼ˆéœ€è¦ LINEID æˆ– ç·šåˆ¥ï¼‰ã€‚")

        seg_cols = {1: "ç¬¬ä¸€æ®µ", 2: "ç¬¬äºŒæ®µ", 3: "ç¬¬ä¸‰æ®µ", 4: "ç¬¬å››æ®µ"}
        for _, colname in seg_cols.items():
            if colname not in df_mem_raw.columns:
                raise ValueError(f"äººå“¡åå–®ç¼ºå°‘æ¬„ä½ï¼š{colname}ï¼ˆéœ€è¦ ç¬¬ä¸€æ®µï½ç¬¬å››æ®µï¼‰")

        member_list = []
        for _, row in df_mem_raw.iterrows():
            line_id = str(row.get(line_col, "")).strip()
            if not line_id or line_id.lower() == "nan":
                continue

            for zid, colname in seg_cols.items():
                name = row.get(colname, None)
                if pd.notna(name) and str(name).strip() != "":
                    n_str = str(name).strip()
                    st_time = _safe_time(fixed_time_map.get(n_str, "08:00"))
                    member_list.append({"ç·šåˆ¥": line_id, "æ®µæ•¸": zid, "å§“å": n_str, "é–‹å§‹æ™‚é–“": st_time})

        df_members = pd.DataFrame(member_list)
        if df_members.empty:
            raise ValueError("äººå“¡åå–®è§£æå¾Œç‚ºç©ºï¼šè«‹ç¢ºèª ç¬¬ä¸€æ®µï½ç¬¬å››æ®µ å…§æœ‰å§“åã€‚")

        df_members["ç·šåˆ¥"] = clean_line(df_members["ç·šåˆ¥"])
        df_members["æ®µæ•¸"] = clean_zone_1to4(df_members["æ®µæ•¸"])
        df_members = df_members[df_members["æ®µæ•¸"].notna()].copy()
        df_members = df_members.drop_duplicates(["ç·šåˆ¥", "æ®µæ•¸"], keep="first").copy()

        # =========================================================
        # 2) ç”Ÿç”¢è³‡æ–™ï¼ˆå…ˆç®—åŠ æ¬ŠPCS + ridï¼‰
        # =========================================================
        df_raw = read_table_robust(prod_file.name, prod_file.getvalue(), label="ç”Ÿç”¢è³‡æ–™æª”æ¡ˆ")
        require_columns(df_raw, ["PICKDATE", "LINEID", "ZONEID", "PACKQTY", "Cweight"], "ç”Ÿç”¢è³‡æ–™æª”æ¡ˆ")

        df_raw["PICKDATE"] = pd.to_datetime(df_raw["PICKDATE"], errors="coerce")
        df_raw = df_raw[df_raw["PICKDATE"].notna()].copy()

        df_raw = df_raw.rename(columns={"LINEID": "ç·šåˆ¥", "ZONEID": "æ®µæ•¸"})
        df_raw["ç·šåˆ¥"] = clean_line(df_raw["ç·šåˆ¥"])
        df_raw["æ®µæ•¸"] = clean_zone_1to4(df_raw["æ®µæ•¸"])
        df_raw = df_raw[df_raw["æ®µæ•¸"].notna()].copy()

        if df_raw.empty:
            raise ValueError("ç”Ÿç”¢è³‡æ–™æ¸…ç†å¾Œç‚ºç©ºï¼šè«‹ç¢ºèª ZONEID æ˜¯å¦ç‚º 1~4ã€‚")

        df_raw["PACKQTY"] = pd.to_numeric(df_raw["PACKQTY"], errors="coerce").fillna(0)
        df_raw["Cweight"] = pd.to_numeric(df_raw["Cweight"], errors="coerce").fillna(0)
        df_raw["åŠ æ¬ŠPCS"] = df_raw["PACKQTY"] * df_raw["Cweight"]

        rid_cols = [c for c in df_raw.columns if c not in ("å§“å", "é–‹å§‹æ™‚é–“", "å°æ™‚", "__rid")]
        df_raw["__rid"] = pd.util.hash_pandas_object(df_raw[rid_cols], index=False)

        # =========================================================
        # 3) åˆä½µï¼ˆm:1ï¼‰+ å»é‡
        # =========================================================
        df = pd.merge(df_raw, df_members, on=["ç·šåˆ¥", "æ®µæ•¸"], how="left", validate="m:1")
        df["å§“å"] = df["å§“å"].fillna("æœªè¨­å®š")
        df["é–‹å§‹æ™‚é–“"] = df["é–‹å§‹æ™‚é–“"].fillna("08:00").map(_safe_time)

        df = df.drop_duplicates("__rid", keep="first").copy()

        # =========================================================
        # 4) é–‹å§‹æ™‚é–“éæ¿¾ï¼ˆåœ¨å»é‡å¾Œï¼‰
        # =========================================================
        pick_minutes = df["PICKDATE"].dt.hour * 60 + df["PICKDATE"].dt.minute
        st_parts = df["é–‹å§‹æ™‚é–“"].astype(str).str.split(":", n=1, expand=True)
        st_h = pd.to_numeric(st_parts[0], errors="coerce").fillna(8).astype(int)
        st_m = pd.to_numeric(st_parts[1], errors="coerce").fillna(0).astype(int)
        st_minutes = st_h * 60 + st_m

        df = df[pick_minutes >= st_minutes].copy()
        if df.empty:
            raise ValueError("å¥—ç”¨é–‹å§‹æ™‚é–“éæ¿¾å¾Œæ²’æœ‰è³‡æ–™ï¼šè«‹ç¢ºèª PICKDATE èˆ‡é–‹å§‹æ™‚é–“è¨­å®šã€‚")

        # =========================================================
        # 5) æ¯å°æ™‚åŠ ç¸½ + ç´¯è¨ˆï¼ˆé¡¯ç¤ºï¼šç•¶å°æ™‚é‡ï¼›åˆ¤æ–·ï¼šç´¯è¨ˆï¼‰
        # =========================================================
        df["å°æ™‚"] = df["PICKDATE"].dt.hour
        base_cols = ["ç·šåˆ¥", "æ®µæ•¸", "å§“å", "é–‹å§‹æ™‚é–“"]

        hourly = df.groupby(base_cols + ["å°æ™‚"], as_index=False)["åŠ æ¬ŠPCS"].sum()
        hourly = hourly.sort_values(base_cols + ["å°æ™‚"])
        hourly["ç´¯è¨ˆå¯¦éš›é‡"] = hourly.groupby(["ç·šåˆ¥", "æ®µæ•¸", "å§“å"])["åŠ æ¬ŠPCS"].cumsum()

        cur_h, cur_m = now.hour, now.minute  # âœ… å°åŒ—æ™‚é–“

        st_parts2 = hourly["é–‹å§‹æ™‚é–“"].astype(str).str.split(":", n=1, expand=True)
        s_h = pd.to_numeric(st_parts2[0], errors="coerce").fillna(8).astype(float)
        s_m = pd.to_numeric(st_parts2[1], errors="coerce").fillna(0).astype(float)

        h = hourly["å°æ™‚"].astype(float)

        elapsed = np.where(
            h < cur_h,
            (h - s_h + 1.0) - (s_m / 60.0),
            np.where(
                h == cur_h,
                (h - s_h) + ((cur_m - s_m) / 60.0),
                np.nan
            )
        )

        target = np.maximum(0.01, elapsed) * float(target_hr)
        status = np.where(np.isnan(elapsed), None, np.where(hourly["ç´¯è¨ˆå¯¦éš›é‡"].values >= target, "PASS", "FAIL"))
        hourly["ç‹€æ…‹"] = status

        val4 = hourly["åŠ æ¬ŠPCS"].round(4)
        hourly["é¡¯ç¤º"] = np.where(
            pd.isna(hourly["ç‹€æ…‹"]),
            None,
            val4.map(lambda x: f"{x:.4f}") + "|" + hourly["ç‹€æ…‹"].astype(str)
        )

        # =========================================================
        # 6) è½‰çŸ©é™£ï¼ˆä¿è­‰ä¸æœƒ pivot æˆç©ºè¡¨ï¼‰
        # =========================================================
        hour_max = cur_h
        hour_cols = list(range(int(hour_min), int(hour_max) + 1))

        # âœ… keysï¼šä¸€å®šä¿ç•™æœ‰å“ªäº›äººï¼ˆç”¨ hourly çš„ index çµ„åˆï¼‰
        keys = hourly[base_cols].drop_duplicates().copy()
        if keys.empty:
            raise ValueError("hourly çµ±è¨ˆå¾Œæ²’æœ‰ä»»ä½•äººå“¡åˆ—ï¼ˆè«‹æª¢æŸ¥ PICKDATE æ˜¯å¦æœ‰æ™‚é–“ã€æˆ–é–‹å§‹æ™‚é–“éæ¿¾æ˜¯å¦å¤ªåš´æ ¼ï¼‰ã€‚")

        grid = keys.assign(_k=1).merge(pd.DataFrame({"å°æ™‚": hour_cols, "_k": 1}), on="_k").drop(columns=["_k"])
        grid = grid.merge(hourly[base_cols + ["å°æ™‚", "é¡¯ç¤º"]], on=base_cols + ["å°æ™‚"], how="left")

        matrix = (
            grid.pivot(index=base_cols, columns="å°æ™‚", values="é¡¯ç¤º")
            .reset_index()
        )

        matrix.columns = [int(c) if str(c).isdigit() else c for c in matrix.columns]
        for hh in hour_cols:
            if hh not in matrix.columns:
                matrix[hh] = None
        matrix = matrix[base_cols + hour_cols]

        # =========================================================
        # 7) ç•«é¢é è¦½ + ä¸‹è¼‰
        # =========================================================
        st.success("è¨ˆç®—å®Œæˆ âœ…ï¼ˆçµæœå·²ä½¿ç”¨ï¼šå»é‡å¾ŒåŠ æ¬ŠPCSï¼‰")
        st.caption("è¡¨æ ¼é¡¯ç¤ºç‚ºï¼šç•¶å°æ™‚åŠ æ¬ŠPCSï¼ˆåˆ¤æ–·PASS/FAILä½¿ç”¨ç´¯è¨ˆï¼‰")

        st.dataframe(matrix, use_container_width=True, height=520)

        xlsx_bytes = build_excel_bytes(matrix, hour_cols)
        filename = f"ç”¢èƒ½æ™‚æ®µåˆ†æ_{datetime.now(TPE).strftime('%H%M')}.xlsx"
        st.download_button(
            "â¬‡ï¸ ä¸‹è¼‰ Excelï¼ˆPASS/FAIL ä¸Šè‰²ï¼‰",
            data=xlsx_bytes,
            file_name=filename,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )

    except Exception as e:
        st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")


if __name__ == "__main__":
    main()
