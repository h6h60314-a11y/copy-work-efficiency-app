# pages/29_å„æ™‚æ®µä½œæ¥­æ•ˆç‡.py
# -*- coding: utf-8 -*-
import io
import os
from io import StringIO
from datetime import datetime, date
from zoneinfo import ZoneInfo

import numpy as np
import pandas as pd
import streamlit as st
import altair as alt
from openpyxl import load_workbook
from openpyxl.styles import PatternFill

# ---- å¥—ç”¨å¹³å°é¢¨æ ¼ï¼ˆæœ‰å°±ç”¨ï¼Œæ²’æœ‰å°±é€€å›åŸç”Ÿï¼‰----
try:
    from common_ui import inject_logistics_theme, set_page, card_open, card_close
    HAS_COMMON_UI = True
except Exception:
    HAS_COMMON_UI = False

TPE = ZoneInfo("Asia/Taipei")

# âœ… ç‹€æ…‹æ–‡å­—ï¼ˆä½ è¦çš„ï¼‰
STATUS_PASS = "é”æ¨™"
STATUS_FAIL = "æœªé”æ¨™"


# =============================
# å¼·éŸŒè®€æª”ï¼šCSV/Excel è‡ªå‹•è™•ç†ç·¨ç¢¼/åˆ†éš”ç¬¦
# =============================
def read_table_robust(file_name: str, raw: bytes, label: str = "æª”æ¡ˆ") -> pd.DataFrame:
    ext = os.path.splitext(file_name)[1].lower()

    # Excel
    if ext in (".xlsx", ".xlsm", ".xltx", ".xltm", ".xls"):
        try:
            return pd.read_excel(io.BytesIO(raw))
        except Exception as e:
            raise ValueError(f"{label} è®€å– Excel å¤±æ•—ï¼š{e}")

    # CSVï¼šå¤šç·¨ç¢¼ + å¤šåˆ†éš”ç¬¦
    encodings = ["utf-8-sig", "utf-8", "cp950", "big5", "ms950", "gb18030", "latin1"]
    seps = [",", "\t", ";", "|"]

    last_err = None
    for enc in encodings:
        for sep in seps:
            try:
                df = pd.read_csv(io.BytesIO(raw), encoding=enc, sep=sep, engine="python", low_memory=False)
                if df.shape[1] <= 1:
                    continue
                return df
            except Exception as e:
                last_err = e

    # æœ€å¾Œæ‰‹æ®µï¼šbytes -> utf-8 replaceï¼Œå†è‡ªå‹•åˆ†éš”
    try:
        text = raw.decode("utf-8", errors="replace")
        df = pd.read_csv(StringIO(text), sep=None, engine="python", low_memory=False)
        if df.shape[1] <= 1:
            raise ValueError("åµæ¸¬ä¸åˆ°æœ‰æ•ˆåˆ†éš”ç¬¦ï¼Œè«‹ç¢ºèªæª”æ¡ˆæ˜¯å¦ç‚ºçœŸæ­£ CSVã€‚")
        return df
    except Exception as e:
        raise ValueError(f"{label} è®€å– CSV å¤±æ•—ï¼ˆå·²å˜—è©¦å¤šç¨®ç·¨ç¢¼/åˆ†éš”ç¬¦ï¼‰ï¼š{last_err} / æœ€çµ‚ï¼š{e}")


def require_columns(df: pd.DataFrame, required: list, label: str):
    missing = [c for c in required if c not in df.columns]
    if missing:
        raise ValueError(f"{label} ç¼ºå°‘æ¬„ä½ï¼š{missing}\nç›®å‰æ¬„ä½ï¼š{list(df.columns)}")


def _norm_cols(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    return df


def clean_line(series: pd.Series) -> pd.Series:
    return series.astype(str).str.strip()


def clean_zone_1to4(series: pd.Series) -> pd.Series:
    z = pd.to_numeric(series, errors="coerce").astype("Int64")
    return z.where(z.between(1, 4, inclusive="both"))


def _safe_time(s: str) -> str:
    s = str(s).strip()
    if not s:
        return "08:00"
    try:
        datetime.strptime(s, "%H:%M")
        return s
    except Exception:
        return "08:00"


# =============================
# Excelï¼šé”æ¨™/æœªé”æ¨™ ä¸Šè‰²ï¼ˆåªè¼¸å‡ºæ–‡å­—ï¼‰
# =============================
def build_excel_bytes_pf(matrix_pf: pd.DataFrame, hour_cols: list[int]) -> bytes:
    bio = io.BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        matrix_pf.to_excel(writer, index=False, sheet_name="é”æ¨™_çŸ©é™£")
    bio.seek(0)

    wb = load_workbook(bio)
    ws = wb.active

    fill_ok = PatternFill(start_color="C6EFCE", end_color="C6EFCE", fill_type="solid")
    fill_ng = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")

    base_cols = ["ç·šåˆ¥", "æ®µæ•¸", "å§“å", "é–‹å§‹æ™‚é–“"]
    min_col = len(base_cols) + 1
    max_col = len(base_cols) + len(hour_cols)

    for r in ws.iter_rows(min_row=2, min_col=min_col, max_col=max_col):
        for c in r:
            v = str(c.value).strip() if c.value is not None else ""
            if v == STATUS_PASS:
                c.fill = fill_ok
            elif v == STATUS_FAIL:
                c.fill = fill_ng

    out = io.BytesIO()
    wb.save(out)
    return out.getvalue()


# =============================
# è¡¨æ ¼è‘—è‰²ï¼ˆå‰ç«¯ dataframeï¼‰
# =============================
def _style_pf(v):
    if v == STATUS_PASS:
        return "background-color: rgba(198,239,206,1); color: rgba(0,0,0,0.9); font-weight:700;"
    if v == STATUS_FAIL:
        return "background-color: rgba(255,199,206,1); color: rgba(0,0,0,0.9); font-weight:700;"
    return ""


def _kpi_counts(dist_df: pd.DataFrame):
    # dist_df columns: å°æ™‚, ç‹€æ…‹, count
    if dist_df is None or dist_df.empty:
        return 0, 0, None
    p = int(dist_df.loc[dist_df["ç‹€æ…‹"] == STATUS_PASS, "count"].sum())
    f = int(dist_df.loc[dist_df["ç‹€æ…‹"] == STATUS_FAIL, "count"].sum())
    rate = (p / (p + f) * 100.0) if (p + f) > 0 else None
    return p, f, rate


def _render_dist_chart(dist_df: pd.DataFrame, title: str):
    # dist_df columns: å°æ™‚, ç‹€æ…‹, count
    if dist_df is None or dist_df.empty:
        st.info("æ­¤å€é–“æ²’æœ‰å¯å‘ˆç¾çš„ é”æ¨™/æœªé”æ¨™ åˆ†ä½ˆã€‚")
        return

    chart = (
        alt.Chart(dist_df)
        .mark_bar()
        .encode(
            x=alt.X("å°æ™‚:O", title="å°æ™‚"),
            y=alt.Y("count:Q", title="æ®µæ•¸æ•¸é‡", stack="zero"),
            color=alt.Color(
                "ç‹€æ…‹:N",
                scale=alt.Scale(domain=[STATUS_PASS, STATUS_FAIL], range=["#2E7D32", "#C62828"]),
                legend=alt.Legend(title="ç‹€æ…‹"),
            ),
            tooltip=[alt.Tooltip("å°æ™‚:O"), alt.Tooltip("ç‹€æ…‹:N"), alt.Tooltip("count:Q")],
        )
        .properties(title=title, height=220)
    )
    st.altair_chart(chart, use_container_width=True)


def main():
    st.set_page_config(page_title="å¤§è±ç‰©æµ - å‡ºè²¨èª²ï½œå„æ™‚æ®µä½œæ¥­æ•ˆç‡", page_icon="â±ï¸", layout="wide")
    if HAS_COMMON_UI:
        inject_logistics_theme()
        set_page("ğŸ“¦ å‡ºè²¨èª²", "â±ï¸ 29ï½œå„æ™‚æ®µä½œæ¥­æ•ˆç‡")

    st.markdown("### â±ï¸ å„æ™‚æ®µä½œæ¥­æ•ˆç‡ï¼ˆé”æ¨™/æœªé”æ¨™ï½œæ®µ1~æ®µ4 åˆ†ä½ˆï¼‰")

    # --- å›ºå®šäººå“¡é–‹å§‹æ™‚é–“è¡¨ ---
    fixed_time_map = {
        'èŒƒæ˜ä¿Š': '08:00', 'é˜®ç‰å': '08:00', 'æèŒ‚éŠ“': '08:00', 'æ²³æ–‡å¼·': '08:00',
        'è”¡éº—ç ': '08:00', 'æ½˜æ–‡ä¸€': '08:00', 'é˜®ä¼Šé»ƒ': '08:00', 'è‘‰æ¬²å¼˜': '09:00',
        'é˜®æ­¦ç‰ç„': '08:00', 'å³é»ƒé‡‘ç ': '08:30', 'æ½˜æ°é’æ±Ÿ': '08:00', 'é™³åœ‹æ…¶': '08:30',
        'æ¥Šå¿ƒå¦‚': '08:00', 'é˜®ç‘ç¾é»ƒç·£': '08:00', 'å‘¨èŠ¸è“': '08:00', 'é»æ°ç“Š': '08:00',
        'ç‹æ–‡æ¥·': '08:30', 'æ½˜æ°æ…¶å¹³': '08:00', 'é˜®æ°ç¾éº—': '08:00', 'å²³å­æ†': '08:30',
        'éƒ­é›™ç‡•': '08:30', 'é˜®å­Ÿå‹‡': '08:00', 'å»–æ°¸æˆ':'08:30', 'æ¥Šæµ©å‚‘':'08:30', 'é»ƒæ—¥åº·':'08:30',
        'è”£é‡‘å¦®':'08:30', 'æŸ´å®¶æ¬£':'08:30',
    }

    with st.sidebar:
        st.markdown("### è¨­å®š")
        target_hr = st.number_input("æ¯å°æ™‚ç›®æ¨™ï¼ˆåŠ æ¬ŠPCS/å°æ™‚ï¼‰", min_value=1.0, value=790.0, step=10.0)
        hour_min = st.number_input("èµ·å§‹å°æ™‚", min_value=0, max_value=23, value=8, step=1)

        use_now = st.toggle("ç”¨ç¾åœ¨æ™‚é–“ä½œç‚ºåˆ¤æ–·æˆªæ­¢ï¼ˆå°åŒ—æ™‚é–“ï¼‰", value=True)
        if use_now:
            now = datetime.now(TPE)
        else:
            t_in = st.time_input("åˆ¤æ–·æˆªæ­¢æ™‚é–“ï¼ˆå°åŒ—æ™‚é–“ï¼‰", value=datetime.now(TPE).time())
            now = datetime.combine(date.today(), t_in).replace(tzinfo=TPE)

        st.caption(f"ç›®å‰æ¡ç”¨æ™‚é–“ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')} (Asia/Taipei)")

    c1, c2 = st.columns(2)
    with c1:
        prod_file = st.file_uploader("â‘  ä¸Šå‚³ã€åŸå§‹ç”Ÿç”¢è³‡æ–™ã€(CSV/Excel)", type=["csv", "xlsx", "xlsm", "xls"])
    with c2:
        mem_file = st.file_uploader("â‘¡ ä¸Šå‚³ã€äººå“¡åå–®ã€(CSV/Excel)", type=["csv", "xlsx", "xlsm", "xls"])

    run = st.button("ğŸš€ é–‹å§‹è¨ˆç®—", type="primary", use_container_width=True)
    if not run:
        return
    if prod_file is None or mem_file is None:
        st.error("è«‹å…ˆä¸Šå‚³å…©å€‹æª”æ¡ˆï¼šç”Ÿç”¢è³‡æ–™ + äººå“¡åå–®ã€‚")
        return

    try:
        # =========================================================
        # 1) äººå“¡åå–®ï¼šLINEID + ç¬¬ä¸€æ®µ~ç¬¬å››æ®µ => æ®µæ•¸=ZONEID(1~4)
        # =========================================================
        df_mem_raw = _norm_cols(read_table_robust(mem_file.name, mem_file.getvalue(), label="äººå“¡åå–®æª”æ¡ˆ"))

        line_col_candidates = ["LINEID", "ç·šåˆ¥", "LineID", "LINE Id", "Line Id"]
        line_col = next((c for c in line_col_candidates if c in df_mem_raw.columns), None)
        if line_col is None:
            raise ValueError("äººå“¡åå–®æ‰¾ä¸åˆ°ç·šåˆ¥æ¬„ä½ï¼ˆéœ€è¦ LINEID æˆ– ç·šåˆ¥ï¼‰ã€‚")

        seg_cols = {1: "ç¬¬ä¸€æ®µ", 2: "ç¬¬äºŒæ®µ", 3: "ç¬¬ä¸‰æ®µ", 4: "ç¬¬å››æ®µ"}
        for _, colname in seg_cols.items():
            if colname not in df_mem_raw.columns:
                raise ValueError(f"äººå“¡åå–®ç¼ºå°‘æ¬„ä½ï¼š{colname}ï¼ˆéœ€è¦ ç¬¬ä¸€æ®µï½ç¬¬å››æ®µï¼‰")

        member_list = []
        for _, row in df_mem_raw.iterrows():
            line_id = str(row.get(line_col, "")).strip()
            if not line_id or line_id.lower() == "nan":
                continue

            for zid, colname in seg_cols.items():
                name = row.get(colname, None)
                if pd.notna(name) and str(name).strip() != "":
                    n_str = str(name).strip()
                    st_time = _safe_time(fixed_time_map.get(n_str, "08:00"))
                    member_list.append({"ç·šåˆ¥": line_id, "æ®µæ•¸": zid, "å§“å": n_str, "é–‹å§‹æ™‚é–“": st_time})

        df_members = pd.DataFrame(member_list)
        if df_members.empty:
            raise ValueError("äººå“¡åå–®è§£æå¾Œç‚ºç©ºï¼šè«‹ç¢ºèª ç¬¬ä¸€æ®µï½ç¬¬å››æ®µ å…§æœ‰å§“åã€‚")

        df_members["ç·šåˆ¥"] = clean_line(df_members["ç·šåˆ¥"])
        df_members["æ®µæ•¸"] = clean_zone_1to4(df_members["æ®µæ•¸"])
        df_members = df_members[df_members["æ®µæ•¸"].notna()].copy()

        # âœ… åŒä¸€ç·šåˆ¥+æ®µæ•¸åªç•™ä¸€ç­†ï¼ˆé¿å…åˆä½µå±•é–‹ï¼‰
        df_members = df_members.drop_duplicates(["ç·šåˆ¥", "æ®µæ•¸"], keep="first").copy()

        # =========================================================
        # 2) ç”Ÿç”¢è³‡æ–™ï¼ˆå»é‡å¾ŒåŠ æ¬ŠPCSï¼‰
        # =========================================================
        df_raw = read_table_robust(prod_file.name, prod_file.getvalue(), label="ç”Ÿç”¢è³‡æ–™æª”æ¡ˆ")
        require_columns(df_raw, ["PICKDATE", "LINEID", "ZONEID", "PACKQTY", "Cweight"], "ç”Ÿç”¢è³‡æ–™æª”æ¡ˆ")

        df_raw["PICKDATE"] = pd.to_datetime(df_raw["PICKDATE"], errors="coerce")
        df_raw = df_raw[df_raw["PICKDATE"].notna()].copy()

        df_raw = df_raw.rename(columns={"LINEID": "ç·šåˆ¥", "ZONEID": "æ®µæ•¸"})
        df_raw["ç·šåˆ¥"] = clean_line(df_raw["ç·šåˆ¥"])
        df_raw["æ®µæ•¸"] = clean_zone_1to4(df_raw["æ®µæ•¸"])
        df_raw = df_raw[df_raw["æ®µæ•¸"].notna()].copy()

        if df_raw.empty:
            raise ValueError("ç”Ÿç”¢è³‡æ–™æ¸…ç†å¾Œç‚ºç©ºï¼šè«‹ç¢ºèª ZONEID æ˜¯å¦ç‚º 1~4ã€‚")

        df_raw["PACKQTY"] = pd.to_numeric(df_raw["PACKQTY"], errors="coerce").fillna(0)
        df_raw["Cweight"] = pd.to_numeric(df_raw["Cweight"], errors="coerce").fillna(0)
        df_raw["åŠ æ¬ŠPCS"] = df_raw["PACKQTY"] * df_raw["Cweight"]

        rid_cols = [c for c in df_raw.columns if c not in ("å§“å", "é–‹å§‹æ™‚é–“", "å°æ™‚", "__rid")]
        df_raw["__rid"] = pd.util.hash_pandas_object(df_raw[rid_cols], index=False)

        # åˆä½µ + å»é‡ï¼ˆæ ¸å¿ƒï¼‰
        df = pd.merge(df_raw, df_members, on=["ç·šåˆ¥", "æ®µæ•¸"], how="left", validate="m:1")
        df["å§“å"] = df["å§“å"].fillna("æœªè¨­å®š")
        df["é–‹å§‹æ™‚é–“"] = df["é–‹å§‹æ™‚é–“"].fillna("08:00").map(_safe_time)
        df = df.drop_duplicates("__rid", keep="first").copy()

        # é–‹å§‹æ™‚é–“éæ¿¾
        pick_minutes = df["PICKDATE"].dt.hour * 60 + df["PICKDATE"].dt.minute
        st_parts = df["é–‹å§‹æ™‚é–“"].astype(str).str.split(":", n=1, expand=True)
        st_h = pd.to_numeric(st_parts[0], errors="coerce").fillna(8).astype(int)
        st_m = pd.to_numeric(st_parts[1], errors="coerce").fillna(0).astype(int)
        st_minutes = st_h * 60 + st_m
        df = df[pick_minutes >= st_minutes].copy()

        if df.empty:
            raise ValueError("å¥—ç”¨é–‹å§‹æ™‚é–“éæ¿¾å¾Œæ²’æœ‰è³‡æ–™ï¼šè«‹ç¢ºèª PICKDATE èˆ‡é–‹å§‹æ™‚é–“è¨­å®šã€‚")

        # =========================================================
        # 3) ä»¥ã€Œç´¯è¨ˆã€åˆ¤æ–· é”æ¨™/æœªé”æ¨™ï¼ˆæ¯äººæ¯å°æ™‚ï¼‰
        # =========================================================
        df["å°æ™‚"] = df["PICKDATE"].dt.hour
        base_cols = ["ç·šåˆ¥", "æ®µæ•¸", "å§“å", "é–‹å§‹æ™‚é–“"]

        hourly = df.groupby(base_cols + ["å°æ™‚"], as_index=False)["åŠ æ¬ŠPCS"].sum()
        hourly = hourly.sort_values(base_cols + ["å°æ™‚"])
        hourly["ç´¯è¨ˆå¯¦éš›é‡"] = hourly.groupby(["ç·šåˆ¥", "æ®µæ•¸", "å§“å"])["åŠ æ¬ŠPCS"].cumsum()

        cur_h, cur_m = now.hour, now.minute

        st_parts2 = hourly["é–‹å§‹æ™‚é–“"].astype(str).str.split(":", n=1, expand=True)
        s_h = pd.to_numeric(st_parts2[0], errors="coerce").fillna(8).astype(float)
        s_m = pd.to_numeric(st_parts2[1], errors="coerce").fillna(0).astype(float)
        h = hourly["å°æ™‚"].astype(float)

        elapsed = np.where(
            h < cur_h,
            (h - s_h + 1.0) - (s_m / 60.0),
            np.where(
                h == cur_h,
                (h - s_h) + ((cur_m - s_m) / 60.0),
                np.nan
            )
        )

        target = np.maximum(0.01, elapsed) * float(target_hr)

        # âœ… ç›´æ¥è¼¸å‡ºã€Œé”æ¨™/æœªé”æ¨™ã€
        status = np.where(
            np.isnan(elapsed),
            None,
            np.where(hourly["ç´¯è¨ˆå¯¦éš›é‡"].values >= target, STATUS_PASS, STATUS_FAIL)
        )
        hourly["ç‹€æ…‹"] = status

        # =========================================================
        # 4) å»ºã€Œå®Œæ•´ç¶²æ ¼ã€ï¼šæ¯ç·š Ã— æ®µ(1~4) Ã— æ¯å°æ™‚ï¼Œéƒ½ç”¨ é”æ¨™/æœªé”æ¨™ é¡¯ç¤º
        # =========================================================
        hour_cols = list(range(int(hour_min), int(cur_h) + 1))

        keys = df_members[base_cols].drop_duplicates().copy()
        if keys.empty:
            raise ValueError("äººå“¡åå–® keys ç‚ºç©ºï¼Œè«‹ç¢ºèªåå–®æª”æ ¼å¼ã€‚")

        grid = keys.assign(_k=1).merge(pd.DataFrame({"å°æ™‚": hour_cols, "_k": 1}), on="_k").drop(columns=["_k"])
        grid = grid.merge(hourly[base_cols + ["å°æ™‚", "ç‹€æ…‹"]], on=base_cols + ["å°æ™‚"], how="left")

        # âœ… ç”¢å‡ºç¸½çŸ©é™£ï¼šç·šåˆ¥+æ®µæ•¸+å§“å+é–‹å§‹æ™‚é–“ + æ¯å°æ™‚ é”æ¨™/æœªé”æ¨™
        matrix_pf = (
            grid.pivot(index=base_cols, columns="å°æ™‚", values="ç‹€æ…‹")
            .reset_index()
        )
        matrix_pf.columns = [int(c) if str(c).isdigit() else c for c in matrix_pf.columns]
        for hh in hour_cols:
            if hh not in matrix_pf.columns:
                matrix_pf[hh] = None
        matrix_pf = matrix_pf[base_cols + hour_cols]

        # =========================================================
        # 5) KPI åœ–è¡¨ï¼šæ¯ç·šï¼ˆæ®µ1~æ®µ4 é”æ¨™/æœªé”æ¨™ åˆ†ä½ˆï¼‰ + å…¨ä½œæ¥­ç·šç¸½å’Œ
        # =========================================================
        st.success("è¨ˆç®—å®Œæˆ âœ…ï¼ˆå‘ˆç¾ï¼šé”æ¨™/æœªé”æ¨™ï½œæ®µ1~æ®µ4 åˆ†ä½ˆï¼‰")
        st.markdown("## ğŸ“Š KPIï¼ˆæ¯ç·šï¼šæ®µ1~æ®µ4 é”æ¨™/æœªé”æ¨™ åˆ†ä½ˆï¼‰")

        # distï¼šæ¯ç·šã€æ¯å°æ™‚ é”æ¨™/æœªé”æ¨™ æœ‰å¹¾æ®µ
        dist = (
            grid[grid["ç‹€æ…‹"].isin([STATUS_PASS, STATUS_FAIL])]
            .groupby(["ç·šåˆ¥", "å°æ™‚", "ç‹€æ…‹"], as_index=False)
            .size()
            .rename(columns={"size": "count"})
            .sort_values(["ç·šåˆ¥", "å°æ™‚", "ç‹€æ…‹"])
        )

        eff_hour = int(cur_h)

        lines = sorted(keys["ç·šåˆ¥"].dropna().unique().tolist())
        for line in lines:
            if HAS_COMMON_UI:
                card_open(f"ğŸ“¦ {line}")
            else:
                st.markdown(f"### ğŸ“¦ {line}")

            # KPIï¼šç›®å‰å°æ™‚çš„ é”æ¨™/æœªé”æ¨™ æ®µæ•¸ï¼ˆæ®µ1~æ®µ4ï¼‰
            dist_now = dist[(dist["ç·šåˆ¥"] == line) & (dist["å°æ™‚"] == eff_hour)]
            p, f, rate = _kpi_counts(dist_now)

            c1, c2, c3, c4 = st.columns(4)
            c1.metric("åˆ¤æ–·å°æ™‚", f"{eff_hour} é»")
            c2.metric("é”æ¨™ æ®µæ•¸", p)
            c3.metric("æœªé”æ¨™ æ®µæ•¸", f)
            c4.metric("é”æ¨™ ç‡", (f"{rate:.1f}%" if rate is not None else "â€”"))

            # åœ–ï¼šæ¯å°æ™‚ é”æ¨™/æœªé”æ¨™ æ®µæ•¸ï¼ˆ0~4ï¼‰
            dist_line = dist[dist["ç·šåˆ¥"] == line].copy()
            _render_dist_chart(dist_line, title=f"{line}ï½œæ¯å°æ™‚ é”æ¨™/æœªé”æ¨™ æ®µæ•¸ï¼ˆæ®µ1~æ®µ4ï¼‰")

            # âœ… è¡¨ï¼šæ®µ1~æ®µ4 Ã— å°æ™‚ï¼ˆé¡¯ç¤ºå§“åï¼‰
            tbl = grid[grid["ç·šåˆ¥"] == line][["æ®µæ•¸", "å§“å", "å°æ™‚", "ç‹€æ…‹"]].copy()
            tbl["æ®µæ•¸"] = pd.to_numeric(tbl["æ®µæ•¸"], errors="coerce").astype("Int64")

            line_matrix = (
                tbl.pivot(index=["æ®µæ•¸", "å§“å"], columns="å°æ™‚", values="ç‹€æ…‹")
                .reset_index()
            )
            line_matrix.columns = [int(c) if str(c).isdigit() else c for c in line_matrix.columns]

            # è£œé½Šå°æ™‚æ¬„
            for hh in hour_cols:
                if hh not in line_matrix.columns:
                    line_matrix[hh] = None

            # æ’åºï¼šæ®µæ•¸ 1~4
            line_matrix = line_matrix.sort_values(["æ®µæ•¸", "å§“å"]).reset_index(drop=True)
            line_matrix = line_matrix[["æ®µæ•¸", "å§“å"] + hour_cols]

            st.caption("æ®µ1~æ®µ4 Ã— æ¯å°æ™‚ï¼šé¡¯ç¤ºã€å§“åã€èˆ‡ã€é”æ¨™/æœªé”æ¨™ã€ï¼ˆç©ºç™½=ç„¡åˆ¤æ–·/æœªåˆ°æ™‚æ®µï¼‰")
            st.dataframe(line_matrix.style.applymap(_style_pf), use_container_width=True, height=240)

            if HAS_COMMON_UI:
                card_close()

        # å…¨ä½œæ¥­ç·šç¸½å’Œ
        st.markdown("## ğŸ§¾ å…¨ä½œæ¥­ç·šç¸½å’Œï¼ˆæ®µ1~æ®µ4 é”æ¨™/æœªé”æ¨™ åˆ†ä½ˆï¼‰")
        dist_all = (
            grid[grid["ç‹€æ…‹"].isin([STATUS_PASS, STATUS_FAIL])]
            .groupby(["å°æ™‚", "ç‹€æ…‹"], as_index=False)
            .size()
            .rename(columns={"size": "count"})
            .sort_values(["å°æ™‚", "ç‹€æ…‹"])
        )

        dist_all_now = dist_all[dist_all["å°æ™‚"] == eff_hour]
        p_all, f_all, rate_all = _kpi_counts(dist_all_now)

        c1, c2, c3, c4 = st.columns(4)
        c1.metric("åˆ¤æ–·å°æ™‚", f"{eff_hour} é»")
        c2.metric("é”æ¨™ æ®µæ•¸", p_all)
        c3.metric("æœªé”æ¨™ æ®µæ•¸", f_all)
        c4.metric("é”æ¨™ ç‡", (f"{rate_all:.1f}%" if rate_all is not None else "â€”"))

        _render_dist_chart(dist_all, title="å…¨ä½œæ¥­ç·šï½œæ¯å°æ™‚ é”æ¨™/æœªé”æ¨™ æ®µæ•¸ï¼ˆæ‰€æœ‰ç·šåˆ¥æ®µ1~æ®µ4ï¼‰")

        # =========================================================
        # 6) ä¸‹è¼‰ Excelï¼ˆé”æ¨™/æœªé”æ¨™ çŸ©é™£ï¼‰
        # =========================================================
        st.markdown("## â¬‡ï¸ ä¸‹è¼‰")
        xlsx_bytes = build_excel_bytes_pf(matrix_pf, hour_cols)
        filename = f"ç”¢èƒ½æ™‚æ®µ_é”æ¨™çŸ©é™£_{datetime.now(TPE).strftime('%H%M')}.xlsx"
        st.download_button(
            "â¬‡ï¸ ä¸‹è¼‰ Excelï¼ˆé”æ¨™/æœªé”æ¨™ çŸ©é™£ï¼Œä¸Šè‰²ï¼‰",
            data=xlsx_bytes,
            file_name=filename,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )

        # ï¼ˆå¯é¸ï¼‰ç¸½çŸ©é™£é è¦½
        with st.expander("ğŸ“‹ å±•é–‹æŸ¥çœ‹ï¼šå…¨é«” é”æ¨™/æœªé”æ¨™ çŸ©é™£ï¼ˆå«å§“åï¼‰", expanded=False):
            st.dataframe(matrix_pf.style.applymap(_style_pf), use_container_width=True, height=520)

    except Exception as e:
        st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")


if __name__ == "__main__":
    main()
