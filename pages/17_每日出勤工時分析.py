# pages/17_æ¯æ—¥å‡ºå‹¤å·¥æ™‚åˆ†æ.py
# -*- coding: utf-8 -*-
"""
æ‰‹å‹•ä¸Šå‚³æª”æ¡ˆ + æ‰‹å‹•é¸æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰
â†’ ä¸Šæ–¹é¡¯ç¤ºï¼šç¸½äººæ¬¡ã€å¹¹éƒ¨ã€ç†è²¨äººå“¡ã€è¨ˆæ™‚ã€æ´¾é£ã€æ”¯æ´æœ¬å€‰ã€æ”¯æ´å¤–å€‰
   ï¼ˆçš†ç‚ºå§“åå»å°¾ç¢¼(-1/-2)å¾Œå»é‡ï¼›å·¥æ™‚>0ï¼›æ’é™¤ä¸»ç®¡ï¼‰
â†’ ä¸‹æ–¹é¡¯ç¤ºï¼šå„è·å‹™ç¸½ä¸Šç­æ™‚é–“ï¼ˆå°æ™‚ï¼›æ’é™¤ä¸»ç®¡ï¼›å›ºå®šè·å‹™é †åºï¼›å«ç¸½è¨ˆï¼‰
â†’ æä¾›ä¸‹è¼‰ï¼šè¼¸å‡º Excelï¼ˆå«æŠ¬é ­å€å¡Š + å·¥æ™‚è¡¨ï¼‰
"""

import warnings
warnings.filterwarnings("ignore")

import io
import os
from datetime import date

import numpy as np
import pandas as pd
import streamlit as st

# è‹¥ä½ å¹³å°æœ‰ common_uiï¼Œæœƒè‡ªå‹•å¥—ç”¨åŒä¸€å¥—ç‰©æµé¢¨æ ¼
try:
    from common_ui import inject_logistics_theme, set_page, card_open, card_close
    HAS_COMMON_UI = True
except Exception:
    HAS_COMMON_UI = False


# =========================
# åƒæ•¸å€ï¼ˆæ²¿ç”¨ä½ åŸæœ¬ï¼‰
# =========================
ROLE_ORDER = ["å¹¹éƒ¨", "ç†è²¨äººå“¡", "è¨ˆæ™‚", "æ´¾é£", "æ”¯æ´æœ¬å€‰", "æ”¯æ´å¤–å€‰"]
EXCLUDE_ROLE_REGEX = r"ä¸»ç®¡"
NAME_SUFFIX_STRIP_REGEX = r"\s*-(?:1|2)\s*$"
TOP_NOTE = "å‚™è¨»ï¼šå§“åä»¥å»å°¾ç¢¼(-1/-2)å¾Œå»é‡ï¼›å·²æ’é™¤è·å‹™å«ã€ä¸»ç®¡ã€ï¼›åƒ…è¨ˆå·¥æ™‚>0"
SHEET_NAME = "ç¸½æ˜ç´°"


# =========================
# å·¥å…·å‡½å¼
# =========================
def detect_role_column(cols) -> str | None:
    if "è·å‹™" in cols:
        return "è·å‹™"
    if "è·å‹™åˆ¥" in cols:
        return "è·å‹™åˆ¥"
    return None


def to_num(s):
    return pd.to_numeric(s, errors="coerce")


def compute_hours(df: pd.DataFrame) -> pd.Series:
    """ä¾ä½ çš„åŸé‚è¼¯ï¼šä¸Šç­æ™‚æ•¸ â†’ æ‰“å¡æ™‚æ•¸ â†’ (ä¸‹ç­-ä¸Šç­)-ç”¨é¤"""
    h = pd.Series(np.nan, index=df.index, dtype="float64")

    if "ä¸Šç­æ™‚æ•¸" in df.columns:
        h = to_num(df["ä¸Šç­æ™‚æ•¸"])

    if h.isna().all() and "æ‰“å¡æ™‚æ•¸" in df.columns:
        h = to_num(df["æ‰“å¡æ™‚æ•¸"])

    if h.isna().all():
        if ("ä¸Šç­æ‰“å¡æ™‚é–“" in df.columns) and ("ä¸‹ç­æ‰“å¡æ™‚é–“" in df.columns):
            tin = pd.to_datetime(df["ä¸Šç­æ‰“å¡æ™‚é–“"], errors="coerce")
            tout = pd.to_datetime(df["ä¸‹ç­æ‰“å¡æ™‚é–“"], errors="coerce")
            dur = (tout - tin).dt.total_seconds() / 3600.0
            meal = to_num(df.get("ç”¨é¤æ™‚æ•¸", 0)).fillna(0.0)
            h = dur - meal

    return pd.to_numeric(h, errors="coerce").fillna(0.0)


def normalize_role(s: pd.Series) -> pd.Series:
    s = s.astype(str).str.strip()
    return s.replace({"": "æœªå¡«", "nan": "æœªå¡«", "None": "æœªå¡«"})


def robust_read_excel(uploaded_file, sheet_name: str) -> pd.DataFrame:
    """
    Streamlit ä¸Šå‚³æª”æ¡ˆå¾Œï¼Œä»¥ bytes è®€å–ã€‚
    - xlsx / xlsmï¼šopenpyxl
    - xlsï¼šxlrdï¼ˆéœ€å®‰è£ xlrd==2.0.1ï¼‰
    """
    filename = uploaded_file.name
    ext = os.path.splitext(filename)[1].lower()
    data = uploaded_file.getvalue()
    bio = io.BytesIO(data)

    if ext in (".xlsx", ".xlsm", ".xltx", ".xltm"):
        return pd.read_excel(bio, sheet_name=sheet_name, engine="openpyxl")

    if ext == ".xls":
        return pd.read_excel(bio, sheet_name=sheet_name, engine="xlrd")

    return pd.read_excel(bio, sheet_name=sheet_name, engine="openpyxl")


def build_output_excel_bytes(
    role_counts: pd.DataFrame,
    total_headcount: int,
    hours_summary: pd.DataFrame,
    target_date: date,
    out_name: str,
) -> tuple[str, bytes]:
    """ç”¢ç”Ÿ xlsx bytesï¼ˆå«æŠ¬é ­å€å¡Š + å·¥æ™‚è¡¨ï¼‰"""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        sheet = "ç•¶æ—¥_å„è·å‹™_å·¥æ™‚"
        start_row = 8  # å·¥æ™‚è¡¨å¾ç¬¬ 9 åˆ—é–‹å§‹ï¼ˆ0-basedï¼‰
        hours_summary.to_excel(writer, sheet_name=sheet, index=False, startrow=start_row)

        ws = writer.sheets[sheet]
        wb = writer.book

        big = wb.add_format({"bold": True, "font_size": 12})
        label = wb.add_format({"bold": True})
        gray = wb.add_format({"font_color": "#666666"})

        # æ—¥æœŸ
        ws.write(0, 0, f"{target_date}", big)
        # å‚™è¨»
        ws.write(1, 0, TOP_NOTE, gray)
        # ç¸½äººæ¬¡
        ws.write(2, 0, "ç¸½äººæ¬¡ï¼š", label)
        ws.write(2, 1, int(total_headcount), big)

        # å„è·å‹™äººæ¬¡
        row = 3
        for _, r in role_counts.iterrows():
            ws.write(row, 0, f"{r['è·å‹™']}ï¼š", label)
            ws.write(row, 1, int(r["äººæ¬¡"]))
            row += 1

        # æ¬„å¯¬ & å‡çµ
        ws.set_column(0, 0, 16)
        ws.set_column(1, 1, 12)
        ws.set_column(2, 10, 14)
        ws.freeze_panes(start_row + 1, 0)

    output.seek(0)
    return out_name, output.getvalue()


# =========================
# é é¢ UIï¼ˆâœ…åˆªé™¤ã€Œè¦å‰‡ã€å€å¡Šï¼‰
# =========================
st.set_page_config(page_title="æ¯æ—¥å‡ºå‹¤å·¥æ™‚åˆ†æ", page_icon="ğŸ•’", layout="wide")

if HAS_COMMON_UI:
    inject_logistics_theme()
    set_page("æ¯æ—¥å‡ºå‹¤å·¥æ™‚åˆ†æ", icon="ğŸ•’", subtitle="å‡ºå‹¤äººæ¬¡ï½œå·¥æ™‚å½™ç¸½ï½œExcelåŒ¯å‡º")
else:
    st.title("ğŸ•’ æ¯æ—¥å‡ºå‹¤å·¥æ™‚åˆ†æ")

st.markdown("ä¸Šå‚³å‡ºå‹¤æª”æ¡ˆï¼ˆéœ€å«ã€Œç¸½æ˜ç´°ã€åˆ†é ï¼‰ä¸¦é¸æ“‡æ—¥æœŸ")
st.divider()

# âœ… ç›´å‘ï¼šå‡ºå‹¤Excel â†’ è¨ˆç®—æ—¥æœŸ
if HAS_COMMON_UI:
    card_open("ğŸ“¤ å‡ºå‹¤ Excel")
uploaded = st.file_uploader("ä¸Šå‚³å‡ºå‹¤ Excelï¼ˆéœ€å«ã€Œç¸½æ˜ç´°ã€åˆ†é ï¼‰", type=["xlsx", "xls", "xlsm"])
if HAS_COMMON_UI:
    card_close()

st.markdown("")

if HAS_COMMON_UI:
    card_open("ğŸ“… è¨ˆç®—æ—¥æœŸ")
target_date = st.date_input("é¸æ“‡è¦è¨ˆç®—çš„æ—¥æœŸ", value=None)
if HAS_COMMON_UI:
    card_close()

st.divider()

# =========================
# é˜²å‘†
# =========================
if not uploaded:
    st.info("è«‹å…ˆä¸Šå‚³å‡ºå‹¤ Excel æª”ã€‚")
    st.stop()

if not target_date:
    st.info("è«‹é¸æ“‡è¦è¨ˆç®—çš„æ—¥æœŸã€‚")
    st.stop()

# =========================
# è®€æª”
# =========================
try:
    df = robust_read_excel(uploaded, sheet_name=SHEET_NAME)
except Exception as e:
    st.error(f"è®€å–å¤±æ•—ï¼šæ‰¾ä¸åˆ°åˆ†é ã€Œ{SHEET_NAME}ã€æˆ–æª”æ¡ˆæ ¼å¼ä¸æ”¯æ´ã€‚\n\néŒ¯èª¤è¨Šæ¯ï¼š{e}")
    st.stop()

# æ¬„ä½æª¢æŸ¥
if "å¹´æœˆæ—¥" not in df.columns:
    st.error("æ¬„ä½ç¼ºå°‘ï¼šæ‰¾ä¸åˆ°ã€Œå¹´æœˆæ—¥ã€æ¬„ä½ã€‚")
    st.stop()

role_col = detect_role_column(df.columns)
if not role_col:
    st.error("æ¬„ä½ç¼ºå°‘ï¼šæ‰¾ä¸åˆ°ã€Œè·å‹™ã€æˆ–ã€Œè·å‹™åˆ¥ã€æ¬„ä½ã€‚")
    st.stop()

if "å“¡å·¥å§“å" not in df.columns:
    st.error("æ¬„ä½ç¼ºå°‘ï¼šæ‰¾ä¸åˆ°ã€Œå“¡å·¥å§“åã€æ¬„ä½ã€‚")
    st.stop()

# =========================
# è¨ˆç®—
# =========================
df["æ—¥æœŸ"] = pd.to_datetime(df["å¹´æœˆæ—¥"], errors="coerce").dt.date
df["å·¥æ™‚"] = compute_hours(df)

day = df[df["æ—¥æœŸ"] == target_date].copy()
if day.empty:
    st.warning(f"{target_date} ç„¡å‡ºå‹¤è³‡æ–™ã€‚")
    st.stop()

day[role_col] = normalize_role(day[role_col])
day["å“¡å·¥å§“å"] = day["å“¡å·¥å§“å"].astype(str).str.strip()

# æ’é™¤ä¸»ç®¡ã€åƒ…å·¥æ™‚>0
day = day[~day[role_col].str.contains(EXCLUDE_ROLE_REGEX, na=False)].copy()
day = day[day["å·¥æ™‚"] > 0].copy()

# å§“åå»å°¾ç¢¼å¾Œå»é‡ï¼ˆäººæ¬¡ï¼‰
day["å§“å_å»å°¾ç¢¼"] = day["å“¡å·¥å§“å"].str.replace(NAME_SUFFIX_STRIP_REGEX, "", regex=True).str.strip()
total_headcount = int(day["å§“å_å»å°¾ç¢¼"].nunique())

# å„è·å‹™äººæ¬¡ï¼ˆç¼ºçš„è£œ0ï¼Œå›ºå®šé †åºï¼‰
role_counts = (
    day.groupby(role_col)["å§“å_å»å°¾ç¢¼"]
       .nunique()
       .reindex(ROLE_ORDER, fill_value=0)
       .reset_index()
       .rename(columns={role_col: "è·å‹™", "å§“å_å»å°¾ç¢¼": "äººæ¬¡"})
)

# å·¥æ™‚å½™ç¸½ï¼ˆå›ºå®šé †åº+ç¸½è¨ˆï¼‰
hours_summary = (
    day.groupby(role_col)["å·¥æ™‚"].sum()
       .reindex(ROLE_ORDER, fill_value=0)
       .reset_index()
)
hours_summary.columns = ["è·å‹™", "å·¥æ™‚"]
hours_summary = pd.concat(
    [hours_summary, pd.DataFrame([{"è·å‹™": "ç¸½è¨ˆ", "å·¥æ™‚": hours_summary["å·¥æ™‚"].sum()}])],
    ignore_index=True
)
hours_summary["å·¥æ™‚"] = hours_summary["å·¥æ™‚"].round(2)

# =========================
# é¡¯ç¤ºï¼šäººæ¬¡
# =========================
if HAS_COMMON_UI:
    card_open("ğŸ‘¥ ç•¶æ—¥äººæ¬¡ç¸½è¦½")
else:
    st.subheader("ğŸ‘¥ ç•¶æ—¥äººæ¬¡ç¸½è¦½")

st.caption(TOP_NOTE)

st.metric("ç¸½äººæ¬¡ï¼ˆå»å°¾ç¢¼å»é‡ï¼‰", f"{total_headcount:,}")

cols = st.columns(3)
for i, r in enumerate(role_counts.itertuples(index=False)):
    cols[i % 3].metric(r.è·å‹™, int(r.äººæ¬¡))

if HAS_COMMON_UI:
    card_close()

st.divider()

# =========================
# é¡¯ç¤ºï¼šå·¥æ™‚
# =========================
if HAS_COMMON_UI:
    card_open("ğŸ§¾ å„è·å‹™ç¸½ä¸Šç­æ™‚é–“ï¼ˆå°æ™‚ï¼‰")
else:
    st.subheader("ğŸ§¾ å„è·å‹™ç¸½ä¸Šç­æ™‚é–“ï¼ˆå°æ™‚ï¼‰")

st.dataframe(hours_summary, use_container_width=True, hide_index=True)

# =========================
# ä¸‹è¼‰è¼¸å‡º
# =========================
base = os.path.splitext(uploaded.name)[0]
out_name = f"{base}_{target_date}_å·¥æ™‚èˆ‡äººæ¬¡.xlsx"

download_name, excel_bytes = build_output_excel_bytes(
    role_counts=role_counts,
    total_headcount=total_headcount,
    hours_summary=hours_summary,
    target_date=target_date,
    out_name=out_name,
)

st.download_button(
    label="â¬‡ï¸ ä¸‹è¼‰ Excelï¼ˆå·¥æ™‚èˆ‡äººæ¬¡ï¼‰",
    data=excel_bytes,
    file_name=download_name,
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    use_container_width=True,
)

if HAS_COMMON_UI:
    card_close()
