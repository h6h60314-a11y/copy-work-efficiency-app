# pages/21_é€²è²¨èª² - ä¸Šæ¶é‡é«”.py
# -*- coding: utf-8 -*-
from __future__ import annotations

import os
import re
from io import BytesIO
from typing import Dict, Optional, List, Tuple

import pandas as pd
import streamlit as st

from common_ui import inject_logistics_theme, set_page, card_open, card_close

pd.options.display.max_columns = 200

# =========================
# è¨­å®šï¼ˆæ²¿ç”¨ä½ åŸè…³æœ¬ï¼‰
# =========================
TO_EXCLUDE_KEYWORDS = ["CGS", "JCPL", "QC99", "GREAT0001X", "GX010", "PD99"]
TO_EXCLUDE_PATTERN = re.compile("|".join(re.escape(k) for k in TO_EXCLUDE_KEYWORDS), flags=re.IGNORECASE)

ITEM_CANDIDATES = [
    "ITEM", "Item", "item", "å•†å“", "å“è™Ÿ", "å“é …", "å•†å“ä»£è™Ÿ", "è²¨è™Ÿ", "æ–™è™Ÿ",
    "itemcode", "ItemCode", "ITEMCODE",
]

LOC_KEY_CANDIDATES = ["å„²ä½", "å„²ä½ä»£ç¢¼", "åˆ°", "å„²ä½ç·¨è™Ÿ", "Location", "LOC", "loc"]
LOC_TYPE_COL = "å„²ä½é¡å‹"


# =========================
# è®€æª”ï¼ˆéƒ¨ç½²ç‰ˆï¼šbytesï¼‰
# =========================
def _read_csv_auto(file_bytes: bytes) -> pd.DataFrame:
    last_err = None
    for enc in ("utf-8-sig", "utf-8", "cp950", "big5"):
        try:
            return pd.read_csv(BytesIO(file_bytes), encoding=enc, low_memory=False)
        except Exception as e:
            last_err = e
    raise RuntimeError(f"CSV/TXT è®€å–å¤±æ•—ï¼ˆå·²å˜—è©¦ utf-8-sig/utf-8/cp950/big5ï¼‰ï¼š{last_err}")


def _read_excel_sheets(file_bytes: bytes, ext: str) -> Dict[str, pd.DataFrame]:
    bio = BytesIO(file_bytes)

    if ext in (".xlsx", ".xlsm", ".xltx", ".xltm"):
        try:
            return pd.read_excel(bio, sheet_name=None, engine="openpyxl")
        except Exception:
            bio.seek(0)
            return pd.read_excel(bio, sheet_name=None)

    if ext == ".xls":
        # è‹¥ç’°å¢ƒæ²’ xlrdï¼Œæœƒæç¤ºä½ å…ˆå¦å­˜ xlsx
        try:
            return pd.read_excel(bio, sheet_name=None, engine="xlrd")
        except Exception as e:
            raise RuntimeError("ç›®å‰ç’°å¢ƒå¯èƒ½æœªå®‰è£ xlrdï¼Œ.xls ç„¡æ³•è®€å–ï¼›è«‹å…ˆå¦å­˜ç‚º .xlsx å†ä¸Šå‚³ã€‚") from e

    if ext == ".xlsb":
        try:
            return pd.read_excel(bio, sheet_name=None, engine="pyxlsb")
        except Exception as e:
            raise RuntimeError("ç›®å‰ç’°å¢ƒå¯èƒ½æœªå®‰è£ pyxlsbï¼Œ.xlsb ç„¡æ³•è®€å–ï¼›è«‹å…ˆå¦å­˜ç‚º .xlsx å†ä¸Šå‚³ã€‚") from e

    # fallback
    bio.seek(0)
    return pd.read_excel(bio, sheet_name=None)


def read_any_table_from_upload(uploaded) -> Dict[str, pd.DataFrame]:
    name = uploaded.name
    _, ext = os.path.splitext(name)
    ext = ext.lower()
    b = uploaded.getvalue()

    if ext in (".csv", ".txt"):
        return {"CSV": _read_csv_auto(b)}
    return _read_excel_sheets(b, ext)


# =========================
# å…±ç”¨å·¥å…·ï¼ˆæ²¿ç”¨ä½ åŸè…³æœ¬ï¼‰
# =========================
def normalize_to_qc(series: pd.Series) -> pd.Series:
    s = series.astype(str).str.strip().str.upper()
    return s.eq("QC")


def to_not_excluded_mask(series: pd.Series) -> pd.Series:
    s = series.astype(str).str.strip()
    hit = s.str.contains(TO_EXCLUDE_PATTERN, na=False)
    return ~hit


def rename_item_column(df: pd.DataFrame) -> pd.DataFrame:
    cols = list(df.columns)
    if "ITEM" in cols:
        return df
    for cand in ITEM_CANDIDATES:
        if cand in cols and cand != "ITEM":
            return df.rename(columns={cand: "ITEM"})
    return df


def detect_col(df: pd.DataFrame, candidates) -> Optional[str]:
    for c in candidates:
        if c in df.columns:
            return c
    return None


def classify_high_low(storage_type: str) -> str:
    if pd.isna(storage_type):
        return "ç„¡æ³•å°æ‡‰"
    s = str(storage_type)
    if "é«˜ç©º" in s:
        return "é«˜ç©º"
    if any(k in s for k in ["ä½ç©º", "è¼•å‹", "è½åœ°", "é‡å‹", "GM"]):
        return "ä½ç©º"
    return "æœªçŸ¥"


def process_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    # 1) ç”±=QCï¼ˆè‹¥ç„¡ã€ç”±ã€â†’ å…¨éƒ¨ä¸ä¿ç•™ï¼‰
    mask_qc = normalize_to_qc(df["ç”±"]) if "ç”±" in df.columns else pd.Series(False, index=df.index)
    # 2) åˆ° ä¸å«æ’é™¤é—œéµå­—ï¼ˆè‹¥ç„¡ã€åˆ°ã€â†’ è¦–ç‚ºé€šéï¼‰
    mask_to_ok = to_not_excluded_mask(df["åˆ°"]) if "åˆ°" in df.columns else pd.Series(True, index=df.index)
    return df[mask_qc & mask_to_ok].copy()


def attach_storage_type(df: pd.DataFrame, loc_map: pd.DataFrame, loc_key_map: str) -> pd.DataFrame:
    if "åˆ°" not in df.columns:
        df["å„²ä½é¡å‹"] = pd.NA
        df["é«˜ä½ç©º"] = "ç„¡æ³•å°æ‡‰"
        return df

    map_df = loc_map.copy()
    df["_åˆ°_key_"] = df["åˆ°"].astype(str).str.strip()
    map_df["_loc_key_"] = map_df[loc_key_map].astype(str).str.strip()

    if LOC_TYPE_COL not in map_df.columns:
        raise RuntimeError(f"å„²ä½æ˜ç´°ç¼ºå°‘å¿…è¦æ¬„ä½ã€Œ{LOC_TYPE_COL}ã€ã€‚")

    map_df = map_df[["_loc_key_", LOC_TYPE_COL]].drop_duplicates("_loc_key_")
    out = df.merge(map_df, how="left", left_on="_åˆ°_key_", right_on="_loc_key_")
    out = out.drop(columns=["_åˆ°_key_", "_loc_key_"])
    out["é«˜ä½ç©º"] = out[LOC_TYPE_COL].apply(classify_high_low)
    return out


def _safe_sheet_name(name: str) -> str:
    n = str(name).replace("/", "_").replace("\\", "_").strip()
    return (n[:31] if len(n) > 31 else n) or "Sheet"


def _kpi_text(title: str, value: int):
    st.markdown(f"**{title}**")
    st.markdown(
        f"<div style='font-size:24px; font-weight:900; line-height:1.1; margin-top:2px; margin-bottom:12px;'>{value:,}</div>",
        unsafe_allow_html=True,
    )


def build_output_excel_bytes(
    processed_by_sheet: Dict[str, pd.DataFrame],
    summary_df: pd.DataFrame,
    type_dist_df: Optional[pd.DataFrame],
) -> bytes:
    out = BytesIO()
    with pd.ExcelWriter(out, engine="openpyxl") as writer:
        for sn, df in processed_by_sheet.items():
            df.to_excel(writer, sheet_name=_safe_sheet_name(sn), index=False)

        summary_df.to_excel(writer, sheet_name="å½™ç¸½", index=False)

        if type_dist_df is not None and not type_dist_df.empty:
            type_dist_df.to_excel(writer, sheet_name="å„²ä½é¡å‹åˆ†ä½ˆ", index=False)

    out.seek(0)
    return out.read()


# =========================
# UI
# =========================
inject_logistics_theme()
set_page("é€²è²¨èª²ï½œä¸Šæ¶é‡é«”", icon="ğŸ“¦", subtitle="ç”±=QCï½œåˆ°æ’é™¤é—œéµå­—ï½œå°æ‡‰å„²ä½é¡å‹ï½œé«˜ä½ç©ºçµ±è¨ˆï½œè¼¸å‡ºExcel")

card_open("ğŸ“¦ ä¸Šæ¶é‡é«”ï¼ˆç”±=QC + å„²ä½é«˜ä½ç©ºï¼‰")

main_up = st.file_uploader(
    "ä¸Šå‚³ä¸»æª”ï¼ˆExcel / CSVï¼‰",
    type=["xlsx", "xlsm", "xltx", "xltm", "xls", "xlsb", "csv", "txt"],
    accept_multiple_files=False,
)

storage_up = st.file_uploader(
    "ä¸Šå‚³å„²ä½æ˜ç´°ï¼ˆéœ€å«ï¼šå„²ä½é¡å‹ + å„²ä½éµæ¬„ä½ï¼‰",
    type=["xlsx", "xlsm", "xltx", "xltm", "xls", "xlsb", "csv", "txt"],
    accept_multiple_files=False,
)

st.markdown("---")

if (main_up is None) or (storage_up is None):
    st.info("è«‹å…ˆä¸Šå‚³ã€Œä¸»æª”ã€èˆ‡ã€Œå„²ä½æ˜ç´°ã€ã€‚")
    card_close()
    st.stop()

run = st.button("é–‹å§‹ç”¢å‡º", type="primary")
if not run:
    card_close()
    st.stop()

# è®€æª”
try:
    main_sheets = read_any_table_from_upload(main_up)
    sto_sheets = read_any_table_from_upload(storage_up)
except Exception as e:
    st.error(f"è®€æª”å¤±æ•—ï¼š{e}")
    card_close()
    st.stop()

# å„²ä½æ˜ç´°ï¼šå–ç¬¬ä¸€å¼µè¡¨
sto_first = list(sto_sheets.keys())[0]
sto_df = sto_sheets[sto_first].copy()
sto_df.columns = [str(c).strip() for c in sto_df.columns]

sto_loc_col = detect_col(sto_df, LOC_KEY_CANDIDATES)
if sto_loc_col is None:
    st.error(f"å„²ä½æ˜ç´°æ‰¾ä¸åˆ°å„²ä½éµæ¬„ä½ï¼ˆå€™é¸ï¼š{', '.join(LOC_KEY_CANDIDATES)}ï¼‰ã€‚")
    card_close()
    st.stop()

if LOC_TYPE_COL not in sto_df.columns:
    st.error(f"å„²ä½æ˜ç´°ç¼ºå°‘æ¬„ä½ã€Œ{LOC_TYPE_COL}ã€ã€‚")
    card_close()
    st.stop()

# è™•ç†
processed_by_sheet: Dict[str, pd.DataFrame] = {}
summary_rows: List[dict] = []
totals = {"ITEM": 0, "é«˜ç©º": 0, "ä½ç©º": 0, "æœªçŸ¥": 0, "ç„¡æ³•å°æ‡‰": 0}

all_concat: List[pd.DataFrame] = []

for sn, df in main_sheets.items():
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    df = rename_item_column(df)

    kept = process_dataframe(df)
    kept2 = attach_storage_type(kept, sto_df, sto_loc_col)

    # è¨ˆæ•¸ï¼ˆITEM=ç­†æ•¸ï¼‰
    cnt = int(kept2.shape[0])
    c_high = int((kept2["é«˜ä½ç©º"] == "é«˜ç©º").sum()) if "é«˜ä½ç©º" in kept2.columns else 0
    c_low = int((kept2["é«˜ä½ç©º"] == "ä½ç©º").sum()) if "é«˜ä½ç©º" in kept2.columns else 0
    c_unknown = int((kept2["é«˜ä½ç©º"] == "æœªçŸ¥").sum()) if "é«˜ä½ç©º" in kept2.columns else 0
    c_nomap = int((kept2["é«˜ä½ç©º"] == "ç„¡æ³•å°æ‡‰").sum()) if "é«˜ä½ç©º" in kept2.columns else 0

    processed_by_sheet[sn] = kept2
    all_concat.append(kept2.assign(_Sheet=str(sn)))

    totals["ITEM"] += cnt
    totals["é«˜ç©º"] += c_high
    totals["ä½ç©º"] += c_low
    totals["æœªçŸ¥"] += c_unknown
    totals["ç„¡æ³•å°æ‡‰"] += c_nomap

    summary_rows.append(
        {"Sheet": str(sn), "ITEM": cnt, "é«˜ç©º": c_high, "ä½ç©º": c_low, "æœªçŸ¥": c_unknown, "ç„¡æ³•å°æ‡‰": c_nomap}
    )

summary_rows.append(
    {"Sheet": "ALL", "ITEM": totals["ITEM"], "é«˜ç©º": totals["é«˜ç©º"], "ä½ç©º": totals["ä½ç©º"], "æœªçŸ¥": totals["æœªçŸ¥"], "ç„¡æ³•å°æ‡‰": totals["ç„¡æ³•å°æ‡‰"]}
)
summary_df = pd.DataFrame(summary_rows)

# å„²ä½é¡å‹åˆ†ä½ˆï¼ˆæ•´é«”ï¼‰
type_dist_df = None
all_df = pd.concat(all_concat, ignore_index=True) if all_concat else pd.DataFrame()
if not all_df.empty and LOC_TYPE_COL in all_df.columns:
    type_dist_df = (
        all_df.groupby(LOC_TYPE_COL, dropna=False)
        .size()
        .reset_index(name="ITEM")
        .sort_values("ITEM", ascending=False)
        .reset_index(drop=True)
    )

# é¡¯ç¤º KPIï¼ˆç´”æ–‡å­—ã€ç›´å‘ï¼‰
st.markdown("### ä¸Šæ¶é‡é«”")
_kpi_text("ITEMï¼ˆç”±=QC ä¸” åˆ°é€šéæ’é™¤ï¼‰", totals["ITEM"])
_kpi_text("é«˜ç©º", totals["é«˜ç©º"])
_kpi_text("ä½ç©º", totals["ä½ç©º"])
_kpi_text("æœªçŸ¥", totals["æœªçŸ¥"])
_kpi_text("ç„¡æ³•å°æ‡‰", totals["ç„¡æ³•å°æ‡‰"])

st.markdown("### å½™ç¸½ï¼ˆé€è¡¨ï¼‰")
st.dataframe(summary_df, use_container_width=True, hide_index=True)

if type_dist_df is not None and not type_dist_df.empty:
    st.markdown("### å„²ä½é¡å‹åˆ†ä½ˆï¼ˆæ•´é«”ï¼‰")
    st.dataframe(type_dist_df, use_container_width=True, hide_index=True)

with st.expander("ğŸ” é è¦½ï¼šéæ¿¾å¾Œæ˜ç´°ï¼ˆæ¯å¼µè¡¨å‰ 200 ç­†ï¼‰", expanded=False):
    for sn, df in processed_by_sheet.items():
        st.markdown(f"**{_safe_sheet_name(sn)}**ï¼ˆ{len(df):,} ç­†ï¼‰")
        st.dataframe(df.head(200), use_container_width=True, hide_index=True)

# ç”¢å‡º Excel
try:
    base, _ = os.path.splitext(main_up.name)
    out_bytes = build_output_excel_bytes(processed_by_sheet, summary_df, type_dist_df)
    out_name = f"{base}_ITEM_é«˜ä½ç©º.xlsx"
except Exception as e:
    st.error(f"å¯«æª”å¤±æ•—ï¼š{e}")
    card_close()
    st.stop()

st.download_button(
    "â¬‡ï¸ ä¸‹è¼‰è¼¸å‡º Excel",
    data=out_bytes,
    file_name=out_name,
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
)

card_close()
