from __future__ import annotations

import io
import os
from typing import List, Dict, Tuple

import pandas as pd
import streamlit as st
import openpyxl
from openpyxl.styles import PatternFill, Font

from common_ui import (
    inject_logistics_theme,
    set_page,
    card_open,
    card_close,
)

# =========================
# å˜—è©¦å•Ÿç”¨ Rich Textï¼ˆè‹¥ç‰ˆæœ¬ä¸æ”¯æ´ï¼Œèµ° fallbackï¼‰
# =========================
RICH_OK = True
try:
    from openpyxl.cell.rich_text import CellRichText, TextBlock  # type: ignore
    from openpyxl.cell.text import InlineFont  # type: ignore
except Exception:
    RICH_OK = False


# =========================
# é€šç”¨è®€æª”ï¼šxlsx/xls/htmlå‡xls/csv/tsv
# =========================
def sniff_file_type_bytes(b: bytes) -> str:
    head = b[:8]
    if head[:2] == b"PK":
        return "xlsx"
    if head[:4] == b"\xD0\xCF\x11\xE0":
        return "xls"
    return "text"


def read_table_any_bytes(file_bytes: bytes, filename: str) -> pd.DataFrame:
    ftype = sniff_file_type_bytes(file_bytes)

    if ftype == "xlsx":
        return pd.read_excel(io.BytesIO(file_bytes), engine="openpyxl")

    if ftype == "xls":
        # éœ€è¦ xlrdï¼›ä½ åŸæœ¬ç¨‹å¼å°±æ˜¯é€™æ¨£
        return pd.read_excel(io.BytesIO(file_bytes), engine="xlrd")

    # HTML è¡¨æ ¼ï¼ˆERP å‡ xls å¸¸è¦‹ï¼‰
    try:
        tables = pd.read_html(io.BytesIO(file_bytes), encoding="utf-8", flavor="lxml")
        if tables and len(tables[0].columns) > 1:
            return tables[0]
    except Exception:
        pass

    # CSV/TSV çŒœåˆ†éš”ç¬¦èˆ‡ç·¨ç¢¼
    encodings = ["utf-8-sig", "cp950", "big5", "utf-8"]
    seps = ["\t", ",", ";", "|"]
    last_err = None
    for enc in encodings:
        for sep in seps:
            try:
                df = pd.read_csv(io.BytesIO(file_bytes), encoding=enc, sep=sep, engine="python")
                if df.shape[1] >= 2:
                    return df
            except Exception as e:
                last_err = e

    raise ValueError(f"âŒ ç„¡æ³•è¾¨è­˜æª”æ¡ˆç‚º Excel æˆ–æ–‡å­—è¡¨æ ¼ï¼š{filename}\næœ€å¾ŒéŒ¯èª¤ï¼š{last_err}")


# =========================
# å„²ä½æ˜ç´°ï¼šè‡ªå‹•æŠ“æ¬„ä½ + å»ºç«‹ å„²ä½ -> æ£šåˆ¥ å°ç…§
# =========================
def detect_col(df: pd.DataFrame, candidates: List[str]) -> str | None:
    cols = [str(c).strip() for c in df.columns]
    for cand in candidates:
        if cand in cols:
            return cand
    # æ”¾å¯¬ï¼šåŒ…å«é—œéµå­—
    for cand in candidates:
        for c in cols:
            if cand in c:
                return c
    return None


def build_loc_to_shelf(slot_df: pd.DataFrame) -> Dict[str, str]:
    slot_df = slot_df.copy()
    slot_df.columns = slot_df.columns.astype(str).str.strip()

    loc_col = detect_col(slot_df, ["å„²ä½", "å„²ä½ç·¨è™Ÿ", "Location", "LOC", "Loc"])
    shelf_col = detect_col(slot_df, ["æ£šåˆ¥", "æ£šæ¶", "Shelf", "SHELF"])

    if not loc_col or not shelf_col:
        raise ValueError(
            "âŒ å„²ä½æ˜ç´°æŠ“ä¸åˆ°å¿…è¦æ¬„ä½ã€‚\n"
            f"æ‰¾åˆ°å„²ä½æ¬„ï¼š{loc_col}\n"
            f"æ‰¾åˆ°æ£šåˆ¥æ¬„ï¼š{shelf_col}\n"
            f"ç›®å‰æ¬„ä½ï¼š{slot_df.columns.tolist()}"
        )

    tmp = slot_df[[loc_col, shelf_col]].copy()
    tmp[loc_col] = tmp[loc_col].astype(str).str.strip()
    tmp[shelf_col] = tmp[shelf_col].astype(str).str.strip()
    tmp = tmp[(tmp[loc_col] != "") & (tmp[loc_col].str.lower() != "nan")]

    return dict(zip(tmp[loc_col], tmp[shelf_col]))


# =========================
# å°‘æ€æª”ï¼šå„è‡ªè¨ˆç®— -> final_df (å°šæœªåŠ æ£šåˆ¥æ¬„)
# =========================
def process_one_short(
    df_original: pd.DataFrame,
    barcode_df: pd.DataFrame,
    stock_df: pd.DataFrame,
) -> Tuple[pd.DataFrame, int]:
    """
    ä¿ç•™ä½ åŸæœ¬é‚è¼¯ï¼š
    - RFæ€è²¨é‡ >= 0
    - pivot å•†å“å½™ç¸½ï¼šå·®ç•°é‡ = RF - æ‡‰æ€ï¼›å–å·®ç•°é‡ < 0
    - å¤šæ•ˆæœŸå±•é–‹ï¼ˆæ¯å•†å“æ¯æ•ˆæœŸä¸€åˆ—ï¼‰
    - åˆä½µåœ‹éš›æ¢ç¢¼
    - åº«å­˜éæ¿¾ï¼šå•†å“è™Ÿã€Canuseqty>0ã€æ’é™¤ç‰¹å®šå„²ä½
    - å±•é–‹å„²ä½/æ•ˆæœŸ pairsï¼ˆå„²ä½1/æ•ˆæœŸ1â€¦ï¼‰
    """
    df_original = df_original.copy()
    df_original.columns = df_original.columns.astype(str).str.strip()

    # ä½ åŸæœ¬å°±å‡è¨­é€™äº›æ¬„ä½å­˜åœ¨
    required = ["å•†å“", "æ‡‰æ€é‡", "RFæ€è²¨é‡", "æ•ˆæœŸ"]
    miss = [c for c in required if c not in df_original.columns]
    if miss:
        raise ValueError(f"âŒ å°‘æ€æ˜ç´°ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{miss}\nç›®å‰æ¬„ä½ï¼š{df_original.columns.tolist()}")

    df_original = df_original[df_original["RFæ€è²¨é‡"] >= 0].copy()

    pivot = pd.pivot_table(
        df_original,
        index="å•†å“",
        values=["æ‡‰æ€é‡", "RFæ€è²¨é‡"],
        aggfunc="sum",
    )
    pivot["å·®ç•°é‡"] = pivot["RFæ€è²¨é‡"] - pivot["æ‡‰æ€é‡"]
    underpicked = pivot[pivot["å·®ç•°é‡"] < 0].copy()

    # å¤šæ•ˆæœŸå±•é–‹ï¼ˆæ¯ç¨®æ•ˆæœŸå„ä¸€åˆ—ï¼‰
    result_rows = []
    for product in underpicked.index:
        exps = df_original.loc[df_original["å•†å“"] == product, "æ•ˆæœŸ"].dropna().unique().tolist()
        if len(exps) == 0:
            result_rows.append(
                [
                    product,
                    underpicked.at[product, "æ‡‰æ€é‡"],
                    underpicked.at[product, "RFæ€è²¨é‡"],
                    underpicked.at[product, "å·®ç•°é‡"],
                    None,
                ]
            )
        elif len(exps) == 1:
            result_rows.append(
                [
                    product,
                    underpicked.at[product, "æ‡‰æ€é‡"],
                    underpicked.at[product, "RFæ€è²¨é‡"],
                    underpicked.at[product, "å·®ç•°é‡"],
                    exps[0],
                ]
            )
        else:
            for exp in sorted(exps):
                result_rows.append(
                    [
                        product,
                        underpicked.at[product, "æ‡‰æ€é‡"],
                        underpicked.at[product, "RFæ€è²¨é‡"],
                        underpicked.at[product, "å·®ç•°é‡"],
                        exp,
                    ]
                )

    result_df = pd.DataFrame(result_rows, columns=["å•†å“", "æ‡‰æ€é‡", "RFæ€è²¨é‡", "å·®ç•°é‡", "æ•ˆæœŸ"])
    result_df["æ•ˆæœŸ"] = pd.to_datetime(result_df["æ•ˆæœŸ"], errors="coerce").dt.strftime("%Y/%m/%d")

    # åˆä½µåœ‹éš›æ¢ç¢¼
    bc = barcode_df.copy()
    bc.columns = bc.columns.astype(str).str.strip()
    if "å•†å“è™Ÿ" in bc.columns and "å•†å“" not in bc.columns:
        bc = bc.rename(columns={"å•†å“è™Ÿ": "å•†å“"})
    if "åœ‹éš›æ¢ç¢¼" in bc.columns and "å•†å“" in bc.columns:
        result_df = result_df.merge(bc[["å•†å“", "åœ‹éš›æ¢ç¢¼"]], on="å•†å“", how="left")

    result_df = result_df.drop_duplicates(subset=["å•†å“", "æ•ˆæœŸ"]).reset_index(drop=True)

    # åº«å­˜éæ¿¾
    st_df = stock_df.copy()
    st_df.columns = st_df.columns.astype(str).str.strip()

    # ä½ åŸæœ¬ä½¿ç”¨é€™äº›æ¬„ä½åï¼ˆè‹¥ä¸åŒå¯åœ¨ä½ çš„å…±ç”¨æª”å…§å…ˆä¿®æ¬„åï¼‰
    required_stock = ["å•†å“è™Ÿ", "å„²ä½", "Canuseqty", "å•†å“æ•ˆæœŸ"]
    miss2 = [c for c in required_stock if c not in st_df.columns]
    if miss2:
        raise ValueError(f"âŒ åº«å­˜æ˜ç´°ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{miss2}\nç›®å‰æ¬„ä½ï¼š{st_df.columns.tolist()}")

    st_df["å•†å“æ•ˆæœŸ"] = pd.to_datetime(st_df.get("å•†å“æ•ˆæœŸ"), errors="coerce").dt.strftime("%Y/%m/%d")

    excluded_locations = ["QC", "PD99", "QC99", "JCPL", "GRP", "CGS"]
    stock_filtered = st_df[
        (st_df["å•†å“è™Ÿ"].isin(result_df["å•†å“"]))
        & (st_df["Canuseqty"] > 0)
        & (~st_df["å„²ä½"].isin(excluded_locations))
    ].copy()

    # ä¾ã€Œå•†å“ + ä¸»æ•ˆæœŸã€å–åº«å­˜çš„å„²ä½èˆ‡æ•ˆæœŸï¼Œå±•é–‹æˆ pairs æ¬„ä½
    expanded_rows = []
    max_pairs = 0

    for _, row in result_df.iterrows():
        product = row["å•†å“"]
        main_exp = row["æ•ˆæœŸ"]

        sub = stock_filtered[stock_filtered["å•†å“è™Ÿ"] == product].copy()
        # ä½ åŸæœ¬æ²’æœ‰å¼·åˆ¶åº«å­˜æ•ˆæœŸ==ä¸»æ•ˆæœŸï¼Œåªæ˜¯åœ¨å¾Œé¢åšã€Œæ•ˆæœŸä¸€è‡´ç¶ åº•ã€
        # é€™è£¡ä¿ç•™ï¼šå…¨éƒ¨å¯ç”¨åº«å­˜éƒ½åˆ—
        pairs = list(zip(sub["å„²ä½"].astype(str).tolist(), sub["å•†å“æ•ˆæœŸ"].astype(str).tolist()))
        max_pairs = max(max_pairs, len(pairs))

        expanded_rows.append(list(row.values) + [v for pair in pairs for v in pair])

    pair_cols = []
    for i in range(max_pairs):
        pair_cols += [f"å„²ä½{i+1}", f"æ•ˆæœŸ{i+1}"]

    final_df = pd.DataFrame(expanded_rows, columns=result_df.columns.tolist() + pair_cols)
    return final_df, max_pairs


# =========================
# çµ„åˆæ¬„ä½ï¼šçµ±ä¸€æœ€å¤§å°æ•¸ã€æ’å…¥æ£šåˆ¥æ¬„ã€å›ºå®šæ¬„ä½é †åº
# =========================
def normalize_and_add_shelf(df: pd.DataFrame, max_pairs: int, loc_to_shelf: Dict[str, str]) -> pd.DataFrame:
    df = df.copy()
    for i in range(1, max_pairs + 1):
        if f"å„²ä½{i}" not in df.columns:
            df[f"å„²ä½{i}"] = None
        if f"æ•ˆæœŸ{i}" not in df.columns:
            df[f"æ•ˆæœŸ{i}"] = None

    # å¾å¾Œå¾€å‰æ’å…¥æ£šåˆ¥æ¬„ï¼ˆè·Ÿä½ åŸç‰ˆä¸€è‡´ï¼‰
    for i in range(max_pairs, 0, -1):
        loc_col = f"å„²ä½{i}"
        shelf_col = f"æ£šåˆ¥{i}"
        if shelf_col not in df.columns and loc_col in df.columns:
            idx = df.columns.get_loc(loc_col)
            shelves = df[loc_col].astype(str).str.strip().map(loc_to_shelf).fillna("ç„¡æ³•å°æ‡‰")
            shelves = shelves.where(df[loc_col].notna(), None)
            df.insert(idx + 1, shelf_col, shelves)

    base_cols = ["å•†å“", "æ‡‰æ€é‡", "RFæ€è²¨é‡", "å·®ç•°é‡", "æ•ˆæœŸ", "åœ‹éš›æ¢ç¢¼"]
    ordered = [c for c in base_cols if c in df.columns]
    for i in range(1, max_pairs + 1):
        ordered += [f"å„²ä½{i}", f"æ£šåˆ¥{i}", f"æ•ˆæœŸ{i}"]

    rest = [c for c in df.columns if c not in ordered]
    return df[ordered + rest]


# =========================
# Excel è¼”åŠ©
# =========================
def write_headers(ws, columns: List[str]):
    for c, name in enumerate(columns, start=1):
        ws.cell(row=1, column=c, value=name)


def write_df_rows(ws, df: pd.DataFrame, start_row: int) -> int:
    end_row = start_row - 1
    for r_i, row in enumerate(df.itertuples(index=False), start=start_row):
        for c_i, val in enumerate(row, start=1):
            ws.cell(row=r_i, column=c_i, value=val)
        end_row = r_i
    return end_row


def find_col_index(ws, header_name: str) -> int | None:
    for c in range(1, ws.max_column + 1):
        if ws.cell(row=1, column=c).value == header_name:
            return c
    return None


def normalize_barcode_value(v) -> str:
    """æŠŠå¯èƒ½æ˜¯æ•¸å­—/æµ®é»/ç§‘å­¸è¨˜è™Ÿçš„æ¢ç¢¼å®‰å…¨è½‰æˆå­—ä¸²ï¼Œä¸¦ç›¡é‡è£œ 13 ç¢¼"""
    if v is None:
        return ""
    s = str(v).strip()
    if s == "" or s.lower() == "nan":
        return ""
    if s.endswith(".0"):
        s = s[:-2]
    if s.isdigit() and len(s) < 13:
        s = s.zfill(13)
    return s


def apply_barcode_last5_big_all(ws, barcode_col: int, start_row: int = 2) -> bool:
    """
    å…¨æ¬„å¥—ç”¨ï¼šåœ‹éš›æ¢ç¢¼åŒä¸€æ ¼å¾Œäº”ç¢¼æ”¾å¤§ï¼ˆRichTextï¼‰ã€‚
    True=æˆåŠŸï¼›False=ä¸æ”¯æ´æˆ–å¤±æ•—ã€‚
    """
    if not RICH_OK:
        return False

    normal_f = InlineFont(sz=11)  # type: ignore
    big_f = InlineFont(sz=16, b=True)  # type: ignore

    try:
        for r in range(start_row, ws.max_row + 1):
            ws.cell(row=r, column=barcode_col).number_format = "@"

        for r in range(start_row, ws.max_row + 1):
            cell = ws.cell(row=r, column=barcode_col)
            s = normalize_barcode_value(cell.value)
            if not s:
                continue

            last5 = s[-5:] if len(s) >= 5 else s
            prefix = s[:-5] if len(s) >= 5 else ""

            rich = CellRichText()  # type: ignore
            if prefix:
                rich.append(TextBlock(normal_f, prefix))  # type: ignore
            rich.append(TextBlock(big_f, last5))  # type: ignore
            cell.value = rich

        return True
    except Exception:
        return False


def add_barcode_last5_column_fallback(ws, barcode_col: int):
    """
    è‹¥ RichText ä¸æ”¯æ´ï¼šæ–°å¢ã€åœ‹éš›æ¢ç¢¼_å¾Œäº”ç¢¼ã€æ¬„ä¸¦æ•´æ ¼æ”¾å¤§ã€‚
    """
    insert_pos = barcode_col + 1
    ws.insert_cols(insert_pos)
    ws.cell(row=1, column=insert_pos, value="åœ‹éš›æ¢ç¢¼_å¾Œäº”ç¢¼")

    big_font = Font(size=16, bold=True)
    for r in range(2, ws.max_row + 1):
        s = normalize_barcode_value(ws.cell(row=r, column=barcode_col).value)
        last5 = s[-5:] if len(s) >= 5 else s
        c = ws.cell(row=r, column=insert_pos, value=last5)
        c.font = big_font


def build_export_xlsx_bytes(dfs2: List[pd.DataFrame], output_sheet_name: str = "çµæœ") -> Tuple[bytes, str]:
    """
    - å–®ä¸€å·¥ä½œè¡¨
    - å¤šæª”æ¥çºŒè²¼ä¸Šï¼ˆä¸ç•™ç©ºç™½è¡Œï¼‰
    - ç¶ åº•ï¼šæ•ˆæœŸ2/æ•ˆæœŸ3â€¦ == ä¸»æ•ˆæœŸ
    - é»ƒåº•ï¼šç¬¬äºŒä»½å°‘æ€æª”å€å¡Šåªé»ƒåœ‹éš›æ¢ç¢¼æ¬„
    - åœ‹éš›æ¢ç¢¼å¾Œäº”ç¢¼æ”¾å¤§ï¼ˆRichText æˆ– fallback æ¬„ï¼‰
    """
    if not dfs2:
        raise ValueError("âŒ æ²’æœ‰å¯è¼¸å‡ºçš„è³‡æ–™")

    wb = openpyxl.Workbook()
    ws = wb.active
    ws.title = output_sheet_name

    columns = list(dfs2[0].columns)
    write_headers(ws, columns)

    blocks = []
    cur_row = 2
    for idx, df in enumerate(dfs2, start=1):
        start = cur_row
        end = write_df_rows(ws, df, start_row=start)
        blocks.append({"idx": idx, "start": start, "end": end})
        cur_row = end + 1

    green_fill = PatternFill(start_color="C6EFCE", end_color="C6EFCE", fill_type="solid")
    yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")

    main_exp_col = find_col_index(ws, "æ•ˆæœŸ")
    barcode_col = find_col_index(ws, "åœ‹éš›æ¢ç¢¼")
    if main_exp_col is None:
        raise ValueError("âŒ æ‰¾ä¸åˆ°ä¸»æ¬„ä½ã€æ•ˆæœŸã€ï¼Œè«‹ç¢ºèªè¼¸å‡ºè¡¨é ­")
    if barcode_col is None:
        raise ValueError("âŒ æ‰¾ä¸åˆ°æ¬„ä½ã€åœ‹éš›æ¢ç¢¼ã€ï¼Œè«‹ç¢ºèªè¼¸å‡ºè¡¨é ­")

    exp_cols = []
    for c in range(1, ws.max_column + 1):
        header = ws.cell(row=1, column=c).value
        if isinstance(header, str) and header.startswith("æ•ˆæœŸ") and header != "æ•ˆæœŸ":
            exp_cols.append(c)

    # æ¨™è‰²ï¼šæ•ˆæœŸä¸€è‡´ -> ç¶ åº•ï¼ˆæ¬„ä½ï¼šæ•ˆæœŸ2/æ•ˆæœŸ3...ï¼‰
    for r in range(2, ws.max_row + 1):
        ref = ws.cell(row=r, column=main_exp_col).value
        if ref in (None, "", "nan"):
            continue
        for c in exp_cols:
            if ws.cell(row=r, column=c).value == ref:
                ws.cell(row=r, column=c).fill = green_fill

    # å…¨æ¬„å¾Œäº”ç¢¼æ”¾å¤§
    used_rich = apply_barcode_last5_big_all(ws, barcode_col, start_row=2)
    if not used_rich:
        add_barcode_last5_column_fallback(ws, barcode_col)

    # ç¬¬äºŒä»½ï¼šåªé»ƒåœ‹éš›æ¢ç¢¼æ¬„
    block2 = next((b for b in blocks if b["idx"] == 2), None)
    if block2:
        # è‹¥ fallback æ’å…¥äº†æ–°æ¬„ï¼Œbarcode_col ä½ç½®ä»æ˜¯åŸæœ¬çš„åœ‹éš›æ¢ç¢¼æ¬„ï¼ˆæ²’è®Šï¼‰
        for r in range(block2["start"], block2["end"] + 1):
            ws.cell(row=r, column=barcode_col).fill = yellow_fill

    out = io.BytesIO()
    wb.save(out)
    wb.close()

    note = "RichText" if used_rich else "Fallback(æ–°å¢å¾Œäº”ç¢¼æ¬„)"
    return out.getvalue(), note


# =========================
# Streamlit Page
# =========================
def main():
    inject_logistics_theme()
    set_page("æ€è²¨å·®ç•°åˆ†æï¼ˆåº«å­˜å®šä½å¼·åŒ–ï¼‰", icon="ğŸ”", subtitle="å°‘æ€å·®ç•°ï½œåº«å­˜å„²ä½å±•é–‹ï½œæ£šåˆ¥å°æ‡‰ï½œåœ‹éš›æ¢ç¢¼å¾Œäº”ç¢¼æ”¾å¤§")

    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        st.caption("ä¾åŸé‚è¼¯ï¼šå°‘æ€å¯å¤šæª”ä¸Šå‚³ï¼Œæœƒä¾åºæ¥çºŒè¼¸å‡ºåˆ°åŒä¸€å¼µ Sheet")
        show_preview_rows = st.number_input("é è¦½ç­†æ•¸", min_value=50, max_value=5000, value=500, step=50)

    card_open("ğŸ“¤ æª”æ¡ˆä¸Šå‚³")
    short_files = st.file_uploader(
        "å°‘æ€æ˜ç´°ï¼ˆå¯å¤šé¸ï¼‰",
        type=["xlsx", "xls", "xlsm", "csv", "txt"],
        accept_multiple_files=True,
    )
    common_file = st.file_uploader(
        "å•†å“å°ç…§è¡¨ / åº«å­˜æ˜ç´°ï¼ˆåŒä¸€å€‹æª”ï¼‰",
        type=["xlsx", "xls", "xlsm", "csv", "txt"],
        accept_multiple_files=False,
    )
    slot_file = st.file_uploader(
        "å„²ä½æ˜ç´°ï¼ˆå«æ£šåˆ¥ï¼‰",
        type=["xlsx", "xls", "xlsm", "csv", "txt"],
        accept_multiple_files=False,
    )

    run = st.button("ğŸš€ ç”¢å‡ºåˆ†æ", type="primary", disabled=(not short_files or not common_file or not slot_file))
    card_close()

    if not run:
        st.info("è«‹ä¾åºä¸Šå‚³ï¼šå°‘æ€æ˜ç´°ï¼ˆå¯å¤šæª”ï¼‰ï¼‹ å•†å“å°ç…§/åº«å­˜æ˜ç´°ï¼ˆåŒæª”ï¼‰ï¼‹ å„²ä½æ˜ç´°ï¼ˆå«æ£šåˆ¥ï¼‰")
        return

    try:
        with st.spinner("è³‡æ–™è™•ç†ä¸­..."):
            # å…±åŒæª”ï¼šåŒä¸€æª”è®€å…©æ¬¡ï¼ˆä¿ç•™ä½ åŸæœ¬é‚è¼¯ï¼‰
            common_xlsx = read_table_any_bytes(common_file.getvalue(), common_file.name)
            barcode_df = common_xlsx.copy()
            stock_df = common_xlsx.copy()

            # åœ‹éš›æ¢ç¢¼è£œ 13 ç¢¼ï¼ˆç©ºå€¼ä¿ç•™ç©ºï¼‰
            barcode_df.columns = barcode_df.columns.astype(str).str.strip()
            if "åœ‹éš›æ¢ç¢¼" in barcode_df.columns:
                barcode_df["åœ‹éš›æ¢ç¢¼"] = barcode_df["åœ‹éš›æ¢ç¢¼"].apply(
                    lambda x: str(x).zfill(13) if pd.notna(x) and str(x).strip() != "" else ""
                )

            # å„²ä½æ˜ç´° -> å„²ä½:æ£šåˆ¥ map
            slot_df = read_table_any_bytes(slot_file.getvalue(), slot_file.name)
            loc_to_shelf = build_loc_to_shelf(slot_df)

            # æ¯ä»½å°‘æ€æª”å„è‡ªç®—å‡º dfï¼ˆä¸åˆä½µè¨ˆç®—ï¼‰
            dfs = []
            max_pairs_global = 0

            for f in short_files:
                df_original = read_table_any_bytes(f.getvalue(), f.name)
                final_df, max_pairs = process_one_short(df_original, barcode_df, stock_df)
                # é è¦½/è¾¨è­˜ç”¨ï¼šåŠ æ‰¹æ¬¡èˆ‡æª”åï¼ˆä¸å½±éŸ¿ä½ åŸæœ¬é‹ç®—ï¼‰
                final_df.insert(0, "æ‰¹æ¬¡", os.path.basename(f.name))
                dfs.append(final_df)
                max_pairs_global = max(max_pairs_global, max_pairs)

            # çµ±ä¸€æ¬„ä½ + æ’å…¥æ£šåˆ¥ + å›ºå®šé †åº
            dfs2 = []
            for df in dfs:
                # normalize_and_add_shelf æœŸæœ› base_cols é–‹é ­æ˜¯å•†å“...ï¼›é€™è£¡æ‰¹æ¬¡åœ¨æœ€å‰é¢ï¼Œæ‰€ä»¥å…ˆæš«å­˜å†æ’å›
                batch = df["æ‰¹æ¬¡"].copy()
                df2 = df.drop(columns=["æ‰¹æ¬¡"]).copy()
                df2 = normalize_and_add_shelf(df2, max_pairs_global, loc_to_shelf)
                df2.insert(0, "æ‰¹æ¬¡", batch.values)
                dfs2.append(df2)

            # åˆä½µé è¦½ï¼ˆç•«é¢ç”¨ï¼‰
            preview_df = pd.concat(dfs2, ignore_index=True)

            # åŒ¯å‡º bytes
            xlsx_bytes, mode_note = build_export_xlsx_bytes(dfs2, output_sheet_name="çµæœ")

        card_open("ğŸ§¾ çµæœé è¦½")
        st.caption(f"åŒ¯å‡ºè™•ç†ï¼šåœ‹éš›æ¢ç¢¼å¾Œäº”ç¢¼æ”¾å¤§æ¨¡å¼ = {mode_note}")
        st.dataframe(preview_df.head(int(show_preview_rows)), use_container_width=True, hide_index=True)
        card_close()

        st.download_button(
            "â¬‡ï¸ åŒ¯å‡ºå ±è¡¨ï¼ˆExcelï¼‰",
            data=xlsx_bytes,
            file_name="æ€è²¨å·®ç•°_å¤šæª”æ¥çºŒè¼¸å‡º_å«æ£šåˆ¥_å¾Œäº”ç¢¼æ”¾å¤§.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

    except Exception as e:
        st.error("âŒ åŸ·è¡Œå¤±æ•—")
        st.code(str(e))


if __name__ == "__main__":
    main()
