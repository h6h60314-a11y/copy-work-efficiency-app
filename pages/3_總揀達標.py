# pages/3_ç¸½æ€é”æ¨™.py
# ------------------------------------------------------------
#  ç¸½æ€é”æ¨™çé‡‘è¨ˆç®—å ±è¡¨ï¼ˆåˆä½µç‰ˆï¼šä¸Šåˆ + ä¸‹åˆåŒé å‘ˆç¾ï¼‰
#  - ç¬¬ä¸€éšæ®µï¼šä¸Šåˆï¼ˆ<=12:30ï¼Œä¼‘æ¯ 10:00-10:15ï¼‰
#  - ç¬¬äºŒéšæ®µï¼šä¸‹åˆï¼ˆ13:30-18:00ï¼Œä¼‘æ¯ 15:30-15:45ï¼‰
#  - ç‰ˆé¢ï¼šåŒä¸€å€‹ Sheet1 ä¸Šä¸‹åˆ†æ®µ
#  - åŒ¯å‡ºï¼šopenpyxlï¼ˆé¿å… Streamlit Cloud ç¼º xlsxwriterï¼‰
#  - ç•«é¢ KPI è¡¨æ ¼ï¼šæ•´åˆ—ç´…/ç¶ åº•ï¼ˆä¾å€åŸŸ+æ•ˆç‡é–€æª»ï¼‰
# ------------------------------------------------------------

from __future__ import annotations

import io
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional

import pandas as pd
import streamlit as st

from common_ui import inject_logistics_theme, set_page, card_open, card_close


# ---------- å¯è¦–åƒæ•¸ -------------------------------------------------
# ä¸Šåˆ
MORNING_END = datetime.strptime("12:30:00", "%H:%M:%S").time()
M_REST_START = datetime.strptime("10:00:00", "%H:%M:%S").time()
M_REST_END = datetime.strptime("10:15:00", "%H:%M:%S").time()

# ä¸‹åˆ
AFTERNOON_START = datetime.strptime("13:30:00", "%H:%M:%S").time()
AFTERNOON_END = datetime.strptime("18:00:00", "%H:%M:%S").time()
A_REST_START = datetime.strptime("15:30:00", "%H:%M:%S").time()
A_REST_END = datetime.strptime("15:45:00", "%H:%M:%S").time()

IDLE_THRESHOLD = timedelta(minutes=10)  # ç©ºçª—é–€æª»
default_start_time_str = "08:05:00"

# ---------- æ€è²¨äººé è¨­è³‡æ–™ ------------------------------------------
# è‹¥ã€Œå€åŸŸã€ç•™ç©º â†’ ä»¥ã€Œä½ç©ºã€è™•ç†ï¼ˆåŸæ¨£ä¿ç•™ï¼‰
preset_picker_info: Dict[str, Dict[str, str]] = {
    "20230412002": {"å§“å": "å³ç§‰ä¸", "èµ·å§‹æ™‚é–“": "8:05:00", "å€åŸŸ": "ä½ç©º"},
    "20200812002": {"å§“å": "å½­æ…ˆæš‰", "èµ·å§‹æ™‚é–“": "7:05:00", "å€åŸŸ": "ä½ç©º"},
    "20210104001": {"å§“å": "æ¥Šæ‰¿ç‰", "èµ·å§‹æ™‚é–“": "7:05:00", "å€åŸŸ": "ä½ç©º"},
    "20201109001": {"å§“å": "æ¢å† å¦‚", "èµ·å§‹æ™‚é–“": "8:05:00", "å€åŸŸ": "ä½ç©º"},
    "20201109003": {"å§“å": "å³æŒ¯å‡±", "èµ·å§‹æ™‚é–“": "8:05:00", "å€åŸŸ": "ä½ç©º"},
    "20231226003": {"å§“å": "é¡ç§€è", "èµ·å§‹æ™‚é–“": "8:05:00", "å€åŸŸ": "ä½ç©º"},
    "20200922002": {"å§“å": "è‘‰æ¬²å¼˜", "èµ·å§‹æ™‚é–“": "8:05:00", "å€åŸŸ": "ä½ç©º"},
    "20200924001": {"å§“å": "é»ƒé›…å›", "èµ·å§‹æ™‚é–“": "8:05:00", "å€åŸŸ": "ä½ç©º"},
}


# =========================================================
# å°å·¥å…·ï¼šä¸­æ–‡å§“å / mappingï¼ˆä¿ç•™æ—¢æœ‰é‚è¼¯ï¼‰
# =========================================================
def _get_name(picker_id: str, mapping: Dict[str, Dict[str, str]]) -> str:
    if picker_id in mapping and (mapping[picker_id].get("å§“å") or "").strip():
        return str(mapping[picker_id].get("å§“å")).strip()
    if picker_id in preset_picker_info:
        return str(preset_picker_info[picker_id].get("å§“å", "")).strip()
    return ""


def _get_start_time(picker_id: str, mapping: Dict[str, Dict[str, str]]) -> str:
    if picker_id in mapping and (mapping[picker_id].get("èµ·å§‹æ™‚é–“") or "").strip():
        return str(mapping[picker_id].get("èµ·å§‹æ™‚é–“")).strip()
    if picker_id in preset_picker_info:
        return str(preset_picker_info[picker_id].get("èµ·å§‹æ™‚é–“", default_start_time_str)).strip()
    return default_start_time_str


def _get_region(picker_id: str, mapping: Dict[str, Dict[str, str]]) -> str:
    if picker_id in mapping and (mapping[picker_id].get("å€åŸŸ") or "").strip():
        return str(mapping[picker_id].get("å€åŸŸ")).strip()
    if picker_id in preset_picker_info:
        return str(preset_picker_info[picker_id].get("å€åŸŸ", "ä½ç©º")).strip() or "ä½ç©º"
    return "ä½ç©º"


def _storage_area_str(records: pd.DataFrame) -> str:
    # ç›¡é‡ä¿æŒåŸæ¨£ï¼šè‹¥æœ‰å„²ä½æ¬„ä½å‰‡ç”¨å„²ä½å‰ç¶´å½™ç¸½
    if records is None or records.empty:
        return ""
    if "å„²ä½" not in records.columns:
        return ""
    vals = records["å„²ä½"].dropna().astype(str).str.strip()
    vals = vals[vals != ""]
    if vals.empty:
        return ""
    # å–å‰2-3ç¢¼åšç°¡æ˜“èšåˆï¼ˆä¿ç•™ä½ çš„æ—¢æœ‰ç¿’æ…£ï¼‰
    head = vals.str[:2].value_counts()
    top = head.head(8).index.tolist()
    return ",".join(top)


def parse_tw_datetime(series: pd.Series) -> pd.Series:
    # åŸæ¨£ä¿ç•™ï¼šå®¹éŒ¯è§£æ
    return pd.to_datetime(series, errors="coerce")


def ensure_datetime(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    if "æ€è²¨å®Œæˆæ™‚é–“" in df.columns:
        df["æ€è²¨å®Œæˆæ™‚é–“"] = parse_tw_datetime(df["æ€è²¨å®Œæˆæ™‚é–“"])
    return df


# =========================================================
# å‰è™•ç†ï¼šè®€æª”ã€å»æˆç®±ã€åˆä½µåˆ—ï¼ˆä¿ç•™åŸé‚è¼¯ï¼‰
# =========================================================
def _load_uploaded_files(files: List[st.runtime.uploaded_file_manager.UploadedFile]) -> pd.DataFrame:
    frames: List[pd.DataFrame] = []
    for f in files:
        name = (f.name or "").lower()
        b = f.getvalue()
        try:
            if name.endswith(".csv"):
                frames.append(pd.read_csv(io.BytesIO(b)))
            else:
                frames.append(pd.read_excel(io.BytesIO(b)))
        except Exception:
            # è®€ä¸åˆ°å°±è·³é
            continue
    if not frames:
        return pd.DataFrame()
    return pd.concat(frames, ignore_index=True)


def remove_boxed_rows(df: pd.DataFrame) -> pd.DataFrame:
    # ä¿ç•™åŸæœ¬è¦å‰‡ï¼šæˆç®±ç®±è™Ÿç‚ºç©ºæ‰ç´å…¥
    if df is None or df.empty:
        return df
    if "æˆç®±ç®±è™Ÿ" in df.columns:
        tmp = df.copy()
        tmp["æˆç®±ç®±è™Ÿ"] = tmp["æˆç®±ç®±è™Ÿ"].astype(str).fillna("").str.strip()
        tmp = tmp[tmp["æˆç®±ç®±è™Ÿ"] == ""]
        return tmp
    return df


def combine_rows(df: pd.DataFrame) -> pd.DataFrame:
    # èˆ‡ä½ åˆä½µç‰ˆä¸€è‡´ï¼šåŒå„²ä½/å•†å“/æ€è²¨äºº/å®Œæˆæ™‚é–“ â†’ æ•¸é‡åŠ ç¸½
    if df is None or df.empty:
        return df
    group_cols = ["å„²ä½", "å•†å“", "æ€è²¨äºº", "æ€è²¨å®Œæˆæ™‚é–“"]
    for c in group_cols:
        if c not in df.columns:
            # è‹¥ç¼ºæ¬„ä½ï¼Œç›´æ¥å›å‚³åŸ dfï¼ˆé¿å…ç ´å£ä½ æ—¢æœ‰è³‡æ–™ï¼‰
            return df

    if "æ•¸é‡" not in df.columns:
        df = df.copy()
        df["æ•¸é‡"] = 1

    combined_df = df.groupby(group_cols, as_index=False).agg({"æ•¸é‡": "sum"})
    return combined_df


# =========================================================
# ä¸Šåˆ/ä¸‹åˆåˆ‡æ®µï¼ˆä¿ç•™åŸé‚è¼¯ï¼‰
# =========================================================
def filter_morning_period(df: pd.DataFrame) -> pd.DataFrame:
    dtv = parse_tw_datetime(df["æ€è²¨å®Œæˆæ™‚é–“"])
    df = df.assign(æ€è²¨å®Œæˆæ™‚é–“=dtv).dropna(subset=["æ€è²¨å®Œæˆæ™‚é–“"])
    df = df[df["æ€è²¨å®Œæˆæ™‚é–“"].dt.time <= MORNING_END]
    return df


def filter_afternoon_period(df: pd.DataFrame) -> pd.DataFrame:
    dtv = parse_tw_datetime(df["æ€è²¨å®Œæˆæ™‚é–“"])
    df = df.assign(æ€è²¨å®Œæˆæ™‚é–“=dtv).dropna(subset=["æ€è²¨å®Œæˆæ™‚é–“"])
    df = df[(df["æ€è²¨å®Œæˆæ™‚é–“"].dt.time >= AFTERNOON_START) & (df["æ€è²¨å®Œæˆæ™‚é–“"].dt.time <= AFTERNOON_END)]
    return df


# =========================================================
# ç©ºçª—æ‹†æ®µï¼ˆä¿ç•™åŸé‚è¼¯ï¼‰
# =========================================================
def split_idle_segment(start: datetime, end: datetime, rest_start: datetime, rest_end: datetime) -> List[Tuple[datetime, datetime]]:
    segs: List[Tuple[datetime, datetime]] = []
    if end <= start:
        return segs

    # åˆ‡æ‰ä¼‘æ¯é‡ç–Š
    if end <= rest_start or start >= rest_end:
        segs.append((start, end))
        return segs

    if start < rest_start:
        segs.append((start, rest_start))
    if end > rest_end:
        segs.append((rest_end, end))
    return [(s, e) for s, e in segs if e > s]


def get_effective_idle_segments(prev_t: datetime, cur_t: datetime, rest_start: datetime, rest_end: datetime) -> List[Tuple[datetime, datetime]]:
    if cur_t <= prev_t:
        return []
    gap = cur_t - prev_t
    if gap < IDLE_THRESHOLD:
        return []
    return split_idle_segment(prev_t, cur_t, rest_start, rest_end)


# =========================================================
# è¨ˆç®—ï¼šä¸Šåˆ / ä¸‹åˆï¼ˆä¿ç•™ä½ åˆä½µç‰ˆé‚è¼¯ï¼‰
# =========================================================
def calculate_statistics_morning(morning_df: pd.DataFrame, full_df: pd.DataFrame, mapping: Dict[str, Dict[str, str]]) -> pd.DataFrame:
    columns_order = ["å€åŸŸ", "æ€è²¨äºº", "å§“å", "ç­†æ•¸", "å·¥ä½œå€é–“", "ç¸½åˆ†é˜", "æ•ˆç‡", "ç©ºçª—åˆ†é˜", "å„²ä½å€åŸŸ", "ç©ºçª—æ™‚é–“æ®µ"]
    if morning_df is None or morning_df.empty:
        return pd.DataFrame(columns=columns_order)

    stats: List[Dict[str, object]] = []
    morning_df = morning_df.copy()
    morning_df["æ€è²¨å®Œæˆæ™‚é–“"] = parse_tw_datetime(morning_df["æ€è²¨å®Œæˆæ™‚é–“"])
    morning_df = morning_df.dropna(subset=["æ€è²¨å®Œæˆæ™‚é–“"])

    full_df = full_df.copy()
    full_df["æ€è²¨å®Œæˆæ™‚é–“"] = parse_tw_datetime(full_df["æ€è²¨å®Œæˆæ™‚é–“"])
    full_df = full_df.dropna(subset=["æ€è²¨å®Œæˆæ™‚é–“"])

    for picker in sorted(morning_df["æ€è²¨äºº"].dropna().astype(str).unique()):
        picker_m = morning_df[morning_df["æ€è²¨äºº"].astype(str) == picker].sort_values("æ€è²¨å®Œæˆæ™‚é–“")
        if picker_m.empty:
            continue

        first_record = picker_m["æ€è²¨å®Œæˆæ™‚é–“"].iloc[0].to_pydatetime()
        last_record = picker_m["æ€è²¨å®Œæˆæ™‚é–“"].iloc[-1].to_pydatetime()

        # èµ·å§‹æ™‚é–“ï¼ˆå¯è¢«è¨­å®šè¦†è“‹ï¼‰
        start_time_str = _get_start_time(picker, mapping) or default_start_time_str
        try:
            st_time = datetime.strptime(start_time_str, "%H:%M:%S").time()
        except Exception:
            st_time = datetime.strptime(default_start_time_str, "%H:%M:%S").time()

        start_dt = datetime.combine(first_record.date(), st_time)
        end_dt = datetime.combine(first_record.date(), MORNING_END)

        effective_start = min(first_record, start_dt)

        # è‹¥è©²æ€è²¨äººåœ¨ full_df æœ‰ä¸‹åˆç´€éŒ„ï¼Œä¸ŠåˆçµæŸç”¨ 12:30ï¼›å¦å‰‡ç”¨ min(æœ€å¾Œä¸€ç­†, 12:30)
        picker_full = full_df[full_df["æ€è²¨äºº"].astype(str) == picker]
        has_afternoon = any(rec.time() >= AFTERNOON_START for rec in picker_full["æ€è²¨å®Œæˆæ™‚é–“"])
        effective_end = end_dt if has_afternoon else min(last_record, end_dt)

        rest_start_dt = datetime.combine(first_record.date(), M_REST_START)
        rest_end_dt = datetime.combine(first_record.date(), M_REST_END)

        overlap_start = max(effective_start, rest_start_dt)
        overlap_end = min(effective_end, rest_end_dt)
        rest_duration = (overlap_end - overlap_start) if overlap_end > overlap_start else timedelta(0)

        work_duration = (effective_end - effective_start) - rest_duration
        total_minutes = round(work_duration.total_seconds() / 60, 2)

        times = picker_m["æ€è²¨å®Œæˆæ™‚é–“"].dt.to_pydatetime().tolist()
        idle_segments: List[Tuple[datetime, datetime]] = []

        if times and times[0] > effective_start:
            idle_segments.extend(split_idle_segment(effective_start, times[0], rest_start_dt, rest_end_dt))

        for i in range(1, len(times)):
            idle_segments.extend(get_effective_idle_segments(times[i - 1], times[i], rest_start_dt, rest_end_dt))

        if last_record < effective_end:
            idle_segments.extend(get_effective_idle_segments(last_record, effective_end, rest_start_dt, rest_end_dt))

        idle_minutes = round(sum((e - s).total_seconds() for s, e in idle_segments) / 60, 2)
        num_records = len(picker_m)
        efficiency = round((num_records / total_minutes * 60) if total_minutes else 0, 2)

        time_period_str = f"{effective_start.strftime('%H:%M:%S')} ~ {effective_end.strftime('%H:%M:%S')}"
        idle_segments_str = "; ".join(f"{s.strftime('%H:%M:%S')} ~ {e.strftime('%H:%M:%S')}" for s, e in idle_segments)

        working_records = picker_m[(picker_m["æ€è²¨å®Œæˆæ™‚é–“"] >= effective_start) & (picker_m["æ€è²¨å®Œæˆæ™‚é–“"] <= effective_end)]
        storage_area_str = _storage_area_str(working_records)

        region = _get_region(picker, mapping)

        stats.append(
            {
                "å€åŸŸ": region,
                "æ€è²¨äºº": picker,
                "å§“å": _get_name(picker, mapping),
                "ç­†æ•¸": num_records,
                "å·¥ä½œå€é–“": time_period_str,
                "ç¸½åˆ†é˜": total_minutes,
                "æ•ˆç‡": efficiency,
                "ç©ºçª—åˆ†é˜": idle_minutes,
                "å„²ä½å€åŸŸ": storage_area_str,
                "ç©ºçª—æ™‚é–“æ®µ": idle_segments_str,
            }
        )

    statistics_df = pd.DataFrame(stats)
    if statistics_df.empty:
        return pd.DataFrame(columns=columns_order)

    statistics_df["å€åŸŸ"] = pd.Categorical(statistics_df["å€åŸŸ"], categories=["ä½ç©º", "é«˜ç©º"], ordered=True)
    statistics_df = statistics_df.sort_values(by=["å€åŸŸ", "æ€è²¨äºº"])
    return statistics_df[columns_order]


def calculate_statistics_afternoon(afternoon_df: pd.DataFrame, full_df: pd.DataFrame, mapping: Dict[str, Dict[str, str]]) -> pd.DataFrame:
    columns_order = ["å€åŸŸ", "æ€è²¨äºº", "å§“å", "ç­†æ•¸", "å·¥ä½œå€é–“", "ç¸½åˆ†é˜", "æ•ˆç‡", "ç©ºçª—åˆ†é˜", "å„²ä½å€åŸŸ", "ç©ºçª—æ™‚é–“æ®µ"]
    if afternoon_df is None or afternoon_df.empty:
        return pd.DataFrame(columns=columns_order)

    stats: List[Dict[str, object]] = []
    afternoon_df = afternoon_df.copy()
    afternoon_df["æ€è²¨å®Œæˆæ™‚é–“"] = parse_tw_datetime(afternoon_df["æ€è²¨å®Œæˆæ™‚é–“"])
    afternoon_df = afternoon_df.dropna(subset=["æ€è²¨å®Œæˆæ™‚é–“"])

    full_df = full_df.copy()
    full_df["æ€è²¨å®Œæˆæ™‚é–“"] = parse_tw_datetime(full_df["æ€è²¨å®Œæˆæ™‚é–“"])
    full_df = full_df.dropna(subset=["æ€è²¨å®Œæˆæ™‚é–“"])

    for picker in sorted(afternoon_df["æ€è²¨äºº"].dropna().astype(str).unique()):
        picker_a = afternoon_df[afternoon_df["æ€è²¨äºº"].astype(str) == picker].sort_values("æ€è²¨å®Œæˆæ™‚é–“")
        if picker_a.empty:
            continue

        first_record = picker_a["æ€è²¨å®Œæˆæ™‚é–“"].iloc[0].to_pydatetime()
        last_record = picker_a["æ€è²¨å®Œæˆæ™‚é–“"].iloc[-1].to_pydatetime()

        start_dt = datetime.combine(first_record.date(), AFTERNOON_START)
        end_dt = datetime.combine(first_record.date(), AFTERNOON_END)
        effective_start = min(first_record, start_dt)

        picker_full = full_df[full_df["æ€è²¨äºº"].astype(str) == picker]
        has_after_end = any(rec.time() > AFTERNOON_END for rec in picker_full["æ€è²¨å®Œæˆæ™‚é–“"])
        effective_end = end_dt if has_after_end else min(last_record, end_dt)

        rest_start_dt = datetime.combine(first_record.date(), A_REST_START)
        rest_end_dt = datetime.combine(first_record.date(), A_REST_END)

        overlap_start = max(effective_start, rest_start_dt)
        overlap_end = min(effective_end, rest_end_dt)
        rest_duration = (overlap_end - overlap_start) if overlap_end > overlap_start else timedelta(0)

        work_duration = (effective_end - effective_start) - rest_duration
        total_minutes = round(work_duration.total_seconds() / 60, 2)

        times = picker_a["æ€è²¨å®Œæˆæ™‚é–“"].dt.to_pydatetime().tolist()
        idle_segments: List[Tuple[datetime, datetime]] = []

        if times and times[0] > effective_start:
            idle_segments.extend(split_idle_segment(effective_start, times[0], rest_start_dt, rest_end_dt))

        for i in range(1, len(times)):
            idle_segments.extend(get_effective_idle_segments(times[i - 1], times[i], rest_start_dt, rest_end_dt))

        if last_record < effective_end:
            idle_segments.extend(get_effective_idle_segments(last_record, effective_end, rest_start_dt, rest_end_dt))

        idle_minutes = round(sum((e - s).total_seconds() for s, e in idle_segments) / 60, 2)
        num_records = len(picker_a)
        efficiency = round((num_records / total_minutes * 60) if total_minutes else 0, 2)

        time_period_str = f"{effective_start.strftime('%H:%M:%S')} ~ {effective_end.strftime('%H:%M:%S')}"
        idle_segments_str = "; ".join(f"{s.strftime('%H:%M:%S')} ~ {e.strftime('%H:%M:%S')}" for s, e in idle_segments)

        working_records = picker_a[(picker_a["æ€è²¨å®Œæˆæ™‚é–“"] >= effective_start) & (picker_a["æ€è²¨å®Œæˆæ™‚é–“"] <= effective_end)]
        storage_area_str = _storage_area_str(working_records)

        region = _get_region(picker, mapping)

        stats.append(
            {
                "å€åŸŸ": region,
                "æ€è²¨äºº": picker,
                "å§“å": _get_name(picker, mapping),
                "ç­†æ•¸": num_records,
                "å·¥ä½œå€é–“": time_period_str,
                "ç¸½åˆ†é˜": total_minutes,
                "æ•ˆç‡": efficiency,
                "ç©ºçª—åˆ†é˜": idle_minutes,
                "å„²ä½å€åŸŸ": storage_area_str,
                "ç©ºçª—æ™‚é–“æ®µ": idle_segments_str,
            }
        )

    statistics_df = pd.DataFrame(stats)
    if statistics_df.empty:
        return pd.DataFrame(columns=columns_order)

    statistics_df["å€åŸŸ"] = pd.Categorical(statistics_df["å€åŸŸ"], categories=["ä½ç©º", "é«˜ç©º"], ordered=True)
    statistics_df = statistics_df.sort_values(by=["å€åŸŸ", "æ€è²¨äºº"])
    return statistics_df[columns_order]


# =========================================================
# åŒ¯å‡ºï¼ˆopenpyxlï¼‰ï¼šåŒä¸€å¼µ Sheet ä¸Šä¸‹åˆ†æ®µ + é”æ¨™ç´…ç¶ åº•è‰²ï¼ˆä¿ç•™åŸé‚è¼¯ï¼‰
# =========================================================
def build_export_xlsx_bytes(
    title: str,
    morning_df: pd.DataFrame,
    afternoon_df: pd.DataFrame,
    low_threshold: float = 48.0,
    high_threshold: float = 20.0,
) -> bytes:
    # ä½ åŸæœ¬çš„åŒ¯å‡ºé‚è¼¯ï¼šopenpyxl + åŒä¸€å¼µ sheet ä¸Šä¸‹æ®µ + ä¾æ•ˆç‡åšç´…ç¶ 
    from openpyxl import Workbook
    from openpyxl.styles import PatternFill, Font, Alignment, Border, Side
    from openpyxl.utils import get_column_letter

    wb = Workbook()
    ws = wb.active
    ws.title = "Sheet1"

    thin = Side(style="thin", color="333333")
    border = Border(left=thin, right=thin, top=thin, bottom=thin)

    fill_green = PatternFill("solid", fgColor="C6EFCE")
    fill_red = PatternFill("solid", fgColor="FFC7CE")
    font_green = Font(color="006100")
    font_red = Font(color="9C0006")

    def autosize_cols(start_row: int, end_row: int, start_col: int, end_col: int):
        widths = {}
        for r in range(start_row, end_row + 1):
            for c in range(start_col, end_col + 1):
                v = ws.cell(r, c).value
                if v is None:
                    continue
                widths[c] = max(widths.get(c, 0), len(str(v)))
        for c, w in widths.items():
            ws.column_dimensions[get_column_letter(c)].width = min(max(10, w + 2), 48)

    def write_block(block_title: str, df: pd.DataFrame, start_row: int) -> int:
        # title row
        ws.merge_cells(start_row=start_row, start_column=1, end_row=start_row, end_column=max(1, len(df.columns) if df is not None else 1))
        c = ws.cell(start_row, 1, block_title)
        c.font = Font(size=14, bold=True)
        c.alignment = Alignment(horizontal="center", vertical="center")
        ws.row_dimensions[start_row].height = 22

        if df is None or df.empty:
            ws.cell(start_row + 1, 1, "ï¼ˆæœ¬æ®µç„¡è³‡æ–™ï¼‰")
            return start_row + 3

        # header
        header_row = start_row + 1
        for j, col in enumerate(df.columns, start=1):
            cell = ws.cell(header_row, j, col)
            cell.font = Font(bold=True)
            cell.alignment = Alignment(horizontal="center", vertical="center", wrap_text=True)
            cell.border = border

        # body
        for i, row in enumerate(df.itertuples(index=False), start=header_row + 1):
            for j, v in enumerate(row, start=1):
                cell = ws.cell(i, j, v)
                cell.alignment = Alignment(horizontal="center", vertical="center", wrap_text=True)
                cell.border = border

            # row color by efficiency
            try:
                region = str(df.iloc[i - (header_row + 1)]["å€åŸŸ"])
                eff = float(df.iloc[i - (header_row + 1)]["æ•ˆç‡"])
            except Exception:
                region, eff = "", 0.0

            ok = False
            if region == "é«˜ç©º":
                ok = eff >= float(high_threshold)
            elif region == "ä½ç©º":
                ok = eff >= float(low_threshold)

            for j in range(1, len(df.columns) + 1):
                if ok:
                    ws.cell(i, j).fill = fill_green
                    ws.cell(i, j).font = font_green
                else:
                    ws.cell(i, j).fill = fill_red
                    ws.cell(i, j).font = font_red

        end_row = header_row + len(df)
        autosize_cols(header_row, end_row, 1, len(df.columns))
        return end_row + 2

    # report title
    # å–æœ€å¤§æ¬„æ•¸é¿å… merge é•·åº¦ä¸ä¸€è‡´
    max_cols = max(
        1,
        (len(morning_df.columns) if morning_df is not None and not morning_df.empty else 1),
        (len(afternoon_df.columns) if afternoon_df is not None and not afternoon_df.empty else 1),
    )
    ws.merge_cells(start_row=1, start_column=1, end_row=1, end_column=max_cols)
    t = ws.cell(1, 1, title)
    t.font = Font(size=18, bold=True)
    t.alignment = Alignment(horizontal="center", vertical="center")
    ws.row_dimensions[1].height = 28

    next_row = 3
    next_row = write_block("ç¬¬ä¸€éšæ®µï¼ˆä¸Šåˆï¼‰", morning_df, next_row)
    next_row = write_block("ç¬¬äºŒéšæ®µï¼ˆä¸‹åˆï¼‰", afternoon_df, next_row)

    out = io.BytesIO()
    wb.save(out)
    return out.getvalue()


# =========================================================
# UIï¼šmapping editorï¼ˆä¿ç•™åŸé‚è¼¯ï¼šå§“åå¯ä¸­æ–‡è¼¸å…¥ï¼‰
# =========================================================
def _mapping_editor():
    if "pick_map" not in st.session_state:
        st.session_state.pick_map = {}

    with st.sidebar:
        st.subheader("ğŸ‘¤ æ€è²¨äººè¨­å®šï¼ˆå¯ä¸­æ–‡å§“åï¼‰")
        st.caption("è¼¸å…¥ã€Œæ€è²¨äººã€ä»£ç¢¼å¾Œï¼Œå¯è¨­å®šå§“å/èµ·å§‹æ™‚é–“/å€åŸŸï¼ˆé«˜ç©º/ä½ç©ºï¼‰ã€‚")

        picker_id = st.text_input("æ€è²¨äººä»£ç¢¼ï¼ˆå¯è²¼ä¸Šï¼‰", value="")
        col1, col2 = st.columns(2)
        with col1:
            name = st.text_input("å§“åï¼ˆä¸­æ–‡å¯è¼¸å…¥ï¼‰", value="")
        with col2:
            region = st.selectbox("å€åŸŸ", options=["ä½ç©º", "é«˜ç©º"], index=0)

        start_time = st.text_input("èµ·å§‹æ™‚é–“ï¼ˆHH:MM:SSï¼‰", value=default_start_time_str)

        if st.button("â• æ–°å¢ / æ›´æ–°"):
            pid = (picker_id or "").strip()
            if not pid:
                st.warning("è«‹è¼¸å…¥æ€è²¨äººä»£ç¢¼")
            else:
                st.session_state.pick_map[pid] = {
                    "å§“å": (name or "").strip(),
                    "èµ·å§‹æ™‚é–“": (start_time or "").strip(),
                    "å€åŸŸ": (region or "").strip(),
                }
                st.success("å·²æ›´æ–°")

        if st.session_state.pick_map:
            st.divider()
            st.caption("ç›®å‰è¨­å®šï¼š")
            mdf = pd.DataFrame(
                [{"æ€è²¨äºº": k, **v} for k, v in st.session_state.pick_map.items()]
            )
            st.dataframe(mdf, use_container_width=True, hide_index=True)


# =========================================================
# âœ… ç•«é¢ KPI è¡¨æ ¼ï¼šæ•´åˆ—ç´…/ç¶ åº•ï¼ˆæ–°å¢ï¼Œä¸æ”¹è¨ˆç®—/åŒ¯å‡ºé‚è¼¯ï¼‰
# =========================================================
def _style_kpi_rows(df: pd.DataFrame, low_threshold: float, high_threshold: float) -> "pd.io.formats.style.Styler":
    if df is None or df.empty:
        return df.style

    def _row_style(row: pd.Series) -> List[str]:
        try:
            region = str(row.get("å€åŸŸ", ""))
            eff = float(row.get("æ•ˆç‡", 0))
        except Exception:
            region, eff = "", 0.0

        ok = False
        if region == "é«˜ç©º":
            ok = eff >= float(high_threshold)
        elif region == "ä½ç©º":
            ok = eff >= float(low_threshold)

        if ok:
            bg, fg = "#C6EFCE", "#006100"
        else:
            bg, fg = "#FFC7CE", "#9C0006"
        return [f"background-color: {bg}; color: {fg};" for _ in row.index]

    return df.style.apply(_row_style, axis=1)


# =========================================================
# Main
# =========================================================
def main():
    inject_logistics_theme()
    set_page(
        "ç¸½æ€é”æ¨™ï¼ˆåˆä½µç‰ˆï¼‰",
        icon="ğŸ§¾",
        subtitle="åŒä¸€å¼µå ±è¡¨ Sheet ä¸Šä¸‹åˆ†æ®µï½œé”æ¨™ç´…ç¶ åº•è‰²ï½œå§“åå¯ä¸­æ–‡è¼¸å…¥",
    )

    # sidebar controls
    _mapping_editor()
    with st.sidebar:
        st.divider()
        st.subheader("âš™ï¸ å ±è¡¨è¨­å®š")
        report_title = st.text_input("å ±è¡¨æ¨™é¡Œ", value="ç¸½æ€é”æ¨™çé‡‘è¨ˆç®—å ±è¡¨ï¼ˆåˆä½µç‰ˆï¼‰")
        st.caption("é”æ¨™é–€æª»ï¼ˆæ²¿ç”¨ä½ åŸæœ¬æ¢ä»¶ï¼‰ï¼šé«˜ç©º 20ã€ä½ç©º 48")
        high_threshold = st.number_input("é«˜ç©ºé”æ¨™ï¼ˆæ•ˆç‡ï¼‰", min_value=0.0, max_value=9999.0, value=20.0, step=1.0)
        low_threshold = st.number_input("ä½ç©ºé”æ¨™ï¼ˆæ•ˆç‡ï¼‰", min_value=0.0, max_value=9999.0, value=48.0, step=1.0)

    # upload
    card_open("ğŸ“¤ ä¸Šå‚³åŸå§‹è³‡æ–™ï¼ˆå¯å¤šæª”åˆä½µï¼‰")
    files = st.file_uploader(
        "ä¸Šå‚³ Excel / CSV",
        type=["xlsx", "xls", "csv"],
        accept_multiple_files=True,
        label_visibility="collapsed",
    )
    run = st.button("ğŸš€ ç”¢å‡ºå ±è¡¨", type="primary", disabled=not files)
    card_close()

    if "picking_result" not in st.session_state:
        st.session_state.picking_result = None

    if run:
        # è¨ˆç®—ä¸€æ¬¡å¾Œå­˜ sessionï¼Œé¿å…ä½ æŒ‰åŒ¯å‡ºå°è‡´ KPI ç•«é¢æ¶ˆå¤±
        with st.spinner("è¨ˆç®—ä¸­ï¼Œè«‹ç¨å€™."):
            raw_df = _load_uploaded_files(files)
            if raw_df.empty:
                st.error("æœªè®€åˆ°ä»»ä½•è³‡æ–™ï¼Œè«‹ç¢ºèªæª”æ¡ˆå…§å®¹ã€‚")
                return

            # åˆä½µç‰ˆé‚è¼¯ï¼šå»æˆç®± + åˆä½µåˆ— + è§£ææ™‚é–“
            df = remove_boxed_rows(raw_df)
            full_df = combine_rows(df)
            full_df = ensure_datetime(full_df).dropna(subset=["æ€è²¨å®Œæˆæ™‚é–“"])

            # ç¯©ä¸Šåˆ/ä¸‹åˆ + è¨ˆç®—
            morning_df = filter_morning_period(full_df)
            afternoon_df = filter_afternoon_period(full_df)

            mapping = st.session_state.pick_map

            morning_stats = calculate_statistics_morning(morning_df, full_df, mapping)
            afternoon_stats = calculate_statistics_afternoon(afternoon_df, full_df, mapping)

            # ç”¢å‡º xlsx bytesï¼ˆåŒä¸€å¼µ Sheet ä¸Šä¸‹åˆ†æ®µï¼‰
            xlsx_bytes = build_export_xlsx_bytes(
                title=report_title.strip() or "ç¸½æ€é”æ¨™çé‡‘è¨ˆç®—å ±è¡¨ï¼ˆåˆä½µç‰ˆï¼‰",
                morning_df=morning_stats,
                afternoon_df=afternoon_stats,
                low_threshold=float(low_threshold),
                high_threshold=float(high_threshold),
            )

            st.session_state.picking_result = {
                "report_title": report_title.strip() or "ç¸½æ€é”æ¨™çé‡‘è¨ˆç®—å ±è¡¨ï¼ˆåˆä½µç‰ˆï¼‰",
                "morning_stats": morning_stats,
                "afternoon_stats": afternoon_stats,
                "xlsx_bytes": xlsx_bytes,
                "low_threshold": float(low_threshold),
                "high_threshold": float(high_threshold),
            }

    # render result (persist)
    result = st.session_state.picking_result
    if not result:
        st.info("è«‹å…ˆä¸Šå‚³æª”æ¡ˆä¸¦é»ã€Œç”¢å‡ºå ±è¡¨ã€ã€‚")
        return

    morning_stats = result["morning_stats"]
    afternoon_stats = result["afternoon_stats"]
    low_thr = float(result.get("low_threshold", 48.0))
    high_thr = float(result.get("high_threshold", 20.0))

    # KPIç•«é¢ï¼šä¸Šåˆ/ä¸‹åˆä¸Šä¸‹é¡¯ç¤ºï¼ˆç¶­æŒä½ ç¾åœ¨å‘ˆç¾ï¼‰
    card_open("ğŸ“Š ç¬¬ä¸€éšæ®µï¼ˆä¸Šåˆï¼‰")
    if morning_stats is None or morning_stats.empty:
        st.info("ä¸Šåˆç„¡è³‡æ–™")
    else:
        st.dataframe(
            _style_kpi_rows(morning_stats, low_thr, high_thr),
            use_container_width=True,
            hide_index=True,
        )
    card_close()

    card_open("ğŸ“Š ç¬¬äºŒéšæ®µï¼ˆä¸‹åˆï¼‰")
    if afternoon_stats is None or afternoon_stats.empty:
        st.info("ä¸‹åˆç„¡è³‡æ–™")
    else:
        st.dataframe(
            _style_kpi_rows(afternoon_stats, low_thr, high_thr),
            use_container_width=True,
            hide_index=True,
        )
    card_close()

    # âœ… åŒ¯å‡ºæŒ‰éˆ•ï¼šç›´æ¥æ˜¯æŒ‰éˆ•ï¼ˆä¸æœƒè®“ KPI æ¶ˆå¤±ï¼Œå› ç‚ºå·²å­˜ session_stateï¼‰
    st.download_button(
        label="â¬‡ï¸ åŒ¯å‡ºå ±è¡¨ï¼ˆExcelï¼‰",
        data=result["xlsx_bytes"],
        file_name=f"{result['report_title']}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )


if __name__ == "__main__":
    main()
