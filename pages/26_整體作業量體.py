# pages/26_æ•´é«”ä½œæ¥­é‡é«”.py
# -*- coding: utf-8 -*-
from __future__ import annotations

from io import BytesIO
from datetime import datetime

import numpy as np
import pandas as pd
import streamlit as st

from common_ui import (
    inject_logistics_theme,
    set_page,
    KPI,
    render_kpis,
    card_open,
    card_close,
    download_excel_card,  # âœ… ä¸€è¡Œ=æŒ‰éˆ•ï¼ˆä¸”å¤–æ¡†ä¸åˆ†æ®µï¼‰
)

st.set_page_config(page_title="å¤§è±KPIï½œæ•´é«”ä½œæ¥­é‡é«”", page_icon="ğŸ§¹", layout="wide")
inject_logistics_theme()

set_page(
    "æ•´é«”ä½œæ¥­é‡é«”",
    icon="ğŸ§¹",
    subtitle="æ”¯æ´ Excel / TXTï½œåˆªé™¤ç®±é¡å‹å«ã€ç«™æ‰€ã€ï½œè¨ˆé‡å–®ä½æ•¸é‡ï½œå‡ºè²¨å–®ä½ï¼ˆåˆ¤æ–·å¾Œï¼‰ï½œGM/ä¸€èˆ¬å€‰ Ã— æˆç®±/é›¶æ•£çµ±è¨ˆï½œExcelä¸‹è¼‰",
)

# ----------------------------
# constants / helpers
# ----------------------------
NEED_COLS = ["packqty", "å…¥æ•¸", "ç®±é¡å‹", "è¼‰å…·è™Ÿ", "BOXTYPE", "boxid"]
CANDIDATE_SEPS = ["\t", ",", "|", ";"]  # å¸¸è¦‹ txt åˆ†éš”ç¬¦
CANDIDATE_ENCODINGS = ["utf-8-sig", "utf-8", "cp950", "big5"]  # å°ç£å¸¸è¦‹


def _safe_str(s: pd.Series) -> pd.Series:
    return s.astype(str).fillna("").astype(str)


def _fmt_int(x) -> str:
    try:
        return f"{int(round(float(x))):,}"
    except Exception:
        return "0"


def _fmt0(x) -> str:
    try:
        return f"{float(x):,.0f}"
    except Exception:
        return "0"


def _detect_sep(text: str) -> str:
    """ç”¨ç¬¬ä¸€è¡Œç²—ç•¥çŒœåˆ†éš”ç¬¦"""
    lines = [ln for ln in text.splitlines() if ln.strip()]
    if not lines:
        return "\t"
    first = lines[0]
    best = "\t"
    best_cnt = -1
    for sep in CANDIDATE_SEPS:
        cnt = first.count(sep)
        if cnt > best_cnt:
            best_cnt = cnt
            best = sep
    return best


def read_txt_bytes(raw: bytes, force_sep: str | None = None, force_encoding: str | None = None) -> pd.DataFrame:
    """
    TXT è®€å–ï¼ˆè‡ªå‹•çŒœåˆ†éš”ç¬¦ã€å˜—è©¦å¤šç¨®ç·¨ç¢¼ï¼‰ã€‚
    - è‹¥ force_sep / force_encoding æœ‰æŒ‡å®šï¼Œæœƒå„ªå…ˆä½¿ç”¨ã€‚
    """
    last_err = None

    encodings = [force_encoding] if force_encoding else []
    encodings += [e for e in CANDIDATE_ENCODINGS if e not in encodings]

    for enc in encodings:
        try:
            text = raw.decode(enc, errors="strict")
        except Exception as e:
            last_err = e
            continue

        sep = force_sep if force_sep else _detect_sep(text)

        # ç”¨ pandas è®€å–
        try:
            bio = BytesIO(raw)
            df = pd.read_csv(
                bio,
                sep=sep,
                encoding=enc,
                dtype=str,          # å…ˆå…¨éƒ¨è®€å­—ä¸²ï¼Œå¾Œé¢å†è½‰æ•¸å€¼ï¼ˆæ¯”è¼ƒç©©ï¼‰
                engine="python",    # å°æ–¼ä¸è¦å‰‡åˆ†éš”è¼ƒå®¹éŒ¯
            )
            return df
        except Exception as e:
            last_err = e
            continue

    raise RuntimeError(f"TXT è®€å–å¤±æ•—ï¼ˆå¯èƒ½æ˜¯åˆ†éš”ç¬¦/ç·¨ç¢¼ä¸ç¬¦æˆ–æª”æ¡ˆæ ¼å¼éè¡¨æ ¼ï¼‰ï¼š{last_err}")


def robust_read_file(uploaded_file, txt_sep_choice: str, txt_encoding_choice: str) -> pd.DataFrame:
    name = (uploaded_file.name or "").lower()
    raw = uploaded_file.getvalue()

    # TXT æ§åˆ¶
    sep_map = {
        "è‡ªå‹•": None,
        "Tab": "\t",
        "é€—è™Ÿ ,": ",",
        "ç›´ç·š |": "|",
        "åˆ†è™Ÿ ;": ";",
    }
    force_sep = sep_map.get(txt_sep_choice, None)
    force_enc = None if txt_encoding_choice == "è‡ªå‹•" else txt_encoding_choice

    if name.endswith(".txt") or name.endswith(".csv"):
        return read_txt_bytes(raw, force_sep=force_sep, force_encoding=force_enc)

    # Excel
    bio = BytesIO(raw)
    try:
        return pd.read_excel(bio, engine="openpyxl")
    except Exception:
        try:
            bio.seek(0)
            return pd.read_excel(bio, engine="xlrd")
        except Exception as e:
            raise RuntimeError(f"è®€å– Excel å¤±æ•—ï¼š{e}")


def make_excel_bytes(df_processed: pd.DataFrame, summary_df: pd.DataFrame) -> bytes:
    bio = BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        summary_df.to_excel(writer, index=False, sheet_name="çµ±è¨ˆçµæœ")
        df_processed.to_excel(writer, index=False, sheet_name="è™•ç†å¾Œæ˜ç´°")
    return bio.getvalue()


def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    """æŠŠæ¬„åå‰å¾Œç©ºç™½å»æ‰ï¼ˆTXT å¾ˆå¸¸ç™¼ç”Ÿï¼‰"""
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    return df


def compute(df_raw: pd.DataFrame) -> dict:
    df_raw = _normalize_columns(df_raw)

    missing = [c for c in NEED_COLS if c not in df_raw.columns]
    if missing:
        # å†åšä¸€æ¬¡ã€Œå¿½ç•¥å¤§å°å¯«/ç©ºç™½ã€å˜—è©¦å°ç…§ï¼ˆé¿å… TXT æ¬„åæ€ªï¼‰
        lower_map = {str(c).strip().lower(): c for c in df_raw.columns}
        remap = {}
        for need in NEED_COLS:
            key = need.strip().lower()
            if key in lower_map:
                remap[lower_map[key]] = need
        if remap:
            df_raw = df_raw.rename(columns=remap)
            df_raw = _normalize_columns(df_raw)

        missing2 = [c for c in NEED_COLS if c not in df_raw.columns]
        if missing2:
            raise KeyError(f"âš ï¸ æ‰¾ä¸åˆ°å¿…è¦æ¬„ä½ï¼š{missing2}ï¼Œè«‹ç¢ºèª TXT/Excel çš„è¡¨é ­æ˜¯å¦ä¸€è‡´ã€‚")

    df0 = df_raw.copy()

    # 1) åˆªé™¤ã€Œç®±é¡å‹ã€å«ã€Œç«™æ‰€ã€
    before = len(df0)
    df = df0[~_safe_str(df0["ç®±é¡å‹"]).str.contains("ç«™æ‰€", na=False)].copy()
    removed_station = before - len(df)

    # 2) æ–°å¢æ¬„ä½
    pack = pd.to_numeric(df["packqty"], errors="coerce")
    unit = pd.to_numeric(df["å…¥æ•¸"], errors="coerce")

    df["è¨ˆé‡å–®ä½æ•¸é‡"] = np.where((unit.notna()) & (unit != 0), pack / unit, np.nan)

    v = pd.to_numeric(df["è¨ˆé‡å–®ä½æ•¸é‡"], errors="coerce")
    is_int = np.isfinite(v) & np.isclose(v, np.round(v))
    df["å‡ºè²¨å–®ä½ï¼ˆåˆ¤æ–·å¾Œï¼‰"] = np.where(is_int, v, pack)

    # 2-3 æ¬„ä½é †åºï¼šæ’åœ¨ã€Œå…¥æ•¸ã€å³é‚Š
    cols = list(df.columns)
    for c in ["è¨ˆé‡å–®ä½æ•¸é‡", "å‡ºè²¨å–®ä½ï¼ˆåˆ¤æ–·å¾Œï¼‰"]:
        if c in cols:
            cols.remove(c)
    ins_pos = cols.index("å…¥æ•¸") + 1
    cols[ins_pos:ins_pos] = ["è¨ˆé‡å–®ä½æ•¸é‡", "å‡ºè²¨å–®ä½ï¼ˆåˆ¤æ–·å¾Œï¼‰"]
    df = df[cols]

    # 3) çµ±è¨ˆé®ç½©
    mask_gm = _safe_str(df["è¼‰å…·è™Ÿ"]).str.contains("GM", case=False, na=False)
    boxtype = _safe_str(df["BOXTYPE"]).str.strip()
    mask_box1 = boxtype == "1"
    mask_box0 = boxtype == "0"
    mask_not_gm = ~mask_gm

    # 4) å››é …çµ±è¨ˆ
    unique_boxid_count = (
        df.loc[mask_gm & mask_box1, "boxid"]
        .astype(str)
        .str.strip()
        .replace("", np.nan)
        .dropna()
        .nunique()
    )

    ship_unit = pd.to_numeric(df["å‡ºè²¨å–®ä½ï¼ˆåˆ¤æ–·å¾Œï¼‰"], errors="coerce")
    total_shipunit_notgm_box0 = ship_unit.loc[mask_not_gm & mask_box0].sum()
    total_shipunit_gm_box1 = ship_unit.loc[mask_gm & mask_box1].sum()
    total_shipunit_notgm_box1 = ship_unit.loc[mask_not_gm & mask_box1].sum()

    summary = pd.DataFrame(
        [
            {"é …ç›®": "A) GMä»¶æ•¸ï¼ˆGM + BOXTYPE=1ï¼Œä¸é‡è¤‡boxidï¼‰", "æ•¸å€¼": unique_boxid_count},
            {"é …ç›®": "B) ä¸€èˆ¬å€‰é›¶æ•£PCSï¼ˆéGM + BOXTYPE=0ï¼‰", "æ•¸å€¼": total_shipunit_notgm_box0},
            {"é …ç›®": "C) GMæˆç®±PCSï¼ˆGM + BOXTYPE=1ï¼‰", "æ•¸å€¼": total_shipunit_gm_box1},
            {"é …ç›®": "D) ä¸€èˆ¬å€‰æˆç®±PCSï¼ˆéGM + BOXTYPE=1ï¼‰", "æ•¸å€¼": total_shipunit_notgm_box1},
        ]
    )

    return {
        "df_processed": df,
        "removed_station": removed_station,
        "total_in": len(df_raw),
        "total_after": len(df),
        "A_gm_cases": unique_boxid_count,
        "B_notgm_loose_pcs": total_shipunit_notgm_box0,
        "C_gm_box_pcs": total_shipunit_gm_box1,
        "D_notgm_box_pcs": total_shipunit_notgm_box1,
        "summary": summary,
    }


# ----------------------------
# UI
# ----------------------------
card_open("ğŸ“¥ ä¸Šå‚³æ˜ç´°ï¼ˆExcel / TXTï¼‰")

# TXT è®€å–è¼”åŠ©ï¼ˆå¯ä¸ç®¡å®ƒï¼Œé è¨­è‡ªå‹•ï¼‰
colA, colB = st.columns(2)
with colA:
    txt_sep_choice = st.selectbox("TXT åˆ†éš”ç¬¦", ["è‡ªå‹•", "Tab", "é€—è™Ÿ ,", "ç›´ç·š |", "åˆ†è™Ÿ ;"], index=0)
with colB:
    txt_encoding_choice = st.selectbox("TXT ç·¨ç¢¼", ["è‡ªå‹•", "utf-8-sig", "utf-8", "cp950", "big5"], index=0)

uploaded = st.file_uploader(
    "è«‹ä¸Šå‚³è¦è™•ç†çš„æª”æ¡ˆï¼ˆ.xlsx / .xls / .txtï¼‰",
    type=["xlsx", "xls", "xlsm", "txt", "csv"],
    accept_multiple_files=False,
)
card_close()

if not uploaded:
    st.info("è«‹å…ˆä¸Šå‚³æª”æ¡ˆã€‚")
    st.stop()

try:
    df_raw = robust_read_file(uploaded, txt_sep_choice=txt_sep_choice, txt_encoding_choice=txt_encoding_choice)
    out = compute(df_raw)
except Exception as e:
    st.error(str(e))
    st.stop()

st.caption(
    f"å·²è®€å– {out['total_in']:,} åˆ—ï¼›"
    f"åˆªé™¤ã€ç®±é¡å‹å«ç«™æ‰€ã€ {out['removed_station']:,} åˆ—ï¼›"
    f"å‰©é¤˜ {out['total_after']:,} åˆ—ä½œç‚ºçµ±è¨ˆèˆ‡è¼¸å‡ºã€‚"
)

# KPIï¼š2 æ¬„ï¼ˆå·¦ï¼šGMï¼Œå³ï¼šä¸€èˆ¬å€‰ï¼‰
c1, c2 = st.columns(2, gap="large")
with c1:
    render_kpis(
        [
            KPI("A) GMä»¶æ•¸", _fmt_int(out["A_gm_cases"])),
            KPI("C) GMæˆç®±PCS", _fmt0(out["C_gm_box_pcs"])),
        ],
        cols=1,
    )
with c2:
    render_kpis(
        [
            KPI("B) ä¸€èˆ¬å€‰é›¶æ•£PCS", _fmt0(out["B_notgm_loose_pcs"])),
            KPI("D) ä¸€èˆ¬å€‰æˆç®±PCS", _fmt0(out["D_notgm_box_pcs"])),
        ],
        cols=1,
    )

card_open("ğŸ“Œ çµ±è¨ˆçµæœ")
sum_df = out["summary"].copy()
sum_df["æ•¸å€¼"] = sum_df["æ•¸å€¼"].apply(_fmt0)
st.dataframe(sum_df, use_container_width=True, hide_index=True)
card_close()

card_open("ğŸ“¤ åŒ¯å‡º")
stamp = datetime.now().strftime("%Y%m%d_%H%M")
filename = f"å¤§è±KPI_æ•´é«”ä½œæ¥­é‡é«”_{stamp}.xlsx"
xlsx_bytes = make_excel_bytes(out["df_processed"], out["summary"])

download_excel_card(
    title="âœ… ä¸‹è¼‰ Excelï¼ˆå«ï¼šçµ±è¨ˆçµæœ + è™•ç†å¾Œæ˜ç´°ï¼‰",
    data=xlsx_bytes,
    filename=filename,
)

with st.expander("ğŸ” è™•ç†å¾Œæ˜ç´°é è¦½ï¼ˆå‰ 200 ç­†ï¼‰", expanded=False):
    st.dataframe(out["df_processed"].head(200), use_container_width=True)
card_close()
