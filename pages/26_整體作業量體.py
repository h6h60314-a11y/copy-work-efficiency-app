# pages/26_æ•´é«”ä½œæ¥­é‡é«”.py
# -*- coding: utf-8 -*-
from __future__ import annotations

from io import BytesIO, StringIO
from datetime import datetime

import numpy as np
import pandas as pd
import streamlit as st

from common_ui import (
    inject_logistics_theme,
    set_page,
    KPI,
    render_kpis,
    card_open,
    card_close,
    download_excel_card,  # âœ… ä¸€è¡Œ=æŒ‰éˆ•ï¼ˆä¸”å¤–æ¡†ä¸åˆ†æ®µï¼‰
)

st.set_page_config(page_title="å¤§è±KPIï½œæ•´é«”ä½œæ¥­é‡é«”", page_icon="ğŸ§¹", layout="wide")
inject_logistics_theme()

set_page(
    "æ•´é«”ä½œæ¥­é‡é«”",
    icon="ğŸ§¹",
    subtitle="æ”¯æ´ Excel/TXTï½œå¯å¤šæª”ä¸Šå‚³ï½œæ¬„ä½å°ç…§ï¼ˆè§£æ±º TXT ä¸­æ–‡äº‚ç¢¼ï¼‰ï½œGM/ä¸€èˆ¬å€‰ Ã— æˆç®±/é›¶æ•£çµ±è¨ˆï½œExcelä¸‹è¼‰",
)

# ----------------------------
# constants
# ----------------------------
NEED_COLS = ["packqty", "å…¥æ•¸", "ç®±é¡å‹", "è¼‰å…·è™Ÿ", "BOXTYPE", "boxid"]
CANDIDATE_SEPS = ["\t", ",", "|", ";"]
CANDIDATE_ENCODINGS = ["utf-8-sig", "utf-8", "cp950", "big5", "latin1"]  # latin1 æœ€å¾Œå…œåº•ï¼ˆä¸ç‚¸ï¼‰


# ----------------------------
# utils
# ----------------------------
def _safe_str(s: pd.Series) -> pd.Series:
    return s.astype(str).fillna("").astype(str)


def _fmt_int(x) -> str:
    try:
        return f"{int(round(float(x))):,}"
    except Exception:
        return "0"


def _fmt0(x) -> str:
    try:
        return f"{float(x):,.0f}"
    except Exception:
        return "0"


def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    return df


def _detect_sep(text: str) -> str | None:
    # è‹¥ Tab/é€—è™Ÿ/|/; éƒ½æ²’æœ‰ â†’ å¯èƒ½æ˜¯å¤šç©ºç™½/å›ºå®šå¯¬åº¦
    lines = [ln for ln in text.splitlines() if ln.strip()]
    if not lines:
        return None
    first = lines[0]

    best = None
    best_cnt = 0
    for sep in CANDIDATE_SEPS:
        cnt = first.count(sep)
        if cnt > best_cnt:
            best_cnt = cnt
            best = sep
    return best if best_cnt > 0 else None


def _read_txt_as_df(text: str, mode: str) -> pd.DataFrame:
    """
    mode:
      - "auto": å…ˆçŒœåˆ†éš”ç¬¦ï¼›çŒœä¸åˆ° -> å¤šç©ºç™½ -> å›ºå®šå¯¬åº¦
      - "sep:\t" / "sep:," / "sep:|" / "sep:;"ï¼šæŒ‡å®šåˆ†éš”ç¬¦
      - "ws": å¤šç©ºç™½
      - "fwf": å›ºå®šå¯¬åº¦
    """
    if mode.startswith("sep:"):
        sep = mode.split(":", 1)[1]
        return pd.read_csv(StringIO(text), sep=sep, dtype=str, engine="python")

    if mode == "ws":
        return pd.read_csv(StringIO(text), sep=r"\s+", dtype=str, engine="python")

    if mode == "fwf":
        return pd.read_fwf(StringIO(text), dtype=str)

    # auto
    sep = _detect_sep(text)
    if sep is not None:
        return pd.read_csv(StringIO(text), sep=sep, dtype=str, engine="python")

    # fallback: ws -> fwf
    try:
        df_ws = pd.read_csv(StringIO(text), sep=r"\s+", dtype=str, engine="python")
        if df_ws.shape[1] >= 2:
            return df_ws
    except Exception:
        pass
    return pd.read_fwf(StringIO(text), dtype=str)


def read_txt_bytes(raw: bytes, parse_mode: str, force_encoding: str | None) -> pd.DataFrame:
    """
    âœ… é‡é»ï¼šdecode ç”¨ errors='replace'ï¼Œé¿å…æ··ç·¨ç¢¼ç›´æ¥ç‚¸
    """
    encs = [force_encoding] if force_encoding else []
    encs += [e for e in CANDIDATE_ENCODINGS if e not in encs]

    last_err = None
    for enc in encs:
        try:
            text = raw.decode(enc, errors="replace")
            return _read_txt_as_df(text, parse_mode)
        except Exception as e:
            last_err = e
            continue

    raise RuntimeError(f"TXT è®€å–å¤±æ•—ï¼ˆåˆ†éš”ç¬¦/æ ¼å¼ä¸ç¬¦ï¼‰ï¼š{last_err}")


def robust_read_file(uploaded_file, txt_parse_choice: str, txt_encoding_choice: str) -> pd.DataFrame:
    name = (uploaded_file.name or "").lower()
    raw = uploaded_file.getvalue()

    # è§£ææ¨¡å¼
    parse_map = {
        "è‡ªå‹•": "auto",
        "Tab": "sep:\t",
        "é€—è™Ÿ ,": "sep:,",
        "ç›´ç·š |": "sep:|",
        "åˆ†è™Ÿ ;": "sep:;",
        "å¤šç©ºç™½(å°é½Š)": "ws",
        "å›ºå®šå¯¬åº¦(FWF)": "fwf",
    }
    parse_mode = parse_map.get(txt_parse_choice, "auto")
    force_enc = None if txt_encoding_choice == "è‡ªå‹•" else txt_encoding_choice

    if name.endswith(".txt") or name.endswith(".csv"):
        return read_txt_bytes(raw, parse_mode=parse_mode, force_encoding=force_enc)

    bio = BytesIO(raw)
    try:
        return pd.read_excel(bio, engine="openpyxl")
    except Exception:
        try:
            bio.seek(0)
            return pd.read_excel(bio, engine="xlrd")
        except Exception as e:
            raise RuntimeError(f"è®€å– Excel å¤±æ•—ï¼š{e}")


def _guess_unit_col(cols: list[str]) -> str | None:
    # å„ªå…ˆç”¨ unitï¼ˆä½ æª”æ¡ˆè£¡å°±æœ‰ï¼‰
    if "unit" in cols:
        return "unit"
    # é€€è€Œæ±‚å…¶æ¬¡ï¼šåç¨±å« unit
    for c in cols:
        if "unit" in c.lower():
            return c
    return None


def _guess_vehicle_col(df: pd.DataFrame) -> str | None:
    # æ‰¾ã€Œå€¼è£¡é¢æœ‰ GMã€çš„æ¬„ä½ï¼ˆæƒå‰ 5000 ç­†å°±å¥½ï¼‰
    sample = df.head(5000)
    for c in sample.columns:
        s = _safe_str(sample[c])
        if s.str.contains("GM", case=False, na=False).any():
            return c
    return None


def _guess_box_type_col(df: pd.DataFrame) -> str | None:
    """
    ç®±é¡å‹é€šå¸¸æ˜¯çŸ­å­—ä¸²ï¼ˆä¾‹å¦‚ï¼šç®±/åŒ…/ç“¶/ç›’...ï¼‰ä¸”å”¯ä¸€å€¼ä¸å¤š
    é€™è£¡ç”¨å•Ÿç™¼å¼æŒ‘æœ€åƒçš„æ¬„ä½
    """
    sample = df.head(8000)
    best = None
    best_score = -1

    for c in sample.columns:
        if c in {"Facility", "Storerkey", "orderdate", "storeid", "storename", "shippeddate",
                 "deliverydate", "deliverytime", "boxid", "externorderkey", "SKU", "manufacturersku",
                 "descr", "susr2", "outqty", "packqty", "memo", "price", "buyersreference", "BOXTYPE"}:
            continue

        s = _safe_str(sample[c]).str.strip()
        s = s[s != ""]
        if len(s) == 0:
            continue

        nunq = s.nunique()
        avg_len = s.str.len().mean()

        # åˆ†æ•¸ï¼šå”¯ä¸€å€¼å°‘ + å¹³å‡é•·åº¦çŸ­
        score = 0
        if nunq <= 20:
            score += 2
        if nunq <= 10:
            score += 2
        if avg_len <= 4:
            score += 2
        if avg_len <= 2:
            score += 1

        if score > best_score:
            best_score = score
            best = c

    return best


def apply_column_mapping(df: pd.DataFrame, map_in: str | None, map_box: str | None, map_vehicle: str | None) -> pd.DataFrame:
    """
    æŠŠä½¿ç”¨è€…é¸åˆ°çš„æ¬„ä½ rename æˆæ¨™æº–æ¬„åï¼š
      å…¥æ•¸ / ç®±é¡å‹ / è¼‰å…·è™Ÿ
    è‹¥æœ¬ä¾†å°±æœ‰æ¨™æº–æ¬„åï¼Œå„ªå…ˆä¿ç•™ä¸è¦†è“‹ã€‚
    """
    df = _normalize_columns(df)

    rename = {}
    if "å…¥æ•¸" not in df.columns and map_in and map_in in df.columns:
        rename[map_in] = "å…¥æ•¸"
    if "ç®±é¡å‹" not in df.columns and map_box and map_box in df.columns:
        rename[map_box] = "ç®±é¡å‹"
    if "è¼‰å…·è™Ÿ" not in df.columns and map_vehicle and map_vehicle in df.columns:
        rename[map_vehicle] = "è¼‰å…·è™Ÿ"

    if rename:
        df = df.rename(columns=rename)

    return df


def compute(df_raw: pd.DataFrame) -> dict:
    df_raw = _normalize_columns(df_raw)

    missing2 = [c for c in NEED_COLS if c not in df_raw.columns]
    if missing2:
        raise KeyError(
            f"âš ï¸ æ‰¾ä¸åˆ°å¿…è¦æ¬„ä½ï¼š{missing2}\n"
            f"ç›®å‰è®€åˆ°çš„æ¬„ä½ï¼ˆå‰30ï¼‰ï¼š{list(df_raw.columns)[:30]}{' ...' if len(df_raw.columns)>30 else ''}"
        )

    df0 = df_raw.copy()

    # 1) åˆªé™¤ã€Œç®±é¡å‹ã€å«ã€Œç«™æ‰€ã€
    before = len(df0)
    df = df0[~_safe_str(df0["ç®±é¡å‹"]).str.contains("ç«™æ‰€", na=False)].copy()
    removed_station = before - len(df)

    # 2) æ–°å¢æ¬„ä½
    pack = pd.to_numeric(df["packqty"], errors="coerce")
    unit = pd.to_numeric(df["å…¥æ•¸"], errors="coerce")

    df["è¨ˆé‡å–®ä½æ•¸é‡"] = np.where((unit.notna()) & (unit != 0), pack / unit, np.nan)

    v = pd.to_numeric(df["è¨ˆé‡å–®ä½æ•¸é‡"], errors="coerce")
    is_int = np.isfinite(v) & np.isclose(v, np.round(v))
    df["å‡ºè²¨å–®ä½ï¼ˆåˆ¤æ–·å¾Œï¼‰"] = np.where(is_int, v, pack)

    # æ’åœ¨ã€Œå…¥æ•¸ã€å³é‚Š
    cols = list(df.columns)
    for c in ["è¨ˆé‡å–®ä½æ•¸é‡", "å‡ºè²¨å–®ä½ï¼ˆåˆ¤æ–·å¾Œï¼‰"]:
        if c in cols:
            cols.remove(c)
    ins_pos = cols.index("å…¥æ•¸") + 1
    cols[ins_pos:ins_pos] = ["è¨ˆé‡å–®ä½æ•¸é‡", "å‡ºè²¨å–®ä½ï¼ˆåˆ¤æ–·å¾Œï¼‰"]
    df = df[cols]

    # 3) çµ±è¨ˆé®ç½©
    mask_gm = _safe_str(df["è¼‰å…·è™Ÿ"]).str.contains("GM", case=False, na=False)
    boxtype = _safe_str(df["BOXTYPE"]).str.strip()
    mask_box1 = boxtype == "1"
    mask_box0 = boxtype == "0"
    mask_not_gm = ~mask_gm

    # 4) å››é …çµ±è¨ˆ
    unique_boxid_count = (
        df.loc[mask_gm & mask_box1, "boxid"]
        .astype(str)
        .str.strip()
        .replace("", np.nan)
        .dropna()
        .nunique()
    )

    ship_unit = pd.to_numeric(df["å‡ºè²¨å–®ä½ï¼ˆåˆ¤æ–·å¾Œï¼‰"], errors="coerce")
    total_shipunit_notgm_box0 = ship_unit.loc[mask_not_gm & mask_box0].sum()
    total_shipunit_gm_box1 = ship_unit.loc[mask_gm & mask_box1].sum()
    total_shipunit_notgm_box1 = ship_unit.loc[mask_not_gm & mask_box1].sum()

    return {
        "df_processed": df,
        "removed_station": int(removed_station),
        "total_in": int(len(df_raw)),
        "total_after": int(len(df)),
        "A_gm_cases": float(unique_boxid_count),
        "B_notgm_loose_pcs": float(total_shipunit_notgm_box0),
        "C_gm_box_pcs": float(total_shipunit_gm_box1),
        "D_notgm_box_pcs": float(total_shipunit_notgm_box1),
    }


def make_excel_bytes(summary_all: pd.DataFrame, detail_all: pd.DataFrame) -> bytes:
    bio = BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        summary_all.to_excel(writer, index=False, sheet_name="çµ±è¨ˆç¸½è¡¨")
        detail_all.to_excel(writer, index=False, sheet_name="åˆä½µæ˜ç´°")
    return bio.getvalue()


# ----------------------------
# UI
# ----------------------------
card_open("ğŸ“¥ ä¸Šå‚³æ˜ç´°ï¼ˆExcel / TXTï¼Œå¯å¤šæª”ï¼‰")

colA, colB = st.columns(2)
with colA:
    txt_parse_choice = st.selectbox(
        "TXT åˆ†æ¬„æ–¹å¼",
        ["è‡ªå‹•", "Tab", "é€—è™Ÿ ,", "ç›´ç·š |", "åˆ†è™Ÿ ;", "å¤šç©ºç™½(å°é½Š)", "å›ºå®šå¯¬åº¦(FWF)"],
        index=0,
    )
with colB:
    txt_encoding_choice = st.selectbox(
        "TXT ç·¨ç¢¼",
        ["è‡ªå‹•", "utf-8-sig", "utf-8", "cp950", "big5", "latin1"],
        index=0,
    )

uploaded_files = st.file_uploader(
    "è«‹ä¸Šå‚³è¦è™•ç†çš„æª”æ¡ˆï¼ˆ.xlsx / .xls / .txtï¼‰",
    type=["xlsx", "xls", "xlsm", "txt", "csv"],
    accept_multiple_files=True,
)
card_close()

if not uploaded_files:
    st.info("è«‹å…ˆä¸Šå‚³æª”æ¡ˆï¼ˆå¯å¤šé¸ï¼‰ã€‚")
    st.stop()

# å…ˆè®€ç¬¬ä¸€å€‹æª”æ¡ˆï¼Œç”¨ä¾†æä¾›ã€Œæ¬„ä½å°ç…§ã€é¸é …èˆ‡é è¨­çŒœæ¸¬
try:
    _df_preview = robust_read_file(uploaded_files[0], txt_parse_choice, txt_encoding_choice)
    _df_preview = _normalize_columns(_df_preview)
except Exception as e:
    st.error(f"ç¬¬ä¸€å€‹æª”æ¡ˆè®€å–å¤±æ•—ï¼š{e}")
    st.stop()

cols = list(_df_preview.columns)
guess_in = _guess_unit_col(cols)
guess_vehicle = _guess_vehicle_col(_df_preview)
guess_box = _guess_box_type_col(_df_preview)

with st.expander("ğŸ§© æ¬„ä½å°ç…§ï¼ˆTXT ä¸­æ–‡äº‚ç¢¼æ™‚è«‹åœ¨é€™è£¡æŒ‡å®šï¼Œæœƒå¥—ç”¨åˆ°æ‰€æœ‰æª”æ¡ˆï¼‰", expanded=True):
    st.caption("è‹¥ Excel å·²æœ‰æ­£ç¢ºä¸­æ–‡æ¬„ä½ï¼Œå¯ç¶­æŒã€è‡ªå‹•ã€ï¼›TXT æ¬„åäº‚ç¢¼æ™‚è«‹æ‰‹å‹•æŒ‡å®šã€‚")

    opt = ["ï¼ˆè‡ªå‹•ï¼‰"] + cols

    col1, col2, col3 = st.columns(3)
    with col1:
        map_in = st.selectbox(
            "å…¥æ•¸ æ¬„ä½",
            opt,
            index=(opt.index(guess_in) if guess_in in opt else 0),
        )
    with col2:
        map_box = st.selectbox(
            "ç®±é¡å‹ æ¬„ä½",
            opt,
            index=(opt.index(guess_box) if guess_box in opt else 0),
        )
    with col3:
        map_vehicle = st.selectbox(
            "è¼‰å…·è™Ÿ æ¬„ä½ï¼ˆç”¨ä¾†åˆ¤æ–· GMï¼‰",
            opt,
            index=(opt.index(guess_vehicle) if guess_vehicle in opt else 0),
        )

# æŠŠï¼ˆè‡ªå‹•ï¼‰è½‰ç‚º None
map_in = None if map_in == "ï¼ˆè‡ªå‹•ï¼‰" else map_in
map_box = None if map_box == "ï¼ˆè‡ªå‹•ï¼‰" else map_box
map_vehicle = None if map_vehicle == "ï¼ˆè‡ªå‹•ï¼‰" else map_vehicle

results = []
details = []
errors = []

with st.spinner("è™•ç†ä¸­â€¦"):
    for f in uploaded_files:
        fname = f.name
        try:
            df_raw = robust_read_file(f, txt_parse_choice, txt_encoding_choice)
            df_raw = apply_column_mapping(df_raw, map_in=map_in, map_box=map_box, map_vehicle=map_vehicle)

            out = compute(df_raw)

            results.append(
                {
                    "æª”å": fname,
                    "è®€å–åˆ—æ•¸": out["total_in"],
                    "åˆªé™¤ç«™æ‰€åˆ—æ•¸": out["removed_station"],
                    "è™•ç†å¾Œåˆ—æ•¸": out["total_after"],
                    "A) GMä»¶æ•¸": out["A_gm_cases"],
                    "B) ä¸€èˆ¬å€‰é›¶æ•£PCS": out["B_notgm_loose_pcs"],
                    "C) GMæˆç®±PCS": out["C_gm_box_pcs"],
                    "D) ä¸€èˆ¬å€‰æˆç®±PCS": out["D_notgm_box_pcs"],
                }
            )

            df_p = out["df_processed"].copy()
            df_p.insert(0, "ä¾†æºæª”å", fname)
            details.append(df_p)

        except Exception as e:
            errors.append({"æª”å": fname, "éŒ¯èª¤": str(e)})

if errors:
    with st.expander("âš ï¸ éƒ¨åˆ†æª”æ¡ˆè™•ç†å¤±æ•—ï¼ˆå·²ç•¥éï¼‰", expanded=True):
        st.dataframe(pd.DataFrame(errors), use_container_width=True, hide_index=True)

if not results:
    st.error("æ²’æœ‰ä»»ä½•æª”æ¡ˆæˆåŠŸè™•ç†ï¼ˆè«‹åœ¨ã€æ¬„ä½å°ç…§ã€æŒ‡å®š å…¥æ•¸/ç®±é¡å‹/è¼‰å…·è™Ÿï¼Œæˆ–èª¿æ•´ TXT åˆ†æ¬„æ–¹å¼ï¼‰ã€‚")
    st.stop()

summary_all = pd.DataFrame(results)
detail_all = pd.concat(details, ignore_index=True) if details else pd.DataFrame()

# KPIï¼ˆå¤šæª”åˆè¨ˆï¼‰
total_files_ok = len(summary_all)
total_in = int(summary_all["è®€å–åˆ—æ•¸"].sum())
total_removed = int(summary_all["åˆªé™¤ç«™æ‰€åˆ—æ•¸"].sum())
total_after = int(summary_all["è™•ç†å¾Œåˆ—æ•¸"].sum())

A_sum = float(summary_all["A) GMä»¶æ•¸"].sum())
B_sum = float(summary_all["B) ä¸€èˆ¬å€‰é›¶æ•£PCS"].sum())
C_sum = float(summary_all["C) GMæˆç®±PCS"].sum())
D_sum = float(summary_all["D) ä¸€èˆ¬å€‰æˆç®±PCS"].sum())

st.caption(
    f"æˆåŠŸè™•ç† {total_files_ok} å€‹æª”æ¡ˆï¼›"
    f"åˆè¨ˆè®€å– {total_in:,} åˆ—ï¼›åˆªé™¤ç«™æ‰€ {total_removed:,} åˆ—ï¼›è™•ç†å¾Œ {total_after:,} åˆ—ã€‚"
)

c1, c2 = st.columns(2, gap="large")
with c1:
    render_kpis(
        [
            KPI("A) GMä»¶æ•¸ï¼ˆåˆè¨ˆï¼‰", _fmt_int(A_sum)),
            KPI("C) GMæˆç®±PCSï¼ˆåˆè¨ˆï¼‰", _fmt0(C_sum)),
        ],
        cols=1,
    )
with c2:
    render_kpis(
        [
            KPI("B) ä¸€èˆ¬å€‰é›¶æ•£PCSï¼ˆåˆè¨ˆï¼‰", _fmt0(B_sum)),
            KPI("D) ä¸€èˆ¬å€‰æˆç®±PCSï¼ˆåˆè¨ˆï¼‰", _fmt0(D_sum)),
        ],
        cols=1,
    )

card_open("ğŸ“Œ å¤šæª”çµ±è¨ˆç¸½è¡¨")
show_df = summary_all.copy()
for c in ["A) GMä»¶æ•¸", "B) ä¸€èˆ¬å€‰é›¶æ•£PCS", "C) GMæˆç®±PCS", "D) ä¸€èˆ¬å€‰æˆç®±PCS"]:
    show_df[c] = show_df[c].apply(_fmt0)
st.dataframe(show_df, use_container_width=True, hide_index=True)
card_close()

card_open("ğŸ“¤ åŒ¯å‡ºï¼ˆçµ±è¨ˆç¸½è¡¨ + åˆä½µæ˜ç´°ï¼‰")
stamp = datetime.now().strftime("%Y%m%d_%H%M")
filename = f"å¤§è±KPI_æ•´é«”ä½œæ¥­é‡é«”_å¤šæª”_{stamp}.xlsx"

xlsx_bytes = make_excel_bytes(summary_all, detail_all)

download_excel_card(
    title="âœ… ä¸‹è¼‰ Excelï¼ˆå«ï¼šçµ±è¨ˆç¸½è¡¨ + åˆä½µæ˜ç´°ï¼‰",
    data=xlsx_bytes,
    filename=filename,
)

with st.expander("ğŸ” åˆä½µæ˜ç´°é è¦½ï¼ˆå‰ 200 ç­†ï¼‰", expanded=False):
    st.dataframe(detail_all.head(200), use_container_width=True)

card_close()
