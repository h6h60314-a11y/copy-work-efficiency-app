# pages/26_æ•´é«”ä½œæ¥­é‡é«”.py
# -*- coding: utf-8 -*-
from __future__ import annotations

from io import BytesIO, StringIO
from datetime import datetime
import hashlib

import numpy as np
import pandas as pd
import streamlit as st

from common_ui import (
    inject_logistics_theme,
    set_page,
    KPI,
    render_kpis,
    card_open,
    card_close,
)

st.set_page_config(page_title="å¤§è±KPIï½œæ•´é«”ä½œæ¥­é‡é«”", page_icon="ğŸ§¹", layout="wide")
inject_logistics_theme()

# âœ… å¼·åˆ¶æŠŠ Streamlit çš„ download/button é¡¯ç¤ºå›ä¾†ï¼ˆé¿å… theme æŠŠæŒ‰éˆ•è—æ‰ï¼‰
st.markdown(
    r"""
<style>
/* download button å®¹å™¨ */
div[data-testid="stDownloadButton"]{
  display:block !important;
  visibility:visible !important;
  opacity:1 !important;
  position:relative !important;
  z-index:99999 !important;
}
/* download button æœ¬é«” */
div[data-testid="stDownloadButton"] button{
  display:inline-flex !important;
  visibility:visible !important;
  opacity:1 !important;
  width:100% !important;
}

/* ä¿éšªï¼šå¦‚æœ theme æŠŠå…¨ç«™ button éš±è—ï¼Œé€™è£¡æ•‘å›ä¾†ï¼ˆåƒ…ç¢ºä¿èƒ½çœ‹è¦‹/å¯é»ï¼‰ */
section[data-testid="stAppViewContainer"] button{
  display:inline-flex !important;
  visibility:visible !important;
  opacity:1 !important;
}
</style>
""",
    unsafe_allow_html=True,
)

set_page(
    "æ•´é«”ä½œæ¥­é‡é«”",
    icon="ğŸ§¹",
    subtitle="æ”¯æ´ Excel/TXTï½œå¯å¤šæª”ä¸Šå‚³ï½œè‡ªå‹•åµæ¸¬TXTç·¨ç¢¼ï¼ˆä¿®æ­£ä¸­æ–‡äº‚ç¢¼ï¼‰ï½œGM/ä¸€èˆ¬å€‰ Ã— æˆç®±/é›¶æ•£çµ±è¨ˆï½œExcelä¸‹è¼‰",
)

# =====================================
# âœ… constants
# =====================================
NEED_COLS = ["packqty", "å…¥æ•¸", "ç®±é¡å‹", "è¼‰å…·è™Ÿ", "BOXTYPE", "boxid"]
CANDIDATE_SEPS = ["\t", ",", "|", ";"]

ENCODING_CANDIDATES = [
    "utf-8-sig",
    "utf-8",
    "cp950",
    "big5",
    "gb18030",
    "cp936",
    "utf-16",
    "utf-16le",
    "utf-16be",
]


# =====================================
# âœ… helpers
# =====================================
def _safe_str(s: pd.Series) -> pd.Series:
    return s.astype(str).fillna("").astype(str)


def _fmt_int(x) -> str:
    try:
        return f"{int(round(float(x))):,}"
    except Exception:
        return "0"


def _fmt0(x) -> str:
    try:
        return f"{float(x):,.0f}"
    except Exception:
        return "0"


def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    return df


# =====================================
# âœ… Encoding detectionï¼ˆè§£æ±ºä¸­æ–‡äº‚ç¢¼ï¼‰
# =====================================
def _bom_encoding(raw: bytes) -> str | None:
    if raw.startswith(b"\xef\xbb\xbf"):
        return "utf-8-sig"
    if raw.startswith(b"\xff\xfe") or raw.startswith(b"\xfe\xff"):
        return "utf-16"
    return None


def _has_utf16_nulls(raw: bytes) -> bool:
    head = raw[:2000] if len(raw) > 2000 else raw
    if not head:
        return False
    nul_ratio = head.count(b"\x00") / max(1, len(head))
    return nul_ratio > 0.08


def _score_text(text: str) -> int:
    repl = text.count("\ufffd")  # replacement char
    ctrl = sum(1 for ch in text if ord(ch) < 32 and ch not in ("\n", "\r", "\t"))
    cjk = sum(1 for ch in text if "\u4e00" <= ch <= "\u9fff")
    lines = [ln for ln in text.splitlines() if ln.strip()]
    first = lines[0] if lines else ""
    sep_bonus = max(first.count("\t"), first.count(","), first.count("|"), first.count(";"))
    return (cjk * 2) + (sep_bonus * 3) - (repl * 25) - (ctrl * 10)


def detect_best_encoding(raw: bytes) -> tuple[str, str]:
    bom = _bom_encoding(raw)
    if bom:
        txt = raw.decode(bom, errors="replace")
        return bom, txt[:4000]

    if _has_utf16_nulls(raw):
        for enc in ("utf-16", "utf-16le", "utf-16be"):
            try:
                txt = raw.decode(enc, errors="replace")
                return enc, txt[:4000]
            except Exception:
                continue

    head = raw[:400_000]
    best_enc = "utf-8"
    best_score = -10**18
    best_txt = ""

    for enc in ENCODING_CANDIDATES:
        try:
            txt = head.decode(enc, errors="replace")
        except Exception:
            continue
        sc = _score_text(txt)
        if sc > best_score:
            best_score = sc
            best_enc = enc
            best_txt = txt

    return best_enc, best_txt[:4000]


# =====================================
# âœ… TXT parse
# =====================================
def _detect_sep(text: str) -> str | None:
    lines = [ln for ln in text.splitlines() if ln.strip()]
    if not lines:
        return None
    first = lines[0]

    best = None
    best_cnt = 0
    for sep in CANDIDATE_SEPS:
        cnt = first.count(sep)
        if cnt > best_cnt:
            best_cnt = cnt
            best = sep
    return best if best_cnt > 0 else None


def _read_txt_as_df(text: str, mode: str) -> pd.DataFrame:
    """
    mode: auto / sep:\t / sep:, / sep:| / sep:; / ws / fwf
    """
    if mode.startswith("sep:"):
        sep = mode.split(":", 1)[1]
        return pd.read_csv(StringIO(text), sep=sep, dtype=str, engine="python")

    if mode == "ws":
        return pd.read_csv(StringIO(text), sep=r"\s+", dtype=str, engine="python")

    if mode == "fwf":
        return pd.read_fwf(StringIO(text), dtype=str)

    # auto
    sep = _detect_sep(text)
    if sep is not None:
        return pd.read_csv(StringIO(text), sep=sep, dtype=str, engine="python")

    # fallbackï¼šå¤šç©ºç™½ -> å›ºå®šå¯¬åº¦
    try:
        df_ws = pd.read_csv(StringIO(text), sep=r"\s+", dtype=str, engine="python")
        if df_ws.shape[1] >= 2:
            return df_ws
    except Exception:
        pass
    return pd.read_fwf(StringIO(text), dtype=str)


def read_txt_bytes(raw: bytes, parse_mode: str, encoding_choice: str) -> tuple[pd.DataFrame, str]:
    if encoding_choice == "è‡ªå‹•(åµæ¸¬)":
        enc, _ = detect_best_encoding(raw)
    else:
        enc = encoding_choice

    text = raw.decode(enc, errors="replace")
    df = _read_txt_as_df(text, parse_mode)
    return df, enc


# =====================================
# âœ… Read fileï¼ˆExcel/TXT/CSVï¼‰
# =====================================
def robust_read_file(uploaded_file, txt_parse_choice: str, txt_encoding_choice: str) -> tuple[pd.DataFrame, str | None]:
    name = (uploaded_file.name or "").lower()
    raw = uploaded_file.getvalue()

    parse_map = {
        "è‡ªå‹•": "auto",
        "Tab": "sep:\t",
        "é€—è™Ÿ ,": "sep:,",
        "ç›´ç·š |": "sep:|",
        "åˆ†è™Ÿ ;": "sep:;",
        "å¤šç©ºç™½(å°é½Š)": "ws",
        "å›ºå®šå¯¬åº¦(FWF)": "fwf",
    }
    parse_mode = parse_map.get(txt_parse_choice, "auto")

    if name.endswith(".txt") or name.endswith(".csv"):
        df, used_enc = read_txt_bytes(raw, parse_mode=parse_mode, encoding_choice=txt_encoding_choice)
        return df, used_enc

    bio = BytesIO(raw)
    try:
        return pd.read_excel(bio, engine="openpyxl"), None
    except Exception:
        bio.seek(0)
        return pd.read_excel(bio, engine="xlrd"), None


# =====================================
# âœ… Column mappingï¼ˆæ¬„ä½å°ç…§ï¼‰
# =====================================
def _guess_unit_col(cols: list[str]) -> str | None:
    if "unit" in cols:
        return "unit"
    for c in cols:
        if "unit" in c.lower():
            return c
    return None


def _guess_vehicle_col(df: pd.DataFrame) -> str | None:
    sample = df.head(8000)
    for c in sample.columns:
        s = _safe_str(sample[c])
        if s.str.contains("GM", case=False, na=False).any():
            return c
    return None


def _guess_box_type_col(df: pd.DataFrame) -> str | None:
    sample = df.head(8000)
    best = None
    best_score = -1

    skip = {
        "Facility",
        "Storerkey",
        "orderdate",
        "storeid",
        "storename",
        "shippeddate",
        "deliverydate",
        "deliverytime",
        "boxid",
        "externorderkey",
        "SKU",
        "manufacturersku",
        "descr",
        "susr2",
        "outqty",
        "packqty",
        "memo",
        "price",
        "buyersreference",
        "BOXTYPE",
    }

    for c in sample.columns:
        if c in skip:
            continue
        s = _safe_str(sample[c]).str.strip()
        s = s[s != ""]
        if len(s) == 0:
            continue

        nunq = s.nunique()
        avg_len = s.str.len().mean()

        score = 0
        if nunq <= 20:
            score += 2
        if nunq <= 10:
            score += 2
        if avg_len <= 4:
            score += 2
        if avg_len <= 2:
            score += 1

        if score > best_score:
            best_score = score
            best = c

    return best


def apply_column_mapping(df: pd.DataFrame, map_in: str | None, map_box: str | None, map_vehicle: str | None) -> pd.DataFrame:
    df = _normalize_columns(df)

    rename = {}
    if "å…¥æ•¸" not in df.columns and map_in and map_in in df.columns:
        rename[map_in] = "å…¥æ•¸"
    if "ç®±é¡å‹" not in df.columns and map_box and map_box in df.columns:
        rename[map_box] = "ç®±é¡å‹"
    if "è¼‰å…·è™Ÿ" not in df.columns and map_vehicle and map_vehicle in df.columns:
        rename[map_vehicle] = "è¼‰å…·è™Ÿ"

    if rename:
        df = df.rename(columns=rename)
    return df


# =====================================
# âœ… Compute
# =====================================
def compute(df_raw: pd.DataFrame) -> dict:
    df_raw = _normalize_columns(df_raw)

    missing = [c for c in NEED_COLS if c not in df_raw.columns]
    if missing:
        raise KeyError(
            f"âš ï¸ æ‰¾ä¸åˆ°å¿…è¦æ¬„ä½ï¼š{missing}\n"
            f"ç›®å‰è®€åˆ°çš„æ¬„ä½ï¼ˆå‰30ï¼‰ï¼š{list(df_raw.columns)[:30]}{' ...' if len(df_raw.columns)>30 else ''}"
        )

    before = len(df_raw)

    # 1) åˆªé™¤ã€Œç®±é¡å‹ã€å«ã€Œç«™æ‰€ã€
    df = df_raw[~_safe_str(df_raw["ç®±é¡å‹"]).str.contains("ç«™æ‰€", na=False)].copy()
    removed_station = before - len(df)

    # 2) æ–°å¢æ¬„ä½
    pack = pd.to_numeric(df["packqty"], errors="coerce")
    unit = pd.to_numeric(df["å…¥æ•¸"], errors="coerce")

    df["è¨ˆé‡å–®ä½æ•¸é‡"] = np.where((unit.notna()) & (unit != 0), pack / unit, np.nan)

    v = pd.to_numeric(df["è¨ˆé‡å–®ä½æ•¸é‡"], errors="coerce")
    is_int = np.isfinite(v) & np.isclose(v, np.round(v))
    df["å‡ºè²¨å–®ä½ï¼ˆåˆ¤æ–·å¾Œï¼‰"] = np.where(is_int, v, pack)

    # æ¬„ä½æ’å…¥ä½ç½®ï¼šå…¥æ•¸å³é‚Š
    cols = list(df.columns)
    for c in ["è¨ˆé‡å–®ä½æ•¸é‡", "å‡ºè²¨å–®ä½ï¼ˆåˆ¤æ–·å¾Œï¼‰"]:
        if c in cols:
            cols.remove(c)
    ins_pos = cols.index("å…¥æ•¸") + 1
    cols[ins_pos:ins_pos] = ["è¨ˆé‡å–®ä½æ•¸é‡", "å‡ºè²¨å–®ä½ï¼ˆåˆ¤æ–·å¾Œï¼‰"]
    df = df[cols]

    # 3) çµ±è¨ˆé®ç½©
    mask_gm = _safe_str(df["è¼‰å…·è™Ÿ"]).str.contains("GM", case=False, na=False)
    boxtype = _safe_str(df["BOXTYPE"]).str.strip()
    mask_box1 = boxtype == "1"
    mask_box0 = boxtype == "0"
    mask_not_gm = ~mask_gm

    # 4) å››é …çµ±è¨ˆ
    unique_boxid_count = (
        df.loc[mask_gm & mask_box1, "boxid"].astype(str).str.strip().replace("", np.nan).dropna().nunique()
    )

    ship_unit = pd.to_numeric(df["å‡ºè²¨å–®ä½ï¼ˆåˆ¤æ–·å¾Œï¼‰"], errors="coerce")
    total_shipunit_notgm_box0 = ship_unit.loc[mask_not_gm & mask_box0].sum()
    total_shipunit_gm_box1 = ship_unit.loc[mask_gm & mask_box1].sum()
    total_shipunit_notgm_box1 = ship_unit.loc[mask_not_gm & mask_box1].sum()

    return {
        "df_processed": df,
        "removed_station": int(removed_station),
        "total_in": int(len(df_raw)),
        "total_after": int(len(df)),
        "A_gm_cases": float(unique_boxid_count),
        "B_notgm_loose_pcs": float(total_shipunit_notgm_box0),
        "C_gm_box_pcs": float(total_shipunit_gm_box1),
        "D_notgm_box_pcs": float(total_shipunit_notgm_box1),
    }


def make_excel_bytes(summary_all: pd.DataFrame, detail_all: pd.DataFrame) -> bytes:
    bio = BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        summary_all.to_excel(writer, index=False, sheet_name="çµ±è¨ˆç¸½è¡¨")
        detail_all.to_excel(writer, index=False, sheet_name="åˆä½µæ˜ç´°")
    bio.seek(0)
    return bio.read()


# =====================================
# âœ… UI
# =====================================
# âœ… é¡å¤–æä¾›æ¸¬è©¦æŒ‰éˆ•ï¼ˆè‹¥é€™é¡†çœ‹ä¸åˆ° = theme é‚„åœ¨è—æŒ‰éˆ•ï¼‰
with st.expander("ğŸ§ª ä¸‹è¼‰æŒ‰éˆ•æ¸¬è©¦ï¼ˆè‹¥çœ‹ä¸åˆ°æŒ‰éˆ•ï¼theme æŠŠæŒ‰éˆ•è—äº†ï¼‰", expanded=False):
    st.download_button(
        "âœ… æ¸¬è©¦ä¸‹è¼‰ hello.txt",
        data="hello",
        file_name="hello.txt",
        mime="text/plain",
        key="dl_test_hello",
        use_container_width=True,
    )

card_open("ğŸ“¥ ä¸Šå‚³æ˜ç´°ï¼ˆExcel / TXTï¼Œå¯å¤šæª”ï¼‰")
colA, colB = st.columns(2)

with colA:
    txt_parse_choice = st.selectbox(
        "TXT åˆ†æ¬„æ–¹å¼",
        ["è‡ªå‹•", "Tab", "é€—è™Ÿ ,", "ç›´ç·š |", "åˆ†è™Ÿ ;", "å¤šç©ºç™½(å°é½Š)", "å›ºå®šå¯¬åº¦(FWF)"],
        index=0,
    )

with colB:
    txt_encoding_choice = st.selectbox(
        "TXT ç·¨ç¢¼",
        ["è‡ªå‹•(åµæ¸¬)", "cp950", "big5", "utf-8-sig", "utf-8", "gb18030", "cp936", "utf-16", "utf-16le", "utf-16be"],
        index=0,
    )

uploaded_files = st.file_uploader(
    "è«‹ä¸Šå‚³è¦è™•ç†çš„æª”æ¡ˆï¼ˆ.xlsx / .xls / .txtï¼‰",
    type=["xlsx", "xls", "xlsm", "txt", "csv"],
    accept_multiple_files=True,
)

card_close()

if not uploaded_files:
    st.info("è«‹å…ˆä¸Šå‚³æª”æ¡ˆï¼ˆå¯å¤šé¸ï¼‰ã€‚")
    st.stop()

# ç”¨ç¬¬ä¸€å€‹æª”æ¡ˆåšæ¬„ä½é è¦½èˆ‡çŒœæ¸¬ï¼ˆçµ¦ä¸‹æ‹‰ç”¨ï¼‰
try:
    df_preview, used_enc_preview = robust_read_file(uploaded_files[0], txt_parse_choice, txt_encoding_choice)
    df_preview = _normalize_columns(df_preview)
except Exception as e:
    st.error(f"ç¬¬ä¸€å€‹æª”æ¡ˆè®€å–å¤±æ•—ï¼š{e}")
    st.stop()

if used_enc_preview:
    st.caption(f"ç¬¬ä¸€å€‹ TXT åµæ¸¬/ä½¿ç”¨ç·¨ç¢¼ï¼š**{used_enc_preview}**ï¼ˆè‹¥ä¸­æ–‡ä»äº‚ç¢¼ï¼Œè«‹æ”¹ TXT ç·¨ç¢¼å†è©¦ï¼‰")

cols = list(df_preview.columns)
guess_in = _guess_unit_col(cols)
guess_vehicle = _guess_vehicle_col(df_preview)
guess_box = _guess_box_type_col(df_preview)

with st.expander("ğŸ§© æ¬„ä½å°ç…§ï¼ˆTXT ä¸­æ–‡äº‚ç¢¼æ™‚è«‹æŒ‡å®šï¼Œæœƒå¥—ç”¨åˆ°æ‰€æœ‰æª”æ¡ˆï¼‰", expanded=True):
    st.caption("Excel è‹¥å·²æœ‰ã€å…¥æ•¸/ç®±é¡å‹/è¼‰å…·è™Ÿã€å¯ç¶­æŒï¼ˆè‡ªå‹•ï¼‰ã€‚TXT è‹¥æ¬„åäº‚ç¢¼ï¼Œè«‹åœ¨ä¸‹æ‹‰é¸åˆ°æ­£ç¢ºæ¬„ä½ã€‚")
    opt = ["ï¼ˆè‡ªå‹•ï¼‰"] + cols

    c1, c2, c3 = st.columns(3)
    with c1:
        map_in = st.selectbox("å…¥æ•¸ æ¬„ä½", opt, index=(opt.index(guess_in) if guess_in in opt else 0))
    with c2:
        map_box = st.selectbox("ç®±é¡å‹ æ¬„ä½", opt, index=(opt.index(guess_box) if guess_box in opt else 0))
    with c3:
        map_vehicle = st.selectbox("è¼‰å…·è™Ÿ æ¬„ä½ï¼ˆç”¨ä¾†åˆ¤æ–· GMï¼‰", opt, index=(opt.index(guess_vehicle) if guess_vehicle in opt else 0))

map_in = None if map_in == "ï¼ˆè‡ªå‹•ï¼‰" else map_in
map_box = None if map_box == "ï¼ˆè‡ªå‹•ï¼‰" else map_box
map_vehicle = None if map_vehicle == "ï¼ˆè‡ªå‹•ï¼‰" else map_vehicle

results = []
details = []
errors = []

with st.spinner("è™•ç†ä¸­â€¦"):
    for f in uploaded_files:
        fname = f.name
        try:
            df_raw, used_enc = robust_read_file(f, txt_parse_choice, txt_encoding_choice)
            df_raw = apply_column_mapping(df_raw, map_in=map_in, map_box=map_box, map_vehicle=map_vehicle)

            out = compute(df_raw)

            results.append(
                {
                    "æª”å": fname,
                    "TXTç·¨ç¢¼": used_enc or "",
                    "è®€å–åˆ—æ•¸": out["total_in"],
                    "åˆªé™¤ç«™æ‰€åˆ—æ•¸": out["removed_station"],
                    "è™•ç†å¾Œåˆ—æ•¸": out["total_after"],
                    "A) GMä»¶æ•¸": out["A_gm_cases"],
                    "B) ä¸€èˆ¬å€‰é›¶æ•£PCS": out["B_notgm_loose_pcs"],
                    "C) GMæˆç®±PCS": out["C_gm_box_pcs"],
                    "D) ä¸€èˆ¬å€‰æˆç®±PCS": out["D_notgm_box_pcs"],
                }
            )

            df_p = out["df_processed"].copy()
            df_p.insert(0, "ä¾†æºæª”å", fname)
            details.append(df_p)

        except Exception as e:
            errors.append({"æª”å": fname, "éŒ¯èª¤": str(e)})

if errors:
    with st.expander("âš ï¸ éƒ¨åˆ†æª”æ¡ˆè™•ç†å¤±æ•—ï¼ˆå·²ç•¥éï¼‰", expanded=True):
        st.dataframe(pd.DataFrame(errors), use_container_width=True, hide_index=True)

if not results:
    st.error("æ²’æœ‰ä»»ä½•æª”æ¡ˆæˆåŠŸè™•ç†ï¼šè«‹å…ˆæŠŠ TXT ç·¨ç¢¼èª¿åˆ°ä¸­æ–‡æ­£å¸¸ï¼ˆæœ€å¸¸è¦‹ cp950 / big5 / utf-16ï¼‰ï¼Œæˆ–åœ¨ã€æ¬„ä½å°ç…§ã€æŒ‡å®šå…¥æ•¸/ç®±é¡å‹/è¼‰å…·è™Ÿã€‚")
    st.stop()

summary_all = pd.DataFrame(results)
detail_all = pd.concat(details, ignore_index=True) if details else pd.DataFrame()

# KPIï¼ˆåˆè¨ˆï¼‰
total_files_ok = len(summary_all)
total_in = int(summary_all["è®€å–åˆ—æ•¸"].sum())
total_removed = int(summary_all["åˆªé™¤ç«™æ‰€åˆ—æ•¸"].sum())
total_after = int(summary_all["è™•ç†å¾Œåˆ—æ•¸"].sum())

A_sum = float(summary_all["A) GMä»¶æ•¸"].sum())
B_sum = float(summary_all["B) ä¸€èˆ¬å€‰é›¶æ•£PCS"].sum())
C_sum = float(summary_all["C) GMæˆç®±PCS"].sum())
D_sum = float(summary_all["D) ä¸€èˆ¬å€‰æˆç®±PCS"].sum())

st.caption(
    f"æˆåŠŸè™•ç† {total_files_ok} å€‹æª”æ¡ˆï¼›"
    f"åˆè¨ˆè®€å– {total_in:,} åˆ—ï¼›åˆªé™¤ç«™æ‰€ {total_removed:,} åˆ—ï¼›è™•ç†å¾Œ {total_after:,} åˆ—ã€‚"
)

left, right = st.columns(2, gap="large")
with left:
    render_kpis(
        [
            KPI("A) GMä»¶æ•¸ï¼ˆåˆè¨ˆï¼‰", _fmt_int(A_sum)),
            KPI("C) GMæˆç®±PCSï¼ˆåˆè¨ˆï¼‰", _fmt0(C_sum)),
            KPI("B) ä¸€èˆ¬å€‰é›¶æ•£PCSï¼ˆåˆè¨ˆï¼‰", _fmt0(B_sum)),
            KPI("D) ä¸€èˆ¬å€‰æˆç®±PCSï¼ˆåˆè¨ˆï¼‰", _fmt0(D_sum)),
        ],
        cols=1,
    )

card_open("ğŸ“Œ å¤šæª”çµ±è¨ˆç¸½è¡¨")
show_df = summary_all.copy()
for c in ["A) GMä»¶æ•¸", "B) ä¸€èˆ¬å€‰é›¶æ•£PCS", "C) GMæˆç®±PCS", "D) ä¸€èˆ¬å€‰æˆç®±PCS"]:
    show_df[c] = show_df[c].apply(_fmt0)
st.dataframe(show_df, use_container_width=True, hide_index=True)
card_close()

# =====================================
# âœ… åŒ¯å‡ºï¼ˆä¸è¦åŒ…åœ¨ card_open/card_close å…§ï¼Œé¿å… theme/å¡ç‰‡æŠŠæŒ‰éˆ•åƒæ‰ï¼‰
# =====================================
st.subheader("ğŸ“¤ åŒ¯å‡ºï¼ˆçµ±è¨ˆç¸½è¡¨ + åˆä½µæ˜ç´°ï¼‰")

export_detail = st.checkbox("åŒ…å«åˆä½µæ˜ç´°ï¼ˆæ˜ç´°å¾ˆå¤§æ™‚å¯èƒ½ä¸‹è¼‰å¤±æ•—ï¼‰", value=True)

stamp = datetime.now().strftime("%Y%m%d_%H%M%S")
fn_summary = f"DaFengKPI_OverallVolume_Summary_{stamp}.xlsx"
fn_full = f"DaFengKPI_OverallVolume_Full_{stamp}.xlsx"
fn_detail_gz = f"DaFengKPI_OverallVolume_Detail_{stamp}.csv.gz"

# 1) âœ… çµ±è¨ˆç¸½è¡¨ï¼šæ°¸é æä¾› Excelï¼ˆé€šå¸¸å¾ˆå°ã€æœ€ç©©ï¼‰
bio_sum = BytesIO()
with pd.ExcelWriter(bio_sum, engine="openpyxl") as writer:
    summary_all.to_excel(writer, index=False, sheet_name="çµ±è¨ˆç¸½è¡¨")
bio_sum.seek(0)
xlsx_sum = bio_sum.read()

st.download_button(
    label="âœ… ä¸‹è¼‰ Excelï¼ˆåªå«ï¼šçµ±è¨ˆç¸½è¡¨ï¼‰",
    data=xlsx_sum,
    file_name=fn_summary,
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    use_container_width=True,
    key=f"dl_sum_{stamp}",
)
st.caption(f"çµ±è¨ˆç¸½è¡¨å¤§å°ï¼š{len(xlsx_sum)/1024/1024:.2f} MB")

# 2) âœ… åˆä½µæ˜ç´°ï¼šæä¾›å…©ç¨®è·¯å¾‘
if export_detail:
    # 2-1) å…ˆå˜—è©¦åšã€Œå®Œæ•´ Excelã€ï¼ˆå¯èƒ½å¾ˆå¤§ï¼‰
    try:
        bio_full = BytesIO()
        with pd.ExcelWriter(bio_full, engine="openpyxl") as writer:
            summary_all.to_excel(writer, index=False, sheet_name="çµ±è¨ˆç¸½è¡¨")
            detail_all.to_excel(writer, index=False, sheet_name="åˆä½µæ˜ç´°")
        bio_full.seek(0)
        xlsx_full = bio_full.read()

        size_mb = len(xlsx_full) / 1024 / 1024
        st.caption(f"å®Œæ•´ Excel å¤§å°ï¼š{size_mb:.2f} MB")

        # âš ï¸ å¤ªå¤§å°±å»ºè­°æ”¹èµ° CSV.gzï¼ˆæ›´ç©©ï¼‰
        if size_mb > 25:
            st.warning("å®Œæ•´ Excel æª”æ¡ˆåå¤§ï¼ˆ> 25MBï¼‰ï¼Œè‹¥ä½ é»äº†æ²’åæ‡‰ï¼Œè«‹æ”¹ç”¨ä¸‹æ–¹ã€Œæ˜ç´° CSV.gzã€ä¸‹è¼‰ï¼ˆæ›´ç©©ï¼‰ã€‚")

        st.download_button(
            label="â¬‡ï¸ ä¸‹è¼‰ Excelï¼ˆå«ï¼šçµ±è¨ˆç¸½è¡¨ + åˆä½µæ˜ç´°ï¼‰",
            data=xlsx_full,
            file_name=fn_full,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
            key=f"dl_full_{stamp}",
        )

    except Exception as e:
        st.error(f"ç”¢ç”Ÿå®Œæ•´ Excel å¤±æ•—ï¼š{e}")

    # 2-2) âœ… æ˜ç´° CSV.gzï¼ˆæœ€ç©©å‚™æ´ï¼‰
    try:
        # ç”¨ gzip å£“ç¸®çš„ CSVï¼Œé€šå¸¸æ¯” xlsx æ›´å°ã€æ›´ä¸å®¹æ˜“è¢«å¡
        gz_bytes = detail_all.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
        # è‹¥ä½ å¸Œæœ›æ›´å°ï¼Œå¯ä»¥æ”¹ç”¨ gzip å£“ç¸®ï¼ˆä¸‹é¢æ˜¯ gzip ç‰ˆæœ¬ï¼‰
        import gzip
        gz_buf = BytesIO()
        with gzip.GzipFile(fileobj=gz_buf, mode="wb") as gz:
            gz.write(detail_all.to_csv(index=False).encode("utf-8"))
        gz_buf.seek(0)
        detail_csv_gz = gz_buf.read()

        st.download_button(
            label="â¬‡ï¸ ä¸‹è¼‰ æ˜ç´°ï¼ˆCSV.gzï¼Œæ¨è–¦ï¼æ›´ç©©ï¼‰",
            data=detail_csv_gz,
            file_name=fn_detail_gz,
            mime="application/gzip",
            use_container_width=True,
            key=f"dl_detail_gz_{stamp}",
        )
        st.caption(f"æ˜ç´° CSV.gz å¤§å°ï¼š{len(detail_csv_gz)/1024/1024:.2f} MB")

    except Exception as e:
        st.error(f"ç”¢ç”Ÿæ˜ç´° CSV.gz å¤±æ•—ï¼š{e}")

with st.expander("ğŸ” åˆä½µæ˜ç´°é è¦½ï¼ˆå‰ 200 ç­†ï¼‰", expanded=False):
    st.dataframe(detail_all.head(200), use_container_width=True)
    
