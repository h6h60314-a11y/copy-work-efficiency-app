# pages/13_åº«å­˜è¨‚å–®å¯¦å‡ºé‡åˆ†æ.py
import io
import os
import re
from typing import Tuple, Dict, List

import pandas as pd
import streamlit as st

from common_ui import inject_logistics_theme, set_page, card_open, card_close


# -----------------------------
# Page setup
# -----------------------------
st.set_page_config(page_title="åº«å­˜è¨‚å–®å¯¦å‡ºé‡åˆ†æ", page_icon="ğŸ“¦", layout="wide")
inject_logistics_theme()


# -----------------------------
# Requirements
# -----------------------------
REQUIRED_COLS = [
    "ç®±é¡å‹", "packqty", "å…¥æ•¸",
    "buyersreference", "BOXTYPE",
    "externorderkey", "SKU", "boxid"
]
BUYERS_OK = {"GSO", "GCOR"}


# -----------------------------
# Column mapping (auto)
# ä½ å¯ä»¥ç¹¼çºŒåŠ åŒç¾©æ¬„ä½ï¼Œè¶Šå®Œæ•´è¶Šä¸æœƒè®€ä¸åˆ°
# key=æ¨™æº–æ¬„å, values=å¯èƒ½å‡ºç¾çš„åŒç¾©æ¬„åï¼ˆå¤§å°å¯«ä¸æ‹˜ã€å¯å«ç©ºç™½/åº•ç·šï¼‰
# -----------------------------
COLUMN_SYNONYMS: Dict[str, List[str]] = {
    "ç®±é¡å‹": ["ç®±é¡å‹", "ç®±å‹", "ç®±åˆ«", "ç®±åˆ¥", "boxtype_name", "carton_type", "ç®±ç¨®", "ç®±ç§"],
    "packqty": ["packqty", "pack_qty", "pack quantity", "æ•¸é‡", "æ•°é‡", "pcs", "qty", "pack"],
    "å…¥æ•¸": ["å…¥æ•¸", "å…¥æ•°", "å…¥æ•¸é‡", "å…¥æ•°é‡", "innum", "in_qty", "unitspercase", "units_per_case", "casepack", "case_pack"],
    "buyersreference": ["buyersreference", "buyers_reference", "buyer reference", "buyerref", "order_type", "å–®åˆ¥", "å•åˆ«", "refer", "buyers ref"],
    "BOXTYPE": ["boxtype", "box_type", "ç®±åˆ¥å‹æ…‹", "ç®±å‹æ…‹", "ç®±åˆ«å‹æ€", "ç®±é¡å‹ä»£ç¢¼", "ç®±ç±»å‹ä»£ç "],
    "externorderkey": ["externorderkey", "extern_order_key", "orderkey", "order_key", "order id", "order_id", "è¨‚å–®è™Ÿ", "è®¢å•å·", "å–®è™Ÿ", "å•å·", "externorder"],
    "SKU": ["sku", "item", "itemcode", "item_code", "å•†å“", "å•†å“ç¢¼", "å•†å“ç ", "å“è™Ÿ", "å“å·", "æ–™è™Ÿ", "æ–™å·"],
    "boxid": ["boxid", "box_id", "box id", "ç®±è™Ÿ", "ç®±å·", "ç®±ç¢¼", "ç®±ç ", "cartonid", "carton_id", "containerid", "container_id"],
}


def _normalize_col(s: str) -> str:
    """æŠŠæ¬„åçµ±ä¸€æˆï¼šå°å¯« + å»ç©ºç™½ + ç§»é™¤ç‰¹æ®Šå­—å…ƒ"""
    s = str(s).strip()
    s = s.replace("\u3000", " ")  # å…¨å½¢ç©ºç™½
    s = re.sub(r"\s+", "", s)     # ç§»é™¤æ‰€æœ‰ç©ºç™½
    s = s.replace("-", "_").replace(".", "_").replace("/", "_")
    s = re.sub(r"[^0-9a-zA-Z_\u4e00-\u9fff]", "", s)  # ä¿ç•™ä¸­è‹±æ•¸èˆ‡åº•ç·š
    return s.lower()


def _apply_column_mapping(df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, str]]:
    """
    ä¾ COLUMN_SYNONYMS è‡ªå‹•æŠŠåŒç¾©æ¬„å rename æˆæ¨™æº–æ¬„å
    å›å‚³ï¼šæ–°df + å‘½ä¸­çš„å°ç…§è¡¨ï¼ˆåŸæ¬„å -> æ¨™æº–æ¬„åï¼‰
    """
    df = df.copy()
    orig_cols = list(df.columns)

    norm_to_orig = {}
    for c in orig_cols:
        norm_to_orig[_normalize_col(c)] = c

    rename_map = {}  # orig -> std
    for std, syns in COLUMN_SYNONYMS.items():
        for syn in syns:
            key = _normalize_col(syn)
            if key in norm_to_orig:
                rename_map[norm_to_orig[key]] = std
                break

    if rename_map:
        df = df.rename(columns=rename_map)

    return df, rename_map


def _is_provider_fake_xls(raw: bytes) -> bool:
    head = raw[:2048].upper()
    return (b"PROVIDER" in head) or (b"<HTML" in head) or (b"<TABLE" in head)


def _read_html_from_bytes(raw: bytes) -> pd.DataFrame:
    for enc in ("utf-8", "utf-8-sig", "big5", "cp950", "latin1"):
        try:
            text = raw.decode(enc, errors="ignore")
            tables = pd.read_html(io.StringIO(text))
            if tables:
                return tables[0]
        except Exception:
            continue
    raise ValueError("HTML è§£æå¤±æ•—ï¼ˆå¯èƒ½ä¸æ˜¯è¡¨æ ¼æ ¼å¼æˆ–å…§å®¹ä¸å®Œæ•´ï¼‰")


def _read_txt_to_df(raw: bytes) -> pd.DataFrame:
    content = None
    for enc in ("utf-8", "utf-8-sig", "cp950", "big5", "latin1"):
        try:
            content = raw.decode(enc)
            break
        except Exception:
            continue
    if content is None:
        content = raw.decode("latin1", errors="ignore")

    sample = content[:5000]
    sep = None
    if "\t" in sample:
        sep = "\t"
    elif "," in sample:
        sep = ","
    elif "|" in sample:
        sep = "|"

    if sep:
        return pd.read_csv(io.StringIO(content), sep=sep, engine="python")
    return pd.read_csv(io.StringIO(content), sep=r"\s+", engine="python")


def _read_any(uploaded) -> Tuple[pd.DataFrame, str]:
    name = uploaded.name
    ext = os.path.splitext(name)[1].lower()
    raw = uploaded.getvalue()

    if ext == ".txt":
        df = _read_txt_to_df(raw)
        return df, name

    if ext == ".csv":
        df = pd.read_csv(io.BytesIO(raw))
        return df, name

    if ext in (".html", ".htm"):
        df = _read_html_from_bytes(raw)
        return df, name

    if ext in (".xlsx", ".xlsm"):
        df = pd.read_excel(io.BytesIO(raw), engine="openpyxl")
        return df, name

    if ext == ".xls":
        if _is_provider_fake_xls(raw):
            df = _read_html_from_bytes(raw)
            return df, name
        try:
            df = pd.read_excel(io.BytesIO(raw), engine="xlrd")
            return df, name
        except Exception:
            df = _read_html_from_bytes(raw)
            return df, name

    # fallback
    try:
        df = pd.read_excel(io.BytesIO(raw), engine="openpyxl")
        return df, name
    except Exception:
        df = _read_html_from_bytes(raw)
        return df, name


def _validate_cols(df: pd.DataFrame) -> List[str]:
    missing = [c for c in REQUIRED_COLS if c not in df.columns]
    return missing


def _to_number(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for c in ("packqty", "å…¥æ•¸", "BOXTYPE"):
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    return df


def _compute(df: pd.DataFrame) -> dict:
    df = df.copy()

    # æ’é™¤ã€Œç®±é¡å‹ã€å«ã€Œç«™æ‰€ã€
    df = df[~df["ç®±é¡å‹"].astype(str).str.contains("ç«™æ‰€", na=False)].copy()

    # æ–°å¢ã€Œå‡ºè²¨å–®ä½æ•¸é‡ã€
    if "å‡ºè²¨å–®ä½æ•¸é‡" not in df.columns:
        try:
            idx = df.columns.get_loc("å…¥æ•¸")
            df.insert(idx + 1, "å‡ºè²¨å–®ä½æ•¸é‡", 0)
        except Exception:
            df["å‡ºè²¨å–®ä½æ•¸é‡"] = 0

    df["å‡ºè²¨å–®ä½æ•¸é‡"] = df["packqty"] / df["å…¥æ•¸"]

    mask_base = df["buyersreference"].astype(str).isin(BUYERS_OK)

    mask0 = mask_base & (df["BOXTYPE"] == 0)
    total_packqty_box0 = df.loc[mask0, "packqty"].sum()

    mask1_eq = mask_base & (df["BOXTYPE"] == 1) & (df["å‡ºè²¨å–®ä½æ•¸é‡"] == 1)
    total_packqty_box1_eq = df.loc[mask1_eq, "packqty"].sum()

    mask1_neq = mask_base & (df["BOXTYPE"] == 1) & (df["å‡ºè²¨å–®ä½æ•¸é‡"] != 1)
    total_units_box1_neq = df.loc[mask1_neq, "å‡ºè²¨å–®ä½æ•¸é‡"].sum()

    total_combined = total_packqty_box1_eq + total_units_box1_neq

    filtered = df[mask_base].copy()
    pivot = (
        filtered
        .pivot_table(index=["externorderkey", "SKU"], aggfunc="size")
        .reset_index(name="count")
    )
    total_groups = int(pivot.shape[0])

    df_box0 = df[df["BOXTYPE"] == 0]
    df_box1 = df[df["BOXTYPE"] == 1]
    count_box0 = int(df_box0["boxid"].nunique())
    count_box1 = int(df_box1["boxid"].nunique())

    return {
        "df": df,
        "å¯¦éš›å‡ºè²¨é‡PTL_è¨‚å–®ç­†æ•¸": total_groups,
        "å¯¦éš›å‡ºè²¨é‡_åº«å­˜é›¶æ•£PCS": float(total_packqty_box0),
        "å¯¦éš›å‡ºè²¨é‡_åº«å­˜æˆç®±PCS": float(total_combined),
        "æ··åº«é›¶æ•£å‡ºè²¨ä»¶æ•¸": count_box0,
        "æ··åº«æˆç®±å‡ºè²¨ä»¶æ•¸": count_box1,
    }


def _fmt_num(x) -> str:
    try:
        if x is None:
            return "-"
        if float(x).is_integer():
            return f"{int(x):,}"
        return f"{float(x):,.2f}"
    except Exception:
        return str(x)


# -----------------------------
# UI
# -----------------------------
set_page(
    "åº«å­˜è¨‚å–®å¯¦å‡ºé‡åˆ†æ",
    icon="ğŸ“¦",
    subtitle="æ”¯æ´ TXT / å‡xls(PROVIDER)ï½œæ¬„ä½è‡ªå‹•å°ç…§ï½œæ’é™¤ç®±é¡å‹=ç«™æ‰€ï½œå¯¦éš›å‡ºè²¨é‡(PTL)ï½œæ··åº«å‡ºè²¨ä»¶æ•¸",
)

card_open("ğŸ“Œ ä¸Šå‚³æ˜ç´°æª”")
uploaded = st.file_uploader(
    "è«‹ä¸Šå‚³æ˜ç´°æª”ï¼ˆXLSX / XLSM / XLS / CSV / HTML / TXTï¼‰",
    type=["xlsx", "xlsm", "xls", "csv", "html", "htm", "txt"],
)
st.caption("å¿…è¦æ¬„ä½ï¼šç®±é¡å‹ã€packqtyã€å…¥æ•¸ã€buyersreferenceã€BOXTYPEã€externorderkeyã€SKUã€boxidï¼ˆå¯åŒç¾©æ¬„åè‡ªå‹•å°ç…§ï¼‰")
card_close()

if not uploaded:
    st.stop()

progress = st.progress(0, text="è³‡æ–™è®€å–ä¸­â€¦")
with st.spinner("è³‡æ–™è®€å–ä¸­â€¦è«‹ç¨å€™ï¼ˆæª”æ¡ˆè¶Šå¤§è¶Šä¹…ï¼‰"):
    progress.progress(15, text="è³‡æ–™è®€å–ä¸­â€¦ï¼ˆè®€å–æª”æ¡ˆï¼‰")
    df, src_name = _read_any(uploaded)

    progress.progress(35, text="è³‡æ–™è®€å–ä¸­â€¦ï¼ˆæ¬„ä½æ¸…ç†/è‡ªå‹•å°ç…§ï¼‰")
    df.columns = [str(c).strip() for c in df.columns]
    df, hit_map = _apply_column_mapping(df)

    progress.progress(55, text="è³‡æ–™è®€å–ä¸­â€¦ï¼ˆæ¬„ä½æª¢æŸ¥ï¼‰")
    missing = _validate_cols(df)

    # âœ… ç¼ºæ¬„ä½ï¼šä¸è¦è®“æ•´é çˆ†æ‰ï¼Œç›´æ¥é¡¯ç¤ºæç¤º + æ¬„ä½æ¸…å–®
    if missing:
        progress.empty()
        st.error(f"ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{missing}")

        if hit_map:
            st.info("å·²è‡ªå‹•å°ç…§ï¼ˆåŸæ¬„å â†’ æ¨™æº–æ¬„åï¼‰ï¼š")
            st.write(hit_map)

        st.markdown("#### ä½ ä¸Šå‚³æª”æ¡ˆç›®å‰çš„æ¬„ä½ï¼ˆè«‹å°ç…§æ˜¯å¦åç¨±ä¸åŒ/æœ‰åŒç¾©æ¬„ä½ï¼‰")
        st.dataframe(pd.DataFrame({"columns": list(df.columns)}), use_container_width=True, height=300)

        st.stop()

    progress.progress(70, text="è³‡æ–™è®€å–ä¸­â€¦ï¼ˆè³‡æ–™è½‰å‹ï¼‰")
    df = _to_number(df)

    progress.progress(90, text="è³‡æ–™è®€å–ä¸­â€¦ï¼ˆè¨ˆç®—ä¸­ï¼‰")
    result = _compute(df)

    progress.progress(100, text="å®Œæˆ âœ…")

progress.empty()
st.success(f"å·²è®€å–ï¼š{src_name}ï¼ˆ{len(result['df']):,} ç­† / {len(result['df'].columns)} æ¬„ï¼‰")

# Metrics
left, right = st.columns([1, 1], gap="large")

with left:
    st.markdown("### å¯¦éš›å‡ºè²¨é‡ï¼ˆPTLï¼‰")
    st.metric("è¨‚å–®ç­†æ•¸", _fmt_num(result["å¯¦éš›å‡ºè²¨é‡PTL_è¨‚å–®ç­†æ•¸"]))
    st.metric("åº«å­˜é›¶æ•£ PCS", _fmt_num(result["å¯¦éš›å‡ºè²¨é‡_åº«å­˜é›¶æ•£PCS"]))
    st.metric("åº«å­˜æˆç®± PCS", _fmt_num(result["å¯¦éš›å‡ºè²¨é‡_åº«å­˜æˆç®±PCS"]))

with right:
    st.markdown("### æ··åº«å‡ºè²¨ä»¶æ•¸")
    st.metric("æ··åº«é›¶æ•£å‡ºè²¨ä»¶æ•¸", _fmt_num(result["æ··åº«é›¶æ•£å‡ºè²¨ä»¶æ•¸"]))
    st.metric("æ··åº«æˆç®±å‡ºè²¨ä»¶æ•¸", _fmt_num(result["æ··åº«æˆç®±å‡ºè²¨ä»¶æ•¸"]))

st.divider()

st.markdown("### æ˜ç´°é è¦½ï¼ˆå«ï¼šå‡ºè²¨å–®ä½æ•¸é‡ï¼‰")
st.dataframe(result["df"].head(200), use_container_width=True, height=420)

# Export
out_df = result["df"].copy()
buf = io.BytesIO()
with pd.ExcelWriter(buf, engine="openpyxl") as writer:
    out_df.to_excel(writer, index=False, sheet_name="æ˜ç´°")
buf.seek(0)

st.download_button(
    "â¬‡ï¸ ä¸‹è¼‰è™•ç†å¾Œæ˜ç´°ï¼ˆExcelï¼‰",
    data=buf.getvalue(),
    file_name="åº«å­˜è¨‚å–®å¯¦å‡ºé‡åˆ†æ_æ˜ç´°.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
)
