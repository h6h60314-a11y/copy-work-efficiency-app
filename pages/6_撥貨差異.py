# pages/20_æ’¥è²¨å·®ç•°.py
import io
import os
import pandas as pd
import streamlit as st

from common_ui import inject_logistics_theme, set_page, card_open, card_close


st.set_page_config(page_title="å¤§è±ç‰©æµ - æ’¥è²¨å·®ç•°", page_icon="ğŸ”", layout="wide")
inject_logistics_theme()


# =========================
# è®€æª”ï¼šå¾ bytes è®€ (å¯éƒ¨ç½²)
# =========================
def _read_source_with_lookup_from_bytes(data: bytes):
    """ä¾†æºæª”ï¼šå›å‚³ main_df + (è‹¥æœ‰ 'å„²ä½' sheet å‰‡å›å‚³ lookup_df)"""
    head = data[:4096]

    # xlsx
    if head.startswith(b"PK\x03\x04"):
        bio = io.BytesIO(data)
        xls = pd.ExcelFile(bio, engine="openpyxl")
        sheets = xls.sheet_names
        main_sheet = "å„²ä½æ˜ç´°" if "å„²ä½æ˜ç´°" in sheets else sheets[0]
        main_df = pd.read_excel(xls, sheet_name=main_sheet, dtype=str).dropna(how="all").copy()

        lookup_df = None
        if "å„²ä½" in sheets:
            lookup_df = pd.read_excel(xls, sheet_name="å„²ä½", dtype=str).dropna(how="all").copy()

        return main_df, lookup_df

    # xls (OLE2) â€”â€” éœ€è¦ xlrd
    if head.startswith(b"\xD0\xCF\x11\xe0\xa1\xb1\x1a\xe1"):
        bio = io.BytesIO(data)
        xls = pd.ExcelFile(bio, engine="xlrd")
        sheets = xls.sheet_names
        main_sheet = "å„²ä½æ˜ç´°" if "å„²ä½æ˜ç´°" in sheets else sheets[0]
        main_df = pd.read_excel(xls, sheet_name=main_sheet, dtype=str).dropna(how="all").copy()

        lookup_df = None
        if "å„²ä½" in sheets:
            lookup_df = pd.read_excel(xls, sheet_name="å„²ä½", dtype=str).dropna(how="all").copy()

        return main_df, lookup_df

    # HTML
    head_text = head.decode("utf-8", errors="ignore").lower()
    if "<html" in head_text or "<table" in head_text:
        tables = pd.read_html(io.BytesIO(data), encoding="utf-8", keep_default_na=False)
        if not tables:
            raise ValueError("HTML å…§æ²’æœ‰è¡¨æ ¼å¯è®€å–")
        return tables[0].dropna(how="all").copy(), None

    # TSV/CSVï¼ˆå‡ xls å¸¸è¦‹ï¼‰
    sample = head.decode("utf-8", errors="ignore")
    sep = "\t" if sample.count("\t") >= sample.count(",") else ","

    last_err = None
    for enc in ("utf-8-sig", "cp950", "big5", "utf-8", "latin1"):
        try:
            txt = data.decode(enc, errors="strict")
            df = pd.read_csv(
                io.StringIO(txt), sep=sep, engine="python",
                dtype=str, keep_default_na=False
            ).dropna(how="all").copy()

            if df.shape[1] <= 1:
                alt_sep = "," if sep == "\t" else "\t"
                df2 = pd.read_csv(
                    io.StringIO(txt), sep=alt_sep, engine="python",
                    dtype=str, keep_default_na=False
                ).dropna(how="all").copy()
                if df2.shape[1] > df.shape[1]:
                    df = df2

            return df, None
        except Exception as e:
            last_err = e
            continue

    raise ValueError(f"ç„¡æ³•è®€å–ä¾†æºæª”ã€‚æœ€å¾ŒéŒ¯èª¤ï¼š{last_err}")


def _read_any_table_from_bytes(data: bytes) -> pd.DataFrame:
    """ä¸»æª”ï¼šè®€ç¬¬ä¸€å¼µè¡¨ï¼ˆæ”¯æ´ xlsx/xls/html/textï¼‰"""
    head = data[:4096]

    if head.startswith(b"PK\x03\x04"):
        bio = io.BytesIO(data)
        xls = pd.ExcelFile(bio, engine="openpyxl")
        return pd.read_excel(xls, sheet_name=xls.sheet_names[0], dtype=str).dropna(how="all").copy()

    if head.startswith(b"\xD0\xCF\x11\xe0\xa1\xb1\x1a\xe1"):
        bio = io.BytesIO(data)
        xls = pd.ExcelFile(bio, engine="xlrd")
        return pd.read_excel(xls, sheet_name=xls.sheet_names[0], dtype=str).dropna(how="all").copy()

    head_text = head.decode("utf-8", errors="ignore").lower()
    if "<html" in head_text or "<table" in head_text:
        tables = pd.read_html(io.BytesIO(data), encoding="utf-8", keep_default_na=False)
        if not tables:
            raise ValueError("HTML å…§æ²’æœ‰è¡¨æ ¼å¯è®€å–")
        return tables[0].dropna(how="all").copy()

    sample = head.decode("utf-8", errors="ignore")
    sep = "\t" if sample.count("\t") >= sample.count(",") else ","

    last_err = None
    for enc in ("utf-8-sig", "cp950", "big5", "utf-8", "latin1"):
        try:
            txt = data.decode(enc, errors="strict")
            df = pd.read_csv(
                io.StringIO(txt), sep=sep, engine="python",
                dtype=str, keep_default_na=False
            ).dropna(how="all").copy()

            if df.shape[1] <= 1:
                alt_sep = "," if sep == "\t" else "\t"
                df2 = pd.read_csv(
                    io.StringIO(txt), sep=alt_sep, engine="python",
                    dtype=str, keep_default_na=False
                ).dropna(how="all").copy()
                if df2.shape[1] > df.shape[1]:
                    df = df2

            return df
        except Exception as e:
            last_err = e
            continue

    raise ValueError(f"ç„¡æ³•è®€å–ä¸»æª”ã€‚æœ€å¾ŒéŒ¯èª¤ï¼š{last_err}")


# =========================
# å·¥å…·ï¼ˆæ²¿ç”¨ä½ åŸæœ¬é‚è¼¯ï¼‰
# =========================
def to_num(s: pd.Series) -> pd.Series:
    return pd.to_numeric(s, errors="coerce")


def is_zero_like(series: pd.Series) -> pd.Series:
    s_str = series.astype(str).str.strip()
    s_num = to_num(series)
    return (s_str == "0") | (s_num == 0)


def find_col_ci(df: pd.DataFrame, target: str):
    t = target.strip().upper()
    for c in df.columns:
        if str(c).strip().upper() == t:
            return c
    return None


def must_col_ci(df: pd.DataFrame, target: str):
    c = find_col_ci(df, target)
    if c is None:
        raise ValueError(f"æ‰¾ä¸åˆ°æ¬„ä½ï¼š{target}")
    return c


def norm_loc(x) -> str:
    if pd.isna(x):
        return ""
    return str(x).strip()[:9]


def reorder_final_cols(df: pd.DataFrame) -> pd.DataFrame:
    cols = ["SONO", "å·®ç•°é‡", "å„²ä½", "åœ‹éš›æ¢ç¢¼", "å•†å“åç¨±", "æ£šåˆ¥", "å•†å“è™Ÿ", "ä¾†æºæª”å"]
    for c in cols:
        if c not in df.columns:
            df[c] = ""
    return df.loc[:, cols].copy()


def step2_filter_or(df: pd.DataFrame) -> pd.DataFrame:
    c_dif = must_col_ci(df, "AllDIF")
    c_act = must_col_ci(df, "ALLACT")
    cond = (to_num(df[c_dif]) >= 15) | (is_zero_like(df[c_act]))
    return df.loc[cond].copy()


def step3_apply_macro2_logic_keep_sono(df_detail: pd.DataFrame, lookup_df: pd.DataFrame | None) -> pd.DataFrame:
    if df_detail.shape[1] < 16:
        raise ValueError(f"æ˜ç´°æ¬„ä½ä¸è¶³ï¼šç›®å‰ {df_detail.shape[1]} æ¬„ï¼Œè‡³å°‘è¦ A~Pï¼ˆ16æ¬„ï¼‰")

    c_sono = find_col_ci(df_detail, "SONO")
    sono_series = df_detail[c_sono] if c_sono is not None else pd.Series([""] * len(df_detail), index=df_detail.index)

    base = df_detail.iloc[:, :16].copy()

    colE = base.columns[4]     # å•†å“è™Ÿ
    colF = base.columns[5]     # åœ‹éš›æ¢ç¢¼
    colG = base.columns[6]     # å•†å“åç¨±
    colH = base.columns[7]     # å·®ç•°é‡
    colP = base.columns[15]    # å„²ä½

    base[colF] = base[colF].astype(str).str.strip().str[:13]
    base[colP] = base[colP].astype(str).str.strip().str[:9]

    mask_keep = ~is_zero_like(base[colH])
    base = base.loc[mask_keep].copy()
    sono_series = sono_series.loc[base.index]

    shelf = pd.Series([""] * len(base), index=base.index, dtype=object)
    if lookup_df is not None and lookup_df.shape[1] >= 2:
        k = lookup_df.columns[0]
        v = lookup_df.columns[1]
        mapping = dict(
            zip(
                lookup_df[k].astype(str).str.strip().map(norm_loc),
                lookup_df[v].astype(str).str.strip()
            )
        )
        shelf = base[colP].map(norm_loc).map(mapping).fillna("")

    out = pd.DataFrame({
        "SONO": sono_series.astype(str),
        "å„²ä½": base[colP].astype(str).str.strip(),
        "æ£šåˆ¥": shelf.astype(str),
        "å•†å“è™Ÿ": base[colE],
        "åœ‹éš›æ¢ç¢¼": base[colF],
        "å•†å“åç¨±": base[colG],
        "å·®ç•°é‡": base[colH],
    }).reset_index(drop=True)

    return out


def build_master_loc_shelf_map(df_master: pd.DataFrame) -> dict:
    c_loc = find_col_ci(df_master, "å„²ä½")
    c_shelf = find_col_ci(df_master, "æ£šåˆ¥")

    if c_loc is None or c_shelf is None:
        if df_master.shape[1] < 2:
            raise ValueError("ä¸»æª”æ¬„ä½ä¸è¶³ï¼Œè‡³å°‘è¦å…©æ¬„ï¼ˆå„²ä½ã€æ£šåˆ¥ï¼‰")
        c_loc = df_master.columns[0]
        c_shelf = df_master.columns[1]

    loc = df_master[c_loc].map(norm_loc)
    shelf = df_master[c_shelf].astype(str).str.strip()
    m = (loc != "")
    return dict(zip(loc[m], shelf[m]))


def step4_overwrite_shelf(df_macro2: pd.DataFrame, master_map: dict) -> tuple[pd.DataFrame, pd.DataFrame]:
    df = df_macro2.copy()
    key = df["å„²ä½"].map(norm_loc)
    shelf_master = key.map(master_map)

    df["æ£šåˆ¥"] = shelf_master.combine_first(df["æ£šåˆ¥"]).fillna("")
    not_found = df[shelf_master.isna()].copy()
    return df, not_found


def main():
    set_page("æ’¥è²¨å·®ç•°ï¼ˆæ£šåˆ¥æ¯”å°ï¼‰", icon="ğŸ”", subtitle="å¤šä¾†æºæª” OR ç¯©é¸ â†’ ç¬¬äºŒå·¨é›†é‚è¼¯ â†’ ä¸»æª”æ£šåˆ¥è¦†è“‹ â†’ åŒ¯å‡ºä¸‹è¼‰")

    card_open("ğŸ“¦ å‡ºè²¨èª²ï½œæ’¥è²¨å·®ç•°åˆ†æ")
    st.write("â‘  ä¸Šå‚³ä¾†æºæª”ï¼ˆå¯å¤šé¸ï¼Œå« AllDIF / ALLACT / å„²ä½æ˜ç´°ï¼‰")
    src_files = st.file_uploader(
        "ä¾†æºæª”ï¼ˆå¤šé¸ï¼‰",
        type=["xlsx", "xls", "csv", "tsv", "txt", "htm", "html"],
        accept_multiple_files=True,
        label_visibility="collapsed",
    )

    st.write("â‘¡ ä¸Šå‚³ä¸»æª”ï¼ˆå„²ä½â†’æ£šåˆ¥ï¼‰")
    master_file = st.file_uploader(
        "ä¸»æª”ï¼ˆå–®æª”ï¼‰",
        type=["xlsx", "xls", "csv", "tsv", "txt", "htm", "html"],
        accept_multiple_files=False,
        label_visibility="collapsed",
    )

    run = st.button("ğŸš€ é–‹å§‹åˆ†æä¸¦ç”¢å‡º Excel", use_container_width=True, disabled=not (src_files and master_file))

    if run:
        try:
            with st.spinner("è®€å–ä¸»æª”ä¸­..."):
                df_master = _read_any_table_from_bytes(master_file.getvalue())
                master_map = build_master_loc_shelf_map(df_master)

            all_or, all_final, all_notfound = [], [], []
            prog = st.progress(0)
            total = len(src_files)

            for i, uf in enumerate(src_files, 1):
                base_name = uf.name

                df_src, lookup_df = _read_source_with_lookup_from_bytes(uf.getvalue())
                df_detail = step2_filter_or(df_src)
                df_detail = df_detail.copy()
                df_detail["ä¾†æºæª”å"] = base_name
                all_or.append(df_detail)

                df_macro2 = step3_apply_macro2_logic_keep_sono(df_detail.drop(columns=["ä¾†æºæª”å"]), lookup_df)
                df_macro2["ä¾†æºæª”å"] = base_name

                df_final, df_notfound = step4_overwrite_shelf(df_macro2, master_map)
                df_final["ä¾†æºæª”å"] = base_name
                df_notfound["ä¾†æºæª”å"] = base_name

                df_final = reorder_final_cols(df_final)
                all_final.append(df_final)

                if not df_notfound.empty:
                    df_notfound = reorder_final_cols(df_notfound)
                    all_notfound.append(df_notfound)

                prog.progress(int(i / total * 100))

            out_or = pd.concat(all_or, ignore_index=True) if all_or else pd.DataFrame()
            out_final = pd.concat(all_final, ignore_index=True) if all_final else pd.DataFrame()
            out_notfound = pd.concat(all_notfound, ignore_index=True) if all_notfound else pd.DataFrame()

            out_name = os.path.splitext(src_files[0].name)[0] + "_å¤šæª”_æ£šåˆ¥è¦†è“‹.xlsx"

            bio = io.BytesIO()
            with pd.ExcelWriter(bio, engine="openpyxl") as writer:
                (out_or if not out_or.empty else pd.DataFrame({"msg": ["ç„¡è³‡æ–™"]})).to_excel(
                    writer, index=False, sheet_name="1_ç¯©é¸æ˜ç´°_OR"
                )
                (out_final if not out_final.empty else pd.DataFrame({"msg": ["ç„¡è³‡æ–™"]})).to_excel(
                    writer, index=False, sheet_name="å·®ç•°æ˜ç´°"
                )
                (out_notfound if not out_notfound.empty else pd.DataFrame({"msg": ["ç„¡è³‡æ–™"]})).to_excel(
                    writer, index=False, sheet_name="3_ä¸»æª”æ‰¾ä¸åˆ°å„²ä½"
                )

            bio.seek(0)
            st.success("âœ… å·²å®Œæˆï¼è«‹ä¸‹è¼‰çµæœæª”ã€‚")
            st.download_button(
                "â¬‡ï¸ ä¸‹è¼‰è¼¸å‡º Excel",
                data=bio,
                file_name=out_name,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True,
            )

        except Exception as e:
            st.error(f"âŒ åŸ·è¡Œå¤±æ•—ï¼š{e}")

    card_close()


if __name__ == "__main__":
    main()
