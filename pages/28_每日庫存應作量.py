# -*- coding: utf-8 -*-
# pages/28_æ¯æ—¥åº«å­˜æ‡‰ä½œé‡.py

import io
import inspect
import pandas as pd
import streamlit as st

# ---- å¥—ç”¨å¹³å°é¢¨æ ¼ï¼ˆæœ‰å°±ç”¨ï¼Œæ²’æœ‰å°±é€€å›åŸç”Ÿï¼‰----
try:
    from common_ui import (
        inject_logistics_theme,
        set_page,
        card_open,
        card_close,
        download_excel_card,
    )
    HAS_COMMON_UI = True
except Exception:
    HAS_COMMON_UI = False


# =============================
# helpers
# =============================
def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    1) å…¨æ¬„ä½åç¨±å»å‰å¾Œç©ºç™½
    2) å¸¸è¦‹äº‚ç¢¼/å…¨å½¢ç©ºç™½ä¹Ÿä¸€ä½µè™•ç†
    """
    df = df.copy()
    new_cols = []
    for c in df.columns:
        s = str(c)
        s = s.replace("\u3000", " ")  # å…¨å½¢ç©ºç™½ -> åŠå½¢
        s = s.strip()
        new_cols.append(s)
    df.columns = new_cols
    return df


def ensure_order_sku_column(df_order: pd.DataFrame) -> pd.DataFrame:
    """
    âœ… è¨‚å–®æª”ï¼šå¼·åˆ¶å°é½Šã€Œå•†å“ã€æ¬„ä½
    - å…ˆ normalize columns
    - è‹¥å­˜åœ¨ 'å•†å“ ' é€™ç¨®å°¾å·´ç©ºç™½ï¼Œnormalize å¾Œæœƒè®Šæˆ 'å•†å“'
    - è‹¥ä»æ²’æœ‰ï¼Œå˜—è©¦åŒç¾©æ¬„ä½æ˜ å°„åˆ° 'å•†å“'
    """
    df_order = normalize_columns(df_order)

    if "å•†å“" in df_order.columns:
        return df_order

    # åŒç¾©æ¬„ä½å€™é¸ï¼ˆä¾ä½ ç’°å¢ƒå¸¸è¦‹å‘½åï¼‰
    candidates = [
        "å•†å“ç¢¼",
        "å•†å“ä»£è™Ÿ",
        "å•†å“è™Ÿ",
        "å“è™Ÿ",
        "ITEM",
        "SKU",
        "SKU#",
        "Item",
        "item",
    ]
    for c in candidates:
        if c in df_order.columns:
            df_order = df_order.rename(columns={c: "å•†å“"})
            return df_order

    raise ValueError(f"è¨‚å–®æª”ç¼ºå°‘æ¬„ä½ã€å•†å“ã€ã€‚ç›®å‰æ¬„ä½ï¼š{list(df_order.columns)}")


def format_code(x, length: int) -> str:
    """è™•ç†ç©ºå€¼ã€å»é™¤å°æ•¸é»ã€è£œè¶³å‰å° 0 (å¦‚ 255 -> 000255)"""
    if pd.isna(x) or str(x).strip() == "":
        return ""
    s = str(x).strip()
    s = s.split(".")[0].strip()  # å»é™¤ Excel å¸¸è¦‹ .0
    return s.zfill(length)


def _is_fake_xls(raw: bytes) -> bool:
    head = raw[:2048].upper()
    return (b"<HTML" in head) or (b"<TABLE" in head) or (b"PROVIDER" in head)


def _read_fake_xls_text_or_html(raw: bytes) -> pd.DataFrame:
    for enc in ("utf-8-sig", "utf-8", "cp950", "big5"):
        try:
            text = raw.decode(enc, errors="replace")
            break
        except Exception:
            text = None
    if text is None:
        text = raw.decode("utf-8", errors="replace")

    if "<table" in text.lower():
        dfs = pd.read_html(io.StringIO(text))
        if not dfs:
            raise ValueError("åµæ¸¬ç‚º HTMLï¼Œä½†æ‰¾ä¸åˆ° table")
        return dfs[0]

    try:
        df = pd.read_csv(io.StringIO(text), sep="\t")
        if df.shape[1] >= 2:
            return df
    except Exception:
        pass

    return pd.read_csv(io.StringIO(text), sep=",")


def robust_read_table(uploaded) -> pd.DataFrame:
    name = (uploaded.name or "").lower()
    raw = uploaded.getvalue()

    if name.endswith(".csv"):
        try:
            return pd.read_csv(io.BytesIO(raw), encoding="utf-8-sig")
        except Exception:
            return pd.read_csv(io.BytesIO(raw), encoding="big5", errors="replace")

    if name.endswith((".xlsx", ".xlsm", ".xltx", ".xltm")):
        return pd.read_excel(io.BytesIO(raw), engine="openpyxl")

    if name.endswith(".xls"):
        if _is_fake_xls(raw):
            return _read_fake_xls_text_or_html(raw)
        try:
            import xlrd  # noqa: F401
        except Exception:
            raise ValueError(
                "ä½ ä¸Šå‚³çš„æ˜¯ã€çœŸ .xlsï¼ˆèˆŠç‰ˆ Excelï¼‰ã€ï¼Œéƒ¨ç½²ç’°å¢ƒéœ€å®‰è£ xlrd æ‰èƒ½è®€ã€‚\n"
                "è«‹åœ¨ requirements.txt åŠ ä¸Šï¼šxlrd>=2.0.1\n"
                "æˆ–å…ˆæŠŠæª”æ¡ˆå¦å­˜æˆ .xlsx / .csv å†ä¸Šå‚³ã€‚"
            )
        return pd.read_excel(io.BytesIO(raw), engine="xlrd")

    return pd.read_excel(io.BytesIO(raw))


def read_master_file(uploaded) -> tuple[pd.DataFrame, pd.DataFrame]:
    raw = uploaded.getvalue()
    name = (uploaded.name or "").lower()

    if name.endswith(".xls"):
        if _is_fake_xls(raw):
            raise ValueError("å•†å“ä¸»æª”ä¸æ‡‰æ˜¯ã€å‡ xlsã€æ ¼å¼ï¼Œè«‹æä¾›æ­£å¸¸ Excelï¼ˆå«åˆ†é ï¼‰ã€‚")
        try:
            import xlrd  # noqa: F401
        except Exception:
            raise ValueError(
                "å•†å“ä¸»æª”æ˜¯ .xlsï¼Œéƒ¨ç½²ç’°å¢ƒéœ€å®‰è£ xlrdã€‚\n"
                "è«‹åœ¨ requirements.txt åŠ ä¸Šï¼šxlrd>=2.0.1\n"
                "æˆ–å…ˆå¦å­˜æˆ .xlsx å†ä¸Šå‚³ã€‚"
            )
        engine = "xlrd"
    else:
        engine = "openpyxl"

    try:
        df_master = pd.read_excel(io.BytesIO(raw), sheet_name="å•†å“ä¸»æª”", engine=engine)
        df_weight = pd.read_excel(io.BytesIO(raw), sheet_name="å¤§é¡åŠ æ¬Š", engine=engine)
        df_master = normalize_columns(df_master)
        df_weight = normalize_columns(df_weight)
        return df_master, df_weight
    except Exception as e:
        raise ValueError("æ‰¾ä¸åˆ°ã€å•†å“ä¸»æª”ã€æˆ–ã€å¤§é¡åŠ æ¬Šã€åˆ†é ï¼Œè«‹æª¢æŸ¥ Excel å·¥ä½œè¡¨åç¨±ã€‚") from e


def build_result(df_order: pd.DataFrame, df_master: pd.DataFrame, df_weight: pd.DataFrame) -> tuple[pd.DataFrame, list[str]]:
    msgs: list[str] = []

    # âœ… æ¬„ä½å°é½Šï¼šä¸€å®šæŠŠè¨‚å–®æª”å°é½Šåˆ°æ¬„ä½ã€å•†å“ã€
    df_order = ensure_order_sku_column(df_order)

    # --- æ’é™¤ç‰¹æ®Šå„²ä½ ---
    exclude_list = ["CGS", "JCPL", "QC99", "PD99", "GX010", "GREAT0001X"]
    if "å„²ä½" in df_order.columns:
        before = len(df_order)
        df_order = df_order.copy()
        df_order["å„²ä½"] = df_order["å„²ä½"].astype(str).str.strip()
        pattern = "|".join(exclude_list)
        df_order = df_order[~df_order["å„²ä½"].str.contains(pattern, case=False, na=False)]
        after = len(df_order)
        msgs.append(f"å·²æ’é™¤ç‰¹æ®Šå„²ä½ï¼š{before - after:,} ç­†ï¼ˆå‰©é¤˜ {after:,} ç­†ï¼‰")
    else:
        msgs.append("è¨‚å–®æª”æ‰¾ä¸åˆ°æ¬„ä½ã€å„²ä½ã€ï¼šç•¥éæ’é™¤ç‰¹æ®Šå„²ä½")

    # --- æˆç®±ç®±è™Ÿæ¸…ç©º ---
    if "æˆç®±ç®±è™Ÿ" in df_order.columns:
        df_order = df_order.copy()
        df_order["æˆç®±ç®±è™Ÿ"] = " "
        msgs.append("å·²å°‡ã€æˆç®±ç®±è™Ÿã€å…¨æ•¸æ”¹ç‚ºç©ºç™½(ç©ºæ ¼)")

    # --- å¿…è¦æ¬„ä½æª¢æŸ¥ ---
    if "å•†å“ä»£è™Ÿ" not in df_master.columns:
        raise ValueError("å•†å“ä¸»æª”ç¼ºå°‘æ¬„ä½ã€å•†å“ä»£è™Ÿã€")
    if "å¤§é¡" not in df_master.columns:
        raise ValueError("å•†å“ä¸»æª”ç¼ºå°‘æ¬„ä½ã€å¤§é¡ã€")
    if "PA" not in df_weight.columns:
        raise ValueError("å¤§é¡åŠ æ¬Šåˆ†é ç¼ºå°‘æ¬„ä½ã€PAã€")
    if "PARM_VALUE2" not in df_weight.columns:
        raise ValueError("å¤§é¡åŠ æ¬Šåˆ†é ç¼ºå°‘æ¬„ä½ã€PARM_VALUE2ã€")

    # --- è£œç¢¼ ---
    df_order = df_order.copy()
    df_master = df_master.copy()
    df_weight = df_weight.copy()

    df_order["å•†å“"] = df_order["å•†å“"].apply(lambda x: format_code(x, 6))
    df_master["å•†å“ä»£è™Ÿ"] = df_master["å•†å“ä»£è™Ÿ"].apply(lambda x: format_code(x, 6))

    df_master["å¤§é¡"] = df_master["å¤§é¡"].apply(lambda x: format_code(x, 2))
    df_weight["PA"] = df_weight["PA"].apply(lambda x: format_code(x, 2))

    # --- äºŒæ¬¡æ¯”å° ---
    master_cols = ["å•†å“ä»£è™Ÿ", "å¤§é¡"]
    if "é¡åˆ¥" in df_master.columns:
        master_cols.append("é¡åˆ¥")
    df_master_sub = df_master[master_cols].drop_duplicates(subset=["å•†å“ä»£è™Ÿ"])

    step1_df = pd.merge(df_order, df_master_sub, left_on="å•†å“", right_on="å•†å“ä»£è™Ÿ", how="left")

    df_weight_sub = df_weight[["PA", "PARM_VALUE2"]].drop_duplicates(subset=["PA"])
    final_df = pd.merge(step1_df, df_weight_sub, left_on="å¤§é¡", right_on="PA", how="left")

    final_df = final_df.rename(columns={"PARM_VALUE2": "å¤§é¡åŠ æ¬Šå€¼"})

    # --- è¨ˆç®—åŠ æ¬Šçµæœ ---
    qty_col = "è¨ˆé‡å–®ä½æ•¸é‡"
    weight_col = "å¤§é¡åŠ æ¬Šå€¼"

    if qty_col in final_df.columns and weight_col in final_df.columns:
        final_df[qty_col] = pd.to_numeric(final_df[qty_col], errors="coerce").fillna(0)
        final_df[weight_col] = pd.to_numeric(final_df[weight_col], errors="coerce").fillna(0)
        final_df["åŠ æ¬Šè¨ˆç®—çµæœ"] = final_df[weight_col] * final_df[qty_col]
        msgs.append("å·²å®Œæˆè¨ˆç®—ï¼šåŠ æ¬Šè¨ˆç®—çµæœ = å¤§é¡åŠ æ¬Šå€¼ * è¨ˆé‡å–®ä½æ•¸é‡")
    else:
        msgs.append(f"âš ï¸ æ‰¾ä¸åˆ°æ¬„ä½ã€{qty_col}ã€æˆ–ã€{weight_col}ã€ï¼Œç„¡æ³•è¨ˆç®—åŠ æ¬Šè¨ˆç®—çµæœ")

    final_df = final_df.drop(columns=["å•†å“ä»£è™Ÿ", "PA"], errors="ignore")
    return final_df, msgs


def to_csv_bytes(df: pd.DataFrame) -> bytes:
    return df.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")


def safe_download_card(label: str, data: bytes, filename: str, mime: str = "text/csv"):
    if HAS_COMMON_UI and "download_excel_card" in globals():
        fn = download_excel_card
        try:
            sig = inspect.signature(fn)
            params = set(sig.parameters.keys())
            kwargs = {}

            for k in ("title", "label", "text"):
                if k in params:
                    kwargs[k] = label
                    break

            for k in ("data", "xlsx_bytes", "bytes_data"):
                if k in params:
                    kwargs[k] = data
                    break

            for k in ("filename", "file_name"):
                if k in params:
                    kwargs[k] = filename
                    break

            if "mime" in params:
                kwargs["mime"] = mime

            if kwargs:
                return fn(**kwargs)
        except Exception:
            pass

        for args in [(label, data, filename), (data, filename), (label, data)]:
            try:
                return fn(*args)
            except Exception:
                continue

    return st.download_button(label, data=data, file_name=filename, mime=mime, use_container_width=True)


# =============================
# UI
# =============================
def main():
    st.set_page_config(page_title="æ¯æ—¥åº«å­˜æ‡‰ä½œé‡", page_icon="ğŸ“¦", layout="wide")

    if HAS_COMMON_UI:
        inject_logistics_theme()
        set_page("ğŸ“¦ æ¯æ—¥åº«å­˜æ‡‰ä½œé‡", "è‡ªå‹•è¾¨è­˜ã€å•†å“ã€æ¬„ä½ï¼ˆå«å°¾å·´ç©ºç™½ï¼‰ï½œåŠ æ¬Šè¨ˆç®—ï½œä¸‹è¼‰ CSV")
    else:
        st.title("ğŸ“¦ æ¯æ—¥åº«å­˜æ‡‰ä½œé‡")
        st.caption("è‡ªå‹•è¾¨è­˜ã€å•†å“ã€æ¬„ä½ï¼ˆå«å°¾å·´ç©ºç™½ï¼‰ï½œåŠ æ¬Šè¨ˆç®—ï½œä¸‹è¼‰ CSV")

    if HAS_COMMON_UI:
        card_open("ğŸ“¥ 1) ä¸Šå‚³æª”æ¡ˆ")

    c1, c2 = st.columns(2)
    with c1:
        order_file = st.file_uploader("è¨‚å–®è³‡æ–™æª”ï¼ˆæŠ“ã€å•†å“ã€ï¼‰", type=["csv", "xlsx", "xls", "xlsm"], key="order")
    with c2:
        master_file = st.file_uploader("å•†å“ä¸»æª”ï¼ˆå«ï¼šå•†å“ä¸»æª” / å¤§é¡åŠ æ¬Šï¼‰", type=["xlsx", "xls", "xlsm"], key="master")

    if HAS_COMMON_UI:
        card_close()

    st.divider()

    run = st.button("âœ… é–‹å§‹è™•ç†", type="primary", disabled=not (order_file and master_file))
    if not run:
        return

    try:
        with st.spinner("è®€å–æª”æ¡ˆä¸­..."):
            df_order = robust_read_table(order_file)
            df_master, df_weight = read_master_file(master_file)

        with st.spinner("è™•ç†ä¸­ï¼ˆæ’é™¤ / è£œç¢¼ / Join / è¨ˆç®—ï¼‰..."):
            final_df, msgs = build_result(df_order, df_master, df_weight)

        # æ‘˜è¦
        total_rows = len(final_df)
        uniq_sku = final_df["å•†å“"].nunique() if "å•†å“" in final_df.columns else 0
        sum_weighted = float(final_df["åŠ æ¬Šè¨ˆç®—çµæœ"].sum()) if "åŠ æ¬Šè¨ˆç®—çµæœ" in final_df.columns else 0.0

        k1, k2, k3 = st.columns(3)
        k1.metric("ç­†æ•¸", f"{total_rows:,}")
        k2.metric("å•†å“æ•¸(ä¸é‡è¤‡)", f"{uniq_sku:,}")
        k3.metric("åŠ æ¬Šè¨ˆç®—çµæœç¸½å’Œ", f"{sum_weighted:,.2f}")

        if msgs:
            st.info(" \n".join([f"- {m}" for m in msgs]))

        st.dataframe(final_df, use_container_width=True, height=520)

        csv_bytes = to_csv_bytes(final_df)
        safe_download_card("âœ… ä¸‹è¼‰ CSVï¼ˆåŠ æ¬Šè¨ˆç®—çµæœï¼‰", csv_bytes, "è™•ç†å®Œæˆ_åŠ æ¬Šè¨ˆç®—çµæœ.csv", mime="text/csv")

        st.success("å®Œæˆ âœ…")

    except Exception as e:
        st.error(f"åŸ·è¡Œä¸­ç™¼ç”Ÿå•é¡Œï¼š{e}")


if __name__ == "__main__":
    main()
