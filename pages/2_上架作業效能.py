import io
import re
import datetime as dt
from typing import Dict, List, Tuple, Optional, Any

import pandas as pd
import streamlit as st

from common_ui import (
    inject_logistics_theme,
    set_page,
    KPI,
    render_kpis,
    bar_topN,
    card_open,
    card_close,
    download_excel_card,   # âœ… ä¸€è¡Œ=æŒ‰éˆ•ï¼ˆä¸”å¤–æ¡†ä¸åˆ†æ®µï¼‰
    sidebar_controls,
)

# =========================================================
# åƒæ•¸
# =========================================================
TO_EXCLUDE_KEYWORDS = ["CGS", "JCPL", "QC99", "GREAT0001X", "GX010", "PD99"]
TO_EXCLUDE_PATTERN = re.compile("|".join(re.escape(k) for k in TO_EXCLUDE_KEYWORDS), flags=re.IGNORECASE)

INPUT_USER_CANDIDATES = ["è¨˜éŒ„è¼¸å…¥äºº", "è¨˜éŒ„è¼¸å…¥è€…", "å»ºç«‹äºº", "è¼¸å…¥äºº"]
REV_DT_CANDIDATES = ["ä¿®è¨‚æ—¥æœŸ", "ä¿®è¨‚æ™‚é–“", "ä¿®è¨‚æ—¥", "ç•°å‹•æ™‚é–“", "ä¿®æ”¹æ™‚é–“"]

TARGET_EFF_DEFAULT = 20
IDLE_MIN_THRESHOLD_DEFAULT = 10

AM_START, AM_END = dt.time(7, 0, 0), dt.time(12, 30, 0)
PM_START, PM_END = dt.time(13, 30, 0), dt.time(23, 59, 59)

NAME_MAP = {
    "20200924001": "é»ƒé›…å›", "20210805001": "éƒ­ä¸­åˆ", "20220505002": "é˜®æ–‡é’æ˜",
    "20221221001": "é˜®æ–‡å…¨", "20221222005": "è¬å¿ é¾", "20230119001": "é™¶æ˜¥é’",
    "20240926001": "é™³è‰å¨œ", "20241011002": "æ—é›™æ…§", "20250502001": "å³è©©æ•",
    "20250617001": "é˜®æ–‡è­š", "20250617003": "å–¬å®¶å¯¶", "20250901009": "å¼µå¯¶è±",
    "G01": "0", "20201109003": "å³æŒ¯å‡±", "09963": "é»ƒè¬™å‡±",
    "20240313003": "é˜®æ›°å¿ ", "20201109001": "æ¢å† å¦‚", "10003": "æèŒ‚éŠ“",
    "20200922002": "è‘‰æ¬²å¼˜", "20250923019": "é˜®æ°ç´…æ·±", "9963": "é»ƒè¬™å‡±",
    "11399": "é™³å“²æ²…",
}

BREAK_RULES = [
    (dt.time(20, 45, 0), dt.time(22, 30, 0), 0,  "é¦–â‰¥20:45 ä¸” æœ«â‰¤22:30 â†’ 0 åˆ†é˜"),
    (dt.time(18, 30, 0), dt.time(20, 30, 0), 0,  "é¦–â‰¥18:30 ä¸” æœ«â‰¤20:30 â†’ 0 åˆ†é˜"),
    (dt.time(15, 30, 0), dt.time(18,  0, 0), 0,  "é¦–â‰¥15:30 ä¸” æœ«â‰¤18:00 â†’ 0 åˆ†é˜"),
    (dt.time(13, 30, 0), dt.time(15, 35, 0), 0,  "é¦–â‰¥13:30 ä¸” æœ«â‰¤15:35 â†’ 0 åˆ†é˜"),
    (dt.time(20, 45, 0), dt.time(23,  0, 0), 0,  "é¦–â‰¥20:45 ä¸” æœ«â‰¤23:00 â†’ 0 åˆ†é˜"),
    (dt.time(20,  0, 0), dt.time(22,  0, 0), 15, "é¦–â‰¥20:00 ä¸” æœ«â‰¤22:00 â†’ 15 åˆ†é˜"),
    (dt.time(18, 30, 0), dt.time(22,  0, 0), 15, "é¦–â‰¥18:30 ä¸” æœ«â‰¤22:00 â†’ 15 åˆ†é˜"),
    (dt.time(19,  0, 0), dt.time(22, 30, 0), 15, "é¦–â‰¥19:00 ä¸” æœ«â‰¤22:30 â†’ 15 åˆ†é˜"),
    (dt.time(13, 30, 0), dt.time(18,  0, 0), 15, "é¦–â‰¥13:30 ä¸” æœ«â‰¤18:00 â†’ 15 åˆ†é˜"),
    (dt.time(16,  0, 0), dt.time(20, 40, 0), 30, "é¦–â‰¥16:00 ä¸” æœ«â‰¤20:40 â†’ 30 åˆ†é˜"),
    (dt.time(15, 30, 0), dt.time(20, 30, 0), 30, "é¦–â‰¥15:30 ä¸” æœ«â‰¤20:30 â†’ 30 åˆ†é˜"),
    (dt.time(17,  0, 0), dt.time(22, 30, 0), 45, "é¦–â‰¥17:00 ä¸” æœ«â‰¤22:30 â†’ 45 åˆ†é˜"),
    (dt.time(15, 45, 0), dt.time(22, 30, 0), 45, "é¦–â‰¥15:45 ä¸” æœ«â‰¤22:30 â†’ 45 åˆ†é˜"),
    (dt.time(13, 30, 0), dt.time(20, 29, 0), 45, "é¦–â‰¥13:30 ä¸” æœ«â‰¤20:29 â†’ 45 åˆ†é˜"),
    (dt.time(13, 30, 0), dt.time(23,  0, 0), 60, "é¦–â‰¥13:30 ä¸” æœ«â‰¤23:00 â†’ 60 åˆ†é˜"),
    (dt.time(11,  0, 0), dt.time(17,  0, 0), 75, "é¦–â‰¥11:00 ä¸” æœ«â‰¤17:00 â†’ 75 åˆ†é˜"),
    (dt.time( 8,  0, 0), dt.time(17,  0, 0), 90, "é¦–â‰¥08:00 ä¸” æœ«â‰¤17:00 â†’ 90 åˆ†é˜"),
    (dt.time(10, 50, 0), dt.time(23,  0, 0), 120,"é¦–â‰¥10:50 ä¸” æœ«â‰¤23:00 â†’ 120 åˆ†é˜"),
    (dt.time( 8,  0, 0), dt.time(23,  0, 0), 135,"é¦–â‰¥08:00 ä¸” æœ«â‰¤23:00 â†’ 135 åˆ†é˜"),
]

# âœ… é è¨­æ’é™¤ç©ºçª—æ™‚æ®µï¼ˆå¯è¢« sidebar è¦†è“‹ï¼‰
EXCLUDE_IDLE_RANGES_DEFAULT = [
    (dt.time(10,  0, 0), dt.time(10, 15, 0)),
    (dt.time(12, 30, 0), dt.time(13, 30, 0)),
    (dt.time(15, 30, 0), dt.time(15, 45, 0)),
    (dt.time(18,  0, 0), dt.time(18, 30, 0)),
    (dt.time(20, 30, 0), dt.time(20, 45, 0)),
]

# =========================================================
# è®€æª”ï¼ˆbytesï¼‰
# =========================================================
def read_excel_any_quiet_bytes(name: str, content: bytes) -> Dict[str, pd.DataFrame]:
    ext = (name.split(".")[-1] or "").lower()
    if ext in ("xlsx", "xlsm"):
        xl = pd.ExcelFile(io.BytesIO(content), engine="openpyxl")
        return {sn: pd.read_excel(xl, sheet_name=sn) for sn in xl.sheet_names}
    if ext == "xls":
        xl = pd.ExcelFile(io.BytesIO(content), engine="xlrd")
        return {sn: pd.read_excel(xl, sheet_name=sn) for sn in xl.sheet_names}
    if ext == "csv":
        for enc in ("utf-8-sig", "cp950", "big5"):
            try:
                return {"CSV": pd.read_csv(io.BytesIO(content), encoding=enc)}
            except Exception:
                continue
        raise Exception("CSV è®€å–å¤±æ•—ï¼ˆè«‹ç¢ºèªç·¨ç¢¼ï¼‰")
    raise Exception("ä¸æ”¯æ´çš„å‰¯æª”åï¼ˆåƒ…æ”¯æ´ xlsx/xlsm/xls/csvï¼‰")


def _strip_cols(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    return df


def find_first_column(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    cols = [str(c).strip() for c in df.columns]
    s = set(cols)
    for name in candidates:
        if name in s:
            return name
    norm_map = {re.sub(r"[ï¼ˆï¼‰\(\)\s]", "", c): c for c in cols}
    for name in candidates:
        key = re.sub(r"[ï¼ˆï¼‰\(\)\s]", "", name)
        if key in norm_map:
            return norm_map[key]
    return None


def normalize_to_qc(series: pd.Series) -> pd.Series:
    return series.astype(str).str.strip().str.upper().eq("QC")


def to_not_excluded_mask(series: pd.Series) -> pd.Series:
    s = series.astype(str).str.strip()
    return ~s.str.contains(TO_EXCLUDE_PATTERN, na=False)


def prepare_filtered_df(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        return pd.DataFrame()
    df = _strip_cols(df)
    if "ç”±" not in df.columns or "åˆ°" not in df.columns:
        return pd.DataFrame()
    return df[normalize_to_qc(df["ç”±"]) & to_not_excluded_mask(df["åˆ°"])].copy()


def break_minutes_for_span(first_dt: pd.Timestamp, last_dt: pd.Timestamp) -> Tuple[int, str]:
    if pd.isna(first_dt) or pd.isna(last_dt):
        return 0, "ç„¡æ™‚é–“è³‡æ–™"
    stt, edt = first_dt.time(), last_dt.time()
    for st_ge, ed_le, mins, tag in BREAK_RULES:
        if (stt >= st_ge) and (edt <= ed_le):
            return int(mins), str(tag)
    return 0, "æœªå‘½ä¸­è¦å‰‡"


# =========================================================
# âœ… æ’é™¤å€é–“åˆ‡æ®µ + ã€Œå·¥æ™‚ã€æ‰£é™¤æ’é™¤æ™‚æ®µï¼ˆé—œéµï¼‰
# =========================================================
def _subtract_exclusions(s_dt: pd.Timestamp, e_dt: pd.Timestamp, exclude_ranges):
    if s_dt >= e_dt or not exclude_ranges:
        return [(s_dt, e_dt)]
    segments = [(s_dt, e_dt)]
    for ex_s_t, ex_e_t in exclude_ranges:
        ex_s = pd.Timestamp.combine(s_dt.date(), ex_s_t)
        ex_e = pd.Timestamp.combine(s_dt.date(), ex_e_t)
        new_segments = []
        for a, b in segments:
            if b <= ex_s or a >= ex_e:
                new_segments.append((a, b))
            else:
                if a < ex_s:
                    new_segments.append((a, ex_s))
                if b > ex_e:
                    new_segments.append((ex_e, b))
        segments = [(x, y) for (x, y) in new_segments if x < y]
    return segments


def _work_minutes_excluding_windows(
    first_dt: pd.Timestamp,
    last_dt: pd.Timestamp,
    exclude_ranges: List[Tuple[dt.time, dt.time]],
) -> int:
    """first~last æ‰£æ‰æ’é™¤æ™‚æ®µå¾Œçš„å·¥ä½œåˆ†é˜ï¼ˆâœ… è®“æ•ˆç‡/åœ–è¡¨è·Ÿè‘—æ›´æ–°ï¼‰"""
    if pd.isna(first_dt) or pd.isna(last_dt) or first_dt >= last_dt:
        return 0
    segs = _subtract_exclusions(first_dt, last_dt, exclude_ranges or [])
    mins = sum((b - a).total_seconds() for a, b in segs) / 60.0
    return max(int(round(mins)), 0)


def _compute_idle(
    series_dt: pd.Series,
    min_minutes: int,
    exclude_ranges: List[Tuple[dt.time, dt.time]],
) -> Tuple[int, str]:
    if series_dt is None or series_dt.size < 2:
        return 0, ""

    s = pd.to_datetime(series_dt, errors="coerce").dropna().sort_values()
    if s.size < 2:
        return 0, ""

    total_min, ranges_txt = 0, []
    prev = s.iloc[0]
    for cur in s.iloc[1:]:
        if cur <= prev:
            prev = cur
            continue

        # âœ… ç©ºçª—åˆ†é˜ï¼šgap è£¡é¢æ‰£æ‰ã€Œæ’é™¤ç©ºçª—æ™‚æ®µã€
        for a, b in _subtract_exclusions(prev, cur, exclude_ranges or []):
            gap_min = int(round((b - a).total_seconds() / 60.0))
            if gap_min >= int(min_minutes):
                total_min += gap_min
                ranges_txt.append(f"{a.time()} ~ {b.time()}")
        prev = cur

    return int(total_min), "ï¼›".join(ranges_txt)


def _span_metrics(series_dt: pd.Series):
    if series_dt is None or series_dt.empty:
        return pd.NaT, pd.NaT, 0
    s = pd.to_datetime(series_dt, errors="coerce").dropna()
    if s.empty:
        return pd.NaT, pd.NaT, 0
    return s.min(), s.max(), int(s.size)


def _eff(n: int, m_minutes: int) -> float:
    return round((n / m_minutes * 60.0), 2) if m_minutes and m_minutes > 0 else 0.0


def compute_am_pm_for_group(
    g: pd.DataFrame,
    idle_threshold_min: int,
    exclude_idle_ranges: List[Tuple[dt.time, dt.time]],
) -> pd.Series:
    times = pd.to_datetime(g["__dt__"], errors="coerce").dropna()

    # ä¸Šåˆï¼š07:00â€“12:30ï¼ˆâœ… å·¥æ™‚ä¹Ÿæ‰£æ’é™¤æ™‚æ®µï¼›ä¸Šåˆä¸æ‰£ä¼‘ï¼‰
    t_am = times[times.dt.time.between(AM_START, AM_END)]
    am_first, am_last, am_cnt = _span_metrics(t_am)
    am_mins = _work_minutes_excluding_windows(am_first, am_last, exclude_idle_ranges) if am_cnt > 0 else 0
    am_eff = _eff(am_cnt, am_mins)
    am_idle_min, am_idle_ranges = _compute_idle(
        t_am, min_minutes=int(idle_threshold_min), exclude_ranges=exclude_idle_ranges
    )

    # ä¸‹åˆï¼š13:30â€“23:59:59ï¼ˆâœ… å…ˆæ‰£æ’é™¤æ™‚æ®µï¼Œå†ä¾è¦å‰‡æ‰£ä¼‘ï¼‰
    t_pm = times[times.dt.time.between(PM_START, PM_END)]
    pm_first, pm_last, pm_cnt = _span_metrics(t_pm)
    if pm_cnt > 0:
        pm_break, pm_rule = break_minutes_for_span(pm_first, pm_last)
        raw_pm_mins = _work_minutes_excluding_windows(pm_first, pm_last, exclude_idle_ranges)
        pm_mins = max(int(raw_pm_mins - pm_break), 0)
    else:
        pm_break, pm_rule, pm_mins = 0, "ç„¡æ™‚é–“è³‡æ–™", 0
        pm_first, pm_last = pd.NaT, pd.NaT
    pm_eff = _eff(pm_cnt, pm_mins)
    pm_idle_min, pm_idle_ranges = _compute_idle(
        t_pm, min_minutes=int(idle_threshold_min), exclude_ranges=exclude_idle_ranges
    )

    # æ•´é«”ï¼šâœ… æ”¹æˆã€Œä¸Šåˆå·¥æ™‚ + ä¸‹åˆå·¥æ™‚ã€ï¼ˆé¿å…è·¨æ®µç©ºæª”è¢«ç®—é€²å»ï¼‰
    whole_first, whole_last, day_cnt = _span_metrics(times)
    whole_mins = int(am_mins) + int(pm_mins)
    whole_break = int(pm_break) if pm_cnt > 0 else 0
    br_tag_whole = f"æ•´é«”=ä¸Šåˆ+ä¸‹åˆï¼›ä¸‹åˆè¦å‰‡ï¼š{pm_rule}" if pm_cnt > 0 else "æ•´é«”=ä¸Šåˆ+ä¸‹åˆï¼›ç„¡ä¸‹åˆè³‡æ–™"
    whole_eff = _eff(int(day_cnt), int(whole_mins))

    return pd.Series({
        "ç¬¬ä¸€ç­†æ™‚é–“": whole_first, "æœ€å¾Œä¸€ç­†æ™‚é–“": whole_last, "ç•¶æ—¥ç­†æ•¸": int(day_cnt),
        "ä¼‘æ¯åˆ†é˜_æ•´é«”": int(whole_break), "å‘½ä¸­è¦å‰‡": br_tag_whole,
        "ç•¶æ—¥å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘": int(whole_mins), "æ•ˆç‡_ä»¶æ¯å°æ™‚": whole_eff,

        "ä¸Šåˆ_ç¬¬ä¸€ç­†": am_first, "ä¸Šåˆ_æœ€å¾Œä¸€ç­†": am_last, "ä¸Šåˆ_ç­†æ•¸": int(am_cnt),
        "ä¸Šåˆ_å·¥æ™‚_åˆ†é˜": int(am_mins), "ä¸Šåˆ_æ•ˆç‡_ä»¶æ¯å°æ™‚": am_eff,
        "ä¸Šåˆ_ç©ºçª—åˆ†é˜": int(am_idle_min), "ä¸Šåˆ_ç©ºçª—æ™‚æ®µ": am_idle_ranges,

        "ä¸‹åˆ_ç¬¬ä¸€ç­†": pm_first, "ä¸‹åˆ_æœ€å¾Œä¸€ç­†": pm_last, "ä¸‹åˆ_ç­†æ•¸": int(pm_cnt),
        "ä¸‹åˆ_ä¼‘æ¯åˆ†é˜": int(pm_break), "ä¸‹åˆ_å‘½ä¸­è¦å‰‡": pm_rule,
        "ä¸‹åˆ_å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘": int(pm_mins), "ä¸‹åˆ_æ•ˆç‡_ä»¶æ¯å°æ™‚": pm_eff,
        "ä¸‹åˆ_ç©ºçª—åˆ†é˜_æ‰£ä¼‘": int(pm_idle_min), "ä¸‹åˆ_ç©ºçª—æ™‚æ®µ": pm_idle_ranges,
    })


# =========================================================
# sidebar_controls æ’é™¤å€é–“è§£æï¼ˆé¿å… common_ui å›å‚³æ ¼å¼ä¸åŒé€ æˆå¤±æ•ˆï¼‰
# =========================================================
def _parse_time_any(x: Any) -> Optional[dt.time]:
    if x is None:
        return None
    if isinstance(x, dt.time):
        return x
    s = str(x).strip()
    if not s:
        return None
    m = re.match(r"^(\d{1,2}):(\d{2})(?::(\d{2}))?$", s)
    if not m:
        return None
    hh = int(m.group(1))
    mm = int(m.group(2))
    ss = int(m.group(3) or 0)
    if not (0 <= hh <= 23 and 0 <= mm <= 59 and 0 <= ss <= 59):
        return None
    return dt.time(hh, mm, ss)


def _parse_exclude_windows(val: Any) -> List[Tuple[dt.time, dt.time]]:
    """
    æ”¯æ´ï¼š
    - [(time,time), ...]
    - [("10:00","10:15"), ...]
    - [{"start":"10:00","end":"10:15"}, ...]
    - {"windows":[...]} ä¹‹é¡åŒ…ä¸€å±¤
    - "10:00-10:15,12:30-13:30" (å­—ä¸²)
    """
    if val is None:
        return EXCLUDE_IDLE_RANGES_DEFAULT

    if isinstance(val, dict):
        for k in ("exclude_windows", "exclude_windows_times", "windows", "ranges", "exclude_ranges"):
            if k in val:
                return _parse_exclude_windows(val.get(k))
        return EXCLUDE_IDLE_RANGES_DEFAULT

    if isinstance(val, str):
        raw = val.strip()
        if not raw:
            return EXCLUDE_IDLE_RANGES_DEFAULT
        parts = re.split(r"[ï¼Œ,;ï¼›\n]+", raw)
        items = []
        for p in parts:
            p = p.strip()
            if not p:
                continue
            m = re.match(r"^(\d{1,2}:\d{2}(?::\d{2})?)\s*[-~ï½]\s*(\d{1,2}:\d{2}(?::\d{2})?)$", p)
            if m:
                items.append((m.group(1), m.group(2)))
        return _parse_exclude_windows(items) if items else EXCLUDE_IDLE_RANGES_DEFAULT

    if not isinstance(val, (list, tuple)):
        return EXCLUDE_IDLE_RANGES_DEFAULT

    out: List[Tuple[dt.time, dt.time]] = []
    for item in val:
        if isinstance(item, dict):
            s = _parse_time_any(item.get("start") or item.get("s") or item.get("from"))
            e = _parse_time_any(item.get("end") or item.get("e") or item.get("to"))
        elif isinstance(item, (list, tuple)) and len(item) >= 2:
            s = _parse_time_any(item[0])
            e = _parse_time_any(item[1])
        else:
            s, e = None, None

        if s and e and (dt.datetime.combine(dt.date.today(), s) < dt.datetime.combine(dt.date.today(), e)):
            out.append((s, e))

    return out if out else EXCLUDE_IDLE_RANGES_DEFAULT


def _extract_exclude_value_from_controls(controls: Dict[str, Any]) -> Any:
    if not isinstance(controls, dict) or not controls:
        return None
    for k in (
        "exclude_windows",
        "exclude_windows_times",
        "exclude_ranges",
        "exclude_idle_ranges",
        "idle_exclude_windows",
        "idle_exclude_ranges",
    ):
        if k in controls and controls.get(k):
            return controls.get(k)
    for k, v in controls.items():
        lk = str(k).lower()
        if ("exclude" in lk) and (("window" in lk) or ("range" in lk)) and v:
            return v
    return None


# =========================================================
# Excel åŒ¯å‡ºï¼ˆbytesï¼‰
# =========================================================
def autosize_columns(ws, df: pd.DataFrame):
    from openpyxl.utils import get_column_letter
    cols = list(df.columns) if df is not None else []
    for i, col in enumerate(cols, start=1):
        if df is not None and not df.empty:
            sample = [len(str(x)) for x in df[col].head(800).tolist()]
            max_len = max([len(str(col))] + sample)
        else:
            max_len = max(len(str(col)), 8)
        ws.column_dimensions[get_column_letter(i)].width = min(max_len + 2, 60)


def shade_rows_by_efficiency(ws, header_name="æ•ˆç‡_ä»¶æ¯å°æ™‚", green="C6EFCE", red="FFC7CE", target_eff=20):
    from openpyxl.styles import PatternFill
    eff_col = None
    for c in range(1, ws.max_column + 1):
        if str(ws.cell(row=1, column=c).value).strip() == header_name:
            eff_col = c
            break
    if eff_col is None:
        return
    green_fill = PatternFill(start_color=green, end_color=green, fill_type="solid")
    red_fill = PatternFill(start_color=red, end_color=red, fill_type="solid")
    for r in range(2, ws.max_row + 1):
        v = ws.cell(row=r, column=eff_col).value
        try:
            val = float(v) if v is not None and str(v).strip() != "" else None
        except Exception:
            val = None
        if val is None:
            continue
        fill = green_fill if val >= float(target_eff) else red_fill
        for c in range(1, ws.max_column + 1):
            ws.cell(row=r, column=c).fill = fill


def write_block_report(writer, detail_long: pd.DataFrame, user_col: str, target_eff: float):
    from openpyxl.styles import Font, Alignment, PatternFill, Border, Side
    from openpyxl.utils import get_column_letter

    sheet_name = "å ±è¡¨_å€å¡Š"
    wb = writer.book
    if sheet_name in wb.sheetnames:
        del wb[sheet_name]
    ws = wb.create_sheet(sheet_name)

    header = ["ä»£ç¢¼", "å§“å", "ç­†æ•¸", "å·¥ä½œå€é–“", "ç¸½åˆ†é˜", "æ•ˆç‡(ä»¶/æ™‚)", "ä¼‘æ¯åˆ†é˜", "ç©ºçª—åˆ†é˜", "ç©ºçª—æ™‚æ®µ"]
    title_font = Font(bold=True, size=14)
    sec_font = Font(bold=True, size=12)
    header_fill = PatternFill(start_color="D9D9D9", end_color="D9D9D9", fill_type="solid")
    border = Border(left=Side(style="thin"), right=Side(style="thin"), top=Side(style="thin"), bottom=Side(style="thin"))
    center = Alignment(horizontal="center", vertical="center")
    left = Alignment(horizontal="left", vertical="center")

    df = detail_long.copy()
    df["å·¥ä½œå€é–“"] = df.apply(
        lambda r: (
            ("" if pd.isna(r["ç¬¬ä¸€ç­†æ™‚é–“"]) else str(r["ç¬¬ä¸€ç­†æ™‚é–“"].time()))
            + " ~ "
            + ("" if pd.isna(r["æœ€å¾Œä¸€ç­†æ™‚é–“"]) else str(r["æœ€å¾Œä¸€ç­†æ™‚é–“"].time()))
        ),
        axis=1,
    )
    df["ç¸½åˆ†é˜"] = df["å·¥æ™‚_åˆ†é˜"].astype(int)

    for dt_date, g in df.groupby("æ—¥æœŸ"):
        row = ws.max_row + 1
        ws.merge_cells(start_row=row, start_column=1, end_row=row, end_column=len(header))
        cell = ws.cell(row=row, column=1, value=f"{dt_date} ä¸Šæ¶ç¸¾æ•ˆ")
        cell.font = title_font
        cell.alignment = center

        for seg in ["ä¸Šåˆ", "ä¸‹åˆ"]:
            seg_df = g[g["æ™‚æ®µ"] == seg]
            if seg_df.empty:
                continue

            row = ws.max_row + 1
            ws.merge_cells(start_row=row, start_column=1, end_row=row, end_column=len(header))
            cell = ws.cell(row=row, column=1, value=seg)
            cell.font = sec_font
            cell.alignment = left

            row = ws.max_row + 1
            for c, h in enumerate(header, start=1):
                hc = ws.cell(row=row, column=c, value=h)
                hc.fill = header_fill
                hc.alignment = center
                hc.border = border
                hc.font = Font(bold=True)

            seg_df = seg_df.sort_values(["æ•ˆç‡_ä»¶æ¯å°æ™‚", "ç­†æ•¸"], ascending=[False, False])
            for _, r in seg_df.iterrows():
                row = ws.max_row + 1
                values = [
                    r[user_col],
                    r["å°æ‡‰å§“å"],
                    int(r["ç­†æ•¸"]),
                    r["å·¥ä½œå€é–“"],
                    int(r["ç¸½åˆ†é˜"]),
                    float(r["æ•ˆç‡_ä»¶æ¯å°æ™‚"]),
                    int(r["ä¼‘æ¯åˆ†é˜"]),
                    int(r["ç©ºçª—åˆ†é˜"]),
                    r["ç©ºçª—æ™‚æ®µ"],
                ]
                for c, v in enumerate(values, start=1):
                    cell = ws.cell(row=row, column=c, value=v)
                    cell.alignment = center if c not in (4, 9) else left
                    cell.border = border

                eff = float(r["æ•ˆç‡_ä»¶æ¯å°æ™‚"]) if pd.notna(r["æ•ˆç‡_ä»¶æ¯å°æ™‚"]) else 0.0
                color = "C6EFCE" if eff >= float(target_eff) else "FFC7CE"
                fill = PatternFill(start_color=color, end_color=color, fill_type="solid")
                for c in range(1, len(header) + 1):
                    ws.cell(row=row, column=c).fill = fill

    for c in range(1, len(header) + 1):
        max_len = 0
        for r in range(1, ws.max_row + 1):
            v = ws.cell(row=r, column=c).value
            max_len = max(max_len, len(str(v)) if v is not None else 0)
        ws.column_dimensions[get_column_letter(c)].width = min(max(max_len + 2, len(str(header[c - 1])) + 2), 60)


def build_excel_bytes(
    user_col: str,
    summary_out: pd.DataFrame,
    daily: pd.DataFrame,
    detail_long: pd.DataFrame,
    target_eff: float,
) -> bytes:
    out = io.BytesIO()
    with pd.ExcelWriter(out, engine="openpyxl", datetime_format="yyyy-mm-dd hh:mm:ss", date_format="yyyy-mm-dd") as writer:
        sum_cols = [
            user_col, "å°æ‡‰å§“å", "ç·æ—¥æ•¸",
            "ç¸½ç­†æ•¸", "ç¸½å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘", "æ•ˆç‡_ä»¶æ¯å°æ™‚",
            "ä¸Šåˆç­†æ•¸", "ä¸Šåˆå·¥æ™‚_åˆ†é˜", "ä¸Šåˆæ•ˆç‡_ä»¶æ¯å°æ™‚",
            "ä¸‹åˆç­†æ•¸", "ä¸‹åˆå·¥æ™‚_åˆ†é˜_æ‰£ä¼‘", "ä¸‹åˆæ•ˆç‡_ä»¶æ¯å°æ™‚",
        ]
        summary_out[sum_cols].to_excel(writer, index=False, sheet_name="å½™ç¸½")
        ws_sum = writer.sheets["å½™ç¸½"]
        autosize_columns(ws_sum, summary_out[sum_cols])
        shade_rows_by_efficiency(ws_sum, "æ•ˆç‡_ä»¶æ¯å°æ™‚", target_eff=target_eff)

        det_cols = [
            user_col, "å°æ‡‰å§“å", "æ—¥æœŸ",
            "ç¬¬ä¸€ç­†æ™‚é–“", "æœ€å¾Œä¸€ç­†æ™‚é–“", "ç•¶æ—¥ç­†æ•¸",
            "ä¼‘æ¯åˆ†é˜_æ•´é«”", "ç•¶æ—¥å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘", "æ•ˆç‡_ä»¶æ¯å°æ™‚",
            "ä¸Šåˆ_ç¬¬ä¸€ç­†", "ä¸Šåˆ_æœ€å¾Œä¸€ç­†", "ä¸Šåˆ_ç­†æ•¸", "ä¸Šåˆ_å·¥æ™‚_åˆ†é˜", "ä¸Šåˆ_æ•ˆç‡_ä»¶æ¯å°æ™‚",
            "ä¸Šåˆ_ç©ºçª—åˆ†é˜", "ä¸Šåˆ_ç©ºçª—æ™‚æ®µ",
            "ä¸‹åˆ_ç¬¬ä¸€ç­†", "ä¸‹åˆ_æœ€å¾Œä¸€ç­†", "ä¸‹åˆ_ç­†æ•¸", "ä¸‹åˆ_ä¼‘æ¯åˆ†é˜",
            "ä¸‹åˆ_å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘", "ä¸‹åˆ_æ•ˆç‡_ä»¶æ¯å°æ™‚",
            "ä¸‹åˆ_ç©ºçª—åˆ†é˜_æ‰£ä¼‘", "ä¸‹åˆ_ç©ºçª—æ™‚æ®µ",
        ]
        daily.sort_values([user_col, "æ—¥æœŸ", "ç¬¬ä¸€ç­†æ™‚é–“"])[det_cols].to_excel(writer, index=False, sheet_name="æ˜ç´°")
        ws_det = writer.sheets["æ˜ç´°"]
        autosize_columns(ws_det, daily[det_cols])
        shade_rows_by_efficiency(ws_det, "æ•ˆç‡_ä»¶æ¯å°æ™‚", target_eff=target_eff)

        if detail_long is not None and not detail_long.empty:
            long_cols = [
                user_col, "å°æ‡‰å§“å", "æ—¥æœŸ", "æ™‚æ®µ",
                "ç¬¬ä¸€ç­†æ™‚é–“", "æœ€å¾Œä¸€ç­†æ™‚é–“",
                "ç­†æ•¸", "å·¥æ™‚_åˆ†é˜", "ä¼‘æ¯åˆ†é˜",
                "ç©ºçª—åˆ†é˜", "ç©ºçª—æ™‚æ®µ",
                "æ•ˆç‡_ä»¶æ¯å°æ™‚", "å‘½ä¸­è¦å‰‡",
            ]
            detail_long[long_cols].to_excel(writer, index=False, sheet_name="æ˜ç´°_æ™‚æ®µ")
            ws_long = writer.sheets["æ˜ç´°_æ™‚æ®µ"]
            autosize_columns(ws_long, detail_long[long_cols])
            shade_rows_by_efficiency(ws_long, "æ•ˆç‡_ä»¶æ¯å°æ™‚", target_eff=target_eff)

        if detail_long is not None and not detail_long.empty:
            write_block_report(writer, detail_long, user_col, target_eff=target_eff)

        rules_rows = []
        for i, (st_ge, ed_le, mins, tag) in enumerate(BREAK_RULES, start=1):
            rules_rows.append({
                "å„ªå…ˆåº": i,
                "é¦–æ™‚é–“æ¢ä»¶(>=)": st_ge.strftime("%H:%M:%S"),
                "æœ«æ™‚é–“æ¢ä»¶(<=)": ed_le.strftime("%H:%M:%S"),
                "ä¼‘æ¯åˆ†é˜": int(mins),
                "è¦å‰‡èªªæ˜": str(tag),
            })
        rules_df = pd.DataFrame(
            rules_rows,
            columns=["å„ªå…ˆåº", "é¦–æ™‚é–“æ¢ä»¶(>=)", "æœ«æ™‚é–“æ¢ä»¶(<=)", "ä¼‘æ¯åˆ†é˜", "è¦å‰‡èªªæ˜"],
        )
        rules_df.to_excel(writer, index=False, sheet_name="ä¼‘æ¯è¦å‰‡")
        autosize_columns(writer.sheets["ä¼‘æ¯è¦å‰‡"], rules_df)

    return out.getvalue()


# =========================================================
# Streamlit Page
# =========================================================
def main():
    inject_logistics_theme()
    set_page("ä¸Šæ¶ç”¢èƒ½åˆ†æï¼ˆPutaway KPIï¼‰", icon="ğŸ“¦", subtitle="ç¸½ä¸Šçµ„ï¼ˆä¸Šæ¶ï¼‰ï½œä¸Šåˆ/ä¸‹åˆåˆ†æ®µï½œæ•ˆç‡é–€æª»è‘—è‰²ï½œå ±è¡¨_å€å¡Šè¼¸å‡º")

    if "putaway_last" not in st.session_state:
        st.session_state.putaway_last = None

    controls = sidebar_controls(default_top_n=30, enable_exclude_windows=True, state_key_prefix="putaway")
    top_n = int(controls.get("top_n", 30))

    exclude_raw = _extract_exclude_value_from_controls(controls)
    exclude_idle_ranges = _parse_exclude_windows(exclude_raw)

    with st.sidebar:
        st.markdown("---")
        target_eff = st.number_input("é”æ¨™é–€æª»ï¼ˆæ•ˆç‡ â‰¥ï¼‰", min_value=1, max_value=999, value=int(TARGET_EFF_DEFAULT), step=1)
        idle_threshold = st.number_input("ç©ºçª—é–€æª»ï¼ˆåˆ†é˜ â‰¥ æ‰ç®—ï¼‰", min_value=1, max_value=240, value=int(IDLE_MIN_THRESHOLD_DEFAULT), step=1)

        preview = "ã€".join([f"{a.strftime('%H:%M')}~{b.strftime('%H:%M')}" for a, b in exclude_idle_ranges]) if exclude_idle_ranges else "ï¼ˆç„¡ï¼‰"
        st.caption(f"âœ… å·²è®€å–æ’é™¤ç©ºçª—æ™‚æ®µï¼š{preview}")
        st.caption("âš ï¸ è‹¥ä½ æ”¹äº†æ’é™¤æ™‚æ®µ/é–€æª»ï¼Œéœ€å†æŒ‰ä¸€æ¬¡ã€ŒğŸš€ ç”¢å‡º KPIã€æ‰æœƒé‡æ–°è¨ˆç®—ã€‚")
        st.caption("æç¤ºï¼šä¸Šå‚³ .xls éœ€ requirements å®‰è£ xlrd==2.0.1")

    card_open("ğŸ“¤ ä¸Šå‚³ä½œæ¥­åŸå§‹è³‡æ–™ï¼ˆä¸Šæ¶ï¼‰")
    uploaded = st.file_uploader(
        "ä¸Šå‚³ Excel / CSVï¼ˆéœ€åŒ…å«ï¼šç”±ã€åˆ°ã€ä¿®è¨‚æ—¥æœŸ/æ™‚é–“ã€è¨˜éŒ„è¼¸å…¥äººï¼‰",
        type=["xlsx", "xlsm", "xls", "csv"],
        label_visibility="collapsed",
    )
    run_clicked = st.button("ğŸš€ ç”¢å‡º KPI", type="primary", disabled=uploaded is None)
    card_close()

    last = st.session_state.putaway_last
    current_params = {
        "target_eff": int(target_eff),
        "idle_threshold": int(idle_threshold),
        "exclude_idle_ranges": [(a.strftime("%H:%M:%S"), b.strftime("%H:%M:%S")) for a, b in exclude_idle_ranges],
        "top_n": int(top_n),
    }
    if last and last.get("params") and last.get("params") != current_params:
        st.warning("âš ï¸ ä½ å·²è®Šæ›´å´é‚Šæ¬„æ¢ä»¶ï¼ˆå«æ’é™¤ç©ºçª—æ™‚æ®µ/é–€æª»ï¼‰ï¼Œè«‹å†æŒ‰ä¸€æ¬¡ã€ŒğŸš€ ç”¢å‡º KPIã€æ‰æœƒå¥—ç”¨æ–°æ¢ä»¶ã€‚")

    if run_clicked:
        with st.spinner("è¨ˆç®—ä¸­ï¼Œè«‹ç¨å€™..."):
            sheets = read_excel_any_quiet_bytes(uploaded.name, uploaded.getvalue())

            kept_all = []
            for sn, df in sheets.items():
                k = prepare_filtered_df(df)
                if not k.empty:
                    k["__sheet__"] = sn
                    kept_all.append(k)

            if not kept_all:
                st.error("ç„¡ç¬¦åˆè³‡æ–™ï¼ˆå¯èƒ½ç¼ºã€ç”±/åˆ°ã€æ¬„æˆ–éæ¿¾å¾Œç‚ºç©ºï¼‰ã€‚")
                st.session_state.putaway_last = None
                return

            data = pd.concat(kept_all, ignore_index=True)

            user_col = find_first_column(data, INPUT_USER_CANDIDATES)
            revdt_col = find_first_column(data, REV_DT_CANDIDATES)
            if user_col is None:
                st.error("æ‰¾ä¸åˆ°ã€è¨˜éŒ„è¼¸å…¥äººã€æ¬„ä½ï¼ˆå€™é¸ï¼šè¨˜éŒ„è¼¸å…¥äºº/è¨˜éŒ„è¼¸å…¥è€…/å»ºç«‹äºº/è¼¸å…¥äººï¼‰ã€‚")
                st.session_state.putaway_last = None
                return
            if revdt_col is None:
                st.error("æ‰¾ä¸åˆ°ã€ä¿®è¨‚æ—¥æœŸ/æ™‚é–“ã€æ¬„ä½ï¼ˆå€™é¸ï¼šä¿®è¨‚æ—¥æœŸ/ä¿®è¨‚æ™‚é–“/ä¿®è¨‚æ—¥/ç•°å‹•æ™‚é–“/ä¿®æ”¹æ™‚é–“ï¼‰ã€‚")
                st.session_state.putaway_last = None
                return

            data["__dt__"] = pd.to_datetime(data[revdt_col], errors="coerce")
            data["__code__"] = data[user_col].astype(str).str.strip()
            data["å°æ‡‰å§“å"] = data["__code__"].map(NAME_MAP).fillna("")

            dt_data = data.dropna(subset=["__dt__"]).copy()
            if dt_data.empty:
                st.error("è³‡æ–™æ²’æœ‰å¯ç”¨çš„ä¿®è¨‚æ—¥æœŸæ™‚é–“ï¼Œç„¡æ³•è¨ˆç®—ã€‚")
                st.session_state.putaway_last = None
                return

            dt_data["æ—¥æœŸ"] = dt_data["__dt__"].dt.date

            daily = (
                dt_data.groupby([user_col, "å°æ‡‰å§“å", "æ—¥æœŸ"], dropna=False)
                .apply(lambda g: compute_am_pm_for_group(
                    g,
                    idle_threshold_min=int(idle_threshold),
                    exclude_idle_ranges=exclude_idle_ranges,
                ))
                .reset_index()
            )

            summary = (
                daily.groupby([user_col, "å°æ‡‰å§“å"], dropna=False, as_index=False)
                .agg(
                    ç·æ—¥æ•¸=("æ—¥æœŸ", "nunique"),
                    ç¸½ç­†æ•¸=("ç•¶æ—¥ç­†æ•¸", "sum"),
                    ä¸Šåˆç­†æ•¸=("ä¸Šåˆ_ç­†æ•¸", "sum"),
                    ä¸Šåˆå·¥æ™‚_åˆ†é˜=("ä¸Šåˆ_å·¥æ™‚_åˆ†é˜", "sum"),
                    ä¸‹åˆç­†æ•¸=("ä¸‹åˆ_ç­†æ•¸", "sum"),
                    ä¸‹åˆå·¥æ™‚_åˆ†é˜_æ‰£ä¼‘=("ä¸‹åˆ_å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘", "sum"),
                )
            )

            summary["ä¸Šåˆæ•ˆç‡_ä»¶æ¯å°æ™‚"] = summary.apply(lambda r: _eff(int(r["ä¸Šåˆç­†æ•¸"]), int(r["ä¸Šåˆå·¥æ™‚_åˆ†é˜"])), axis=1)
            summary["ä¸‹åˆæ•ˆç‡_ä»¶æ¯å°æ™‚"] = summary.apply(lambda r: _eff(int(r["ä¸‹åˆç­†æ•¸"]), int(r["ä¸‹åˆå·¥æ™‚_åˆ†é˜_æ‰£ä¼‘"])), axis=1)

            # âœ… ç¸½å·¥æ™‚æ¡ã€Œä¸Šåˆ+ä¸‹åˆã€ï¼šè·Ÿæ•´é«”ï¼ˆdayï¼‰ä¸€è‡´ï¼Œé¿å…è·¨æ®µç©ºæª”å½±éŸ¿
            summary["ç¸½å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘"] = summary["ä¸Šåˆå·¥æ™‚_åˆ†é˜"].fillna(0).astype(int) + summary["ä¸‹åˆå·¥æ™‚_åˆ†é˜_æ‰£ä¼‘"].fillna(0).astype(int)
            summary["æ•ˆç‡_ä»¶æ¯å°æ™‚"] = summary.apply(lambda r: _eff(int(r["ç¸½ç­†æ•¸"]), int(r["ç¸½å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘"])), axis=1)

            for c in ["ç¸½ç­†æ•¸", "ç¸½å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘", "ä¸Šåˆç­†æ•¸", "ä¸Šåˆå·¥æ™‚_åˆ†é˜", "ä¸‹åˆç­†æ•¸", "ä¸‹åˆå·¥æ™‚_åˆ†é˜_æ‰£ä¼‘"]:
                summary[c] = summary[c].fillna(0).astype(int)

            total_people = int(summary[user_col].nunique())
            met_people = int((summary["æ•ˆç‡_ä»¶æ¯å°æ™‚"] >= float(target_eff)).sum())
            rate = (met_people / total_people) if total_people > 0 else 0.0

            total_row = {
                user_col: "æ•´é«”åˆè¨ˆ",
                "å°æ‡‰å§“å": "",
                "ç·æ—¥æ•¸": int(summary["ç·æ—¥æ•¸"].sum()),
                "ç¸½ç­†æ•¸": int(summary["ç¸½ç­†æ•¸"].sum()),
                "ç¸½å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘": int(summary["ç¸½å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘"].sum()),
                "ä¸Šåˆç­†æ•¸": int(summary["ä¸Šåˆç­†æ•¸"].sum()),
                "ä¸Šåˆå·¥æ™‚_åˆ†é˜": int(summary["ä¸Šåˆå·¥æ™‚_åˆ†é˜"].sum()),
                "ä¸‹åˆç­†æ•¸": int(summary["ä¸‹åˆç­†æ•¸"].sum()),
                "ä¸‹åˆå·¥æ™‚_åˆ†é˜_æ‰£ä¼‘": int(summary["ä¸‹åˆå·¥æ™‚_åˆ†é˜_æ‰£ä¼‘"].sum()),
                "æ•ˆç‡_ä»¶æ¯å°æ™‚": _eff(int(summary["ç¸½ç­†æ•¸"].sum()), int(summary["ç¸½å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘"].sum())),
                "ä¸Šåˆæ•ˆç‡_ä»¶æ¯å°æ™‚": _eff(int(summary["ä¸Šåˆç­†æ•¸"].sum()), int(summary["ä¸Šåˆå·¥æ™‚_åˆ†é˜"].sum())),
                "ä¸‹åˆæ•ˆç‡_ä»¶æ¯å°æ™‚": _eff(int(summary["ä¸‹åˆç­†æ•¸"].sum()), int(summary["ä¸‹åˆå·¥æ™‚_åˆ†é˜_æ‰£ä¼‘"].sum())),
            }
            summary_out = pd.concat([summary, pd.DataFrame([total_row])], ignore_index=True)

            long_rows = []
            for _, r in daily.iterrows():
                if int(r["ä¸Šåˆ_ç­†æ•¸"]) > 0:
                    long_rows.append({
                        user_col: r[user_col], "å°æ‡‰å§“å": r["å°æ‡‰å§“å"], "æ—¥æœŸ": r["æ—¥æœŸ"], "æ™‚æ®µ": "ä¸Šåˆ",
                        "ç¬¬ä¸€ç­†æ™‚é–“": r["ä¸Šåˆ_ç¬¬ä¸€ç­†"], "æœ€å¾Œä¸€ç­†æ™‚é–“": r["ä¸Šåˆ_æœ€å¾Œä¸€ç­†"],
                        "ç­†æ•¸": int(r["ä¸Šåˆ_ç­†æ•¸"]), "å·¥æ™‚_åˆ†é˜": int(r["ä¸Šåˆ_å·¥æ™‚_åˆ†é˜"]),
                        "ä¼‘æ¯åˆ†é˜": 0,
                        "ç©ºçª—åˆ†é˜": int(r["ä¸Šåˆ_ç©ºçª—åˆ†é˜"]), "ç©ºçª—æ™‚æ®µ": r["ä¸Šåˆ_ç©ºçª—æ™‚æ®µ"],
                        "æ•ˆç‡_ä»¶æ¯å°æ™‚": float(r["ä¸Šåˆ_æ•ˆç‡_ä»¶æ¯å°æ™‚"]),
                        "å‘½ä¸­è¦å‰‡": "ä¸Šåˆä¸æ‰£ä¼‘",
                    })
                if int(r["ä¸‹åˆ_ç­†æ•¸"]) > 0:
                    long_rows.append({
                        user_col: r[user_col], "å°æ‡‰å§“å": r["å°æ‡‰å§“å"], "æ—¥æœŸ": r["æ—¥æœŸ"], "æ™‚æ®µ": "ä¸‹åˆ",
                        "ç¬¬ä¸€ç­†æ™‚é–“": r["ä¸‹åˆ_ç¬¬ä¸€ç­†"], "æœ€å¾Œä¸€ç­†æ™‚é–“": r["ä¸‹åˆ_æœ€å¾Œä¸€ç­†"],
                        "ç­†æ•¸": int(r["ä¸‹åˆ_ç­†æ•¸"]), "å·¥æ™‚_åˆ†é˜": int(r["ä¸‹åˆ_å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘"]),
                        "ä¼‘æ¯åˆ†é˜": int(r["ä¸‹åˆ_ä¼‘æ¯åˆ†é˜"]),
                        "ç©ºçª—åˆ†é˜": int(r["ä¸‹åˆ_ç©ºçª—åˆ†é˜_æ‰£ä¼‘"]), "ç©ºçª—æ™‚æ®µ": r["ä¸‹åˆ_ç©ºçª—æ™‚æ®µ"],
                        "æ•ˆç‡_ä»¶æ¯å°æ™‚": float(r["ä¸‹åˆ_æ•ˆç‡_ä»¶æ¯å°æ™‚"]),
                        "å‘½ä¸­è¦å‰‡": str(r["ä¸‹åˆ_å‘½ä¸­è¦å‰‡"]),
                    })
            detail_long = pd.DataFrame(long_rows)
            if not detail_long.empty:
                detail_long = detail_long.sort_values([user_col, "æ—¥æœŸ", "æ™‚æ®µ", "ç¬¬ä¸€ç­†æ™‚é–“"])

            xlsx_bytes = build_excel_bytes(user_col, summary_out, daily, detail_long, target_eff=float(target_eff))
            xlsx_name = f"{uploaded.name.rsplit('.', 1)[0]}_ä¸Šæ¶ç¸¾æ•ˆ.xlsx"

            st.session_state.putaway_last = {
                "params": current_params,
                "user_col": user_col,
                "summary": summary,
                "summary_out": summary_out,
                "daily": daily,
                "detail_long": detail_long,
                "target_eff": float(target_eff),
                "top_n": int(top_n),
                "total_people": int(total_people),
                "met_people": int(met_people),
                "rate": float(rate),
                "xlsx_bytes": xlsx_bytes,
                "xlsx_name": xlsx_name,
            }

    last = st.session_state.putaway_last
    if not last:
        st.info("è«‹å…ˆä¸Šå‚³ä¸Šæ¶ä½œæ¥­åŸå§‹è³‡æ–™ä¸¦é»é¸ã€ŒğŸš€ ç”¢å‡º KPIã€")
        return

    user_col = last["user_col"]
    summary = last["summary"]
    target_eff_show = float(last["target_eff"])
    top_n_show = int(last.get("top_n", 30))
    total_people = int(last["total_people"])
    met_people = int(last["met_people"])
    rate = float(last["rate"])
    xlsx_bytes = last["xlsx_bytes"]
    xlsx_name = last["xlsx_name"]

    card_open("ğŸ“Œ ç¸½è¦½ KPI")
    render_kpis([
        KPI("ç¸½äººæ•¸", f"{total_people:,}"),
        KPI("é”æ¨™äººæ•¸", f"{met_people:,}"),
        KPI("é”æ¨™ç‡", f"{rate:.1%}"),
        KPI("é”æ¨™é–€æª»", f"æ•ˆç‡ â‰¥ {int(target_eff_show)}"),
    ])
    card_close()

    col_l, col_r = st.columns(2)

    with col_l:
        card_open(f"ğŸŒ“ AMï¼ˆä¸Šåˆï¼‰æ•ˆç‡æ’è¡Œï¼ˆTop {top_n_show}ï¼‰")
        am_rank = summary[[user_col, "å°æ‡‰å§“å", "ä¸Šåˆç­†æ•¸", "ä¸Šåˆå·¥æ™‚_åˆ†é˜", "ä¸Šåˆæ•ˆç‡_ä»¶æ¯å°æ™‚"]].copy()
        am_rank = am_rank.rename(columns={"ä¸Šåˆæ•ˆç‡_ä»¶æ¯å°æ™‚": "æ•ˆç‡", "ä¸Šåˆç­†æ•¸": "ç­†æ•¸", "ä¸Šåˆå·¥æ™‚_åˆ†é˜": "å·¥æ™‚"})
        am_rank["å§“å"] = am_rank["å°æ‡‰å§“å"].where(am_rank["å°æ‡‰å§“å"].astype(str).str.len() > 0, am_rank[user_col].astype(str))
        bar_topN(
            am_rank[["å§“å", "æ•ˆç‡", "ç­†æ•¸", "å·¥æ™‚"]],
            x_col="å§“å",
            y_col="æ•ˆç‡",
            hover_cols=["ç­†æ•¸", "å·¥æ™‚"],
            top_n=top_n_show,
            target=float(target_eff_show),
        )
        card_close()

    with col_r:
        card_open(f"ğŸŒ™ PMï¼ˆä¸‹åˆï¼‰æ•ˆç‡æ’è¡Œï¼ˆTop {top_n_show}ï¼‰")
        pm_rank = summary[[user_col, "å°æ‡‰å§“å", "ä¸‹åˆç­†æ•¸", "ä¸‹åˆå·¥æ™‚_åˆ†é˜_æ‰£ä¼‘", "ä¸‹åˆæ•ˆç‡_ä»¶æ¯å°æ™‚"]].copy()
        pm_rank = pm_rank.rename(columns={"ä¸‹åˆæ•ˆç‡_ä»¶æ¯å°æ™‚": "æ•ˆç‡", "ä¸‹åˆç­†æ•¸": "ç­†æ•¸", "ä¸‹åˆå·¥æ™‚_åˆ†é˜_æ‰£ä¼‘": "å·¥æ™‚"})
        pm_rank["å§“å"] = pm_rank["å°æ‡‰å§“å"].where(pm_rank["å°æ‡‰å§“å"].astype(str).str.len() > 0, pm_rank[user_col].astype(str))
        bar_topN(
            pm_rank[["å§“å", "æ•ˆç‡", "ç­†æ•¸", "å·¥æ™‚"]],
            x_col="å§“å",
            y_col="æ•ˆç‡",
            hover_cols=["ç­†æ•¸", "å·¥æ™‚"],
            top_n=top_n_show,
            target=float(target_eff_show),
        )
        card_close()

    download_excel_card(
        xlsx_bytes,
        xlsx_name,
        label="â¬‡ï¸ åŒ¯å‡º KPI å ±è¡¨ï¼ˆExcelï¼‰",
    )


if __name__ == "__main__":
    main()
