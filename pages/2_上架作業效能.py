import io
import re
import datetime as dt
from typing import Dict, List, Tuple, Optional, Any

import pandas as pd
import streamlit as st

from common_ui import (
    inject_logistics_theme,
    set_page,
    KPI,
    render_kpis,
    bar_topN,
    card_open,
    card_close,
    download_excel_card,
    sidebar_controls,
)

# =========================================================
# åƒæ•¸
# =========================================================
TO_EXCLUDE_KEYWORDS = ["CGS", "JCPL", "QC99", "GREAT0001X", "GX010", "PD99"]
TO_EXCLUDE_PATTERN = re.compile("|".join(re.escape(k) for k in TO_EXCLUDE_KEYWORDS), flags=re.IGNORECASE)

INPUT_USER_CANDIDATES = ["è¨˜éŒ„è¼¸å…¥äºº", "è¨˜éŒ„è¼¸å…¥è€…", "å»ºç«‹äºº", "è¼¸å…¥äºº"]
REV_DT_CANDIDATES = ["ä¿®è¨‚æ—¥æœŸ", "ä¿®è¨‚æ™‚é–“", "ä¿®è¨‚æ—¥", "ç•°å‹•æ™‚é–“", "ä¿®æ”¹æ™‚é–“"]

TARGET_EFF_DEFAULT = 20
IDLE_MIN_THRESHOLD_DEFAULT = 10

AM_START, AM_END = dt.time(7, 0, 0), dt.time(12, 30, 0)
PM_START, PM_END = dt.time(13, 30, 0), dt.time(23, 59, 59)

# âœ… å„²ä½é¡å‹ï¼ˆå€ç¢¼3 â†’ é¡å‹ï¼‰
STORAGE_TYPE_ZONES = {
    "è¼•å‹æ–™æ¶": ["001", "002", "003", "017", "016"],
    "è½åœ°å„²": ["014", "018", "019", "020", "010", "081", "401", "402", "403", "015"],
    "é‡å‹ä½ç©º": ["011", "012", "013", "031", "032", "033", "034", "035", "036", "037", "038"],
    "é«˜ç©ºå„²": [
        "021", "022", "023",
        "041", "042", "043",
        "051", "052", "053", "054", "055", "056", "057",
        "301", "302", "303", "304", "305", "306",
    ],
}
ZONE3_TO_STORAGE_TYPE = {z: t for t, zones in STORAGE_TYPE_ZONES.items() for z in zones}

# âœ… æ—¢æœ‰ä»£ç¢¼â†’å§“åï¼ˆä»ä¿ç•™ï¼‰
NAME_MAP = {
    "20200924001": "é»ƒé›…å›", "20210805001": "éƒ­ä¸­åˆ", "20220505002": "é˜®æ–‡é’æ˜",
    "20221221001": "é˜®æ–‡å…¨", "20221222005": "è¬å¿ é¾", "20230119001": "é™¶æ˜¥é’",
    "20240926001": "é™³è‰å¨œ", "20241011002": "æ—é›™æ…§", "20250502001": "å³è©©æ•",
    "20250617001": "é˜®æ–‡è­š", "20250617003": "å–¬å®¶å¯¶", "20250901009": "å¼µå¯¶è±",
    "G01": "0", "20201109003": "å³æŒ¯å‡±", "09963": "é»ƒè¬™å‡±",
    "20240313003": "é˜®æ›°å¿ ", "20201109001": "æ¢å† å¦‚", "10003": "æèŒ‚éŠ“",
    "20200922002": "è‘‰æ¬²å¼˜", "20250923019": "é˜®æ°ç´…æ·±", "9963": "é»ƒè¬™å‡±",
    "11399": "é™³å“²æ²…",
}

BREAK_RULES = [
    (dt.time(20, 45, 0), dt.time(22, 30, 0), 0,  "é¦–â‰¥20:45 ä¸” æœ«â‰¤22:30 â†’ 0 åˆ†é˜"),
    (dt.time(18, 30, 0), dt.time(20, 30, 0), 0,  "é¦–â‰¥18:30 ä¸” æœ«â‰¤20:30 â†’ 0 åˆ†é˜"),
    (dt.time(15, 30, 0), dt.time(18,  0, 0), 0,  "é¦–â‰¥15:30 ä¸” æœ«â‰¤18:00 â†’ 0 åˆ†é˜"),
    (dt.time(13, 30, 0), dt.time(15, 35, 0), 0,  "é¦–â‰¥13:30 ä¸” æœ«â‰¤15:35 â†’ 0 åˆ†é˜"),
    (dt.time(20, 45, 0), dt.time(23,  0, 0), 0,  "é¦–â‰¥20:45 ä¸” æœ«â‰¤23:00 â†’ 0 åˆ†é˜"),
    (dt.time(20,  0, 0), dt.time(22,  0, 0), 15, "é¦–â‰¥20:00 ä¸” æœ«â‰¤22:00 â†’ 15 åˆ†é˜"),
    (dt.time(18, 30, 0), dt.time(22,  0, 0), 15, "é¦–â‰¥18:30 ä¸” æœ«â‰¤22:00 â†’ 15 åˆ†é˜"),
    (dt.time(19,  0, 0), dt.time(22, 30, 0), 15, "é¦–â‰¥19:00 ä¸” æœ«â‰¤22:30 â†’ 15 åˆ†é˜"),
    (dt.time(13, 30, 0), dt.time(18,  0, 0), 15, "é¦–â‰¥13:30 ä¸” æœ«â‰¤18:00 â†’ 15 åˆ†é˜"),
    (dt.time(16,  0, 0), dt.time(20, 40, 0), 30, "é¦–â‰¥16:00 ä¸” æœ«â‰¤20:40 â†’ 30 åˆ†é˜"),
    (dt.time(15, 30, 0), dt.time(20, 30, 0), 30, "é¦–â‰¥15:30 ä¸” æœ«â‰¤20:30 â†’ 30 åˆ†é˜"),
    (dt.time(17,  0, 0), dt.time(22, 30, 0), 45, "é¦–â‰¥17:00 ä¸” æœ«â‰¤22:30 â†’ 45 åˆ†é˜"),
    (dt.time(15, 45, 0), dt.time(22, 30, 0), 45, "é¦–â‰¥15:45 ä¸” æœ«â‰¤22:30 â†’ 45 åˆ†é˜"),
    (dt.time(13, 30, 0), dt.time(20, 29, 0), 45, "é¦–â‰¥13:30 ä¸” æœ«â‰¤20:29 â†’ 45 åˆ†é˜"),
    (dt.time(13, 30, 0), dt.time(23,  0, 0), 60, "é¦–â‰¥13:30 ä¸” æœ«â‰¤23:00 â†’ 60 åˆ†é˜"),
    (dt.time(11,  0, 0), dt.time(17,  0, 0), 75, "é¦–â‰¥11:00 ä¸” æœ«â‰¤17:00 â†’ 75 åˆ†é˜"),
    (dt.time( 8,  0, 0), dt.time(17,  0, 0), 90, "é¦–â‰¥08:00 ä¸” æœ«â‰¤17:00 â†’ 90 åˆ†é˜"),
    (dt.time(10, 50, 0), dt.time(23,  0, 0), 120,"é¦–â‰¥10:50 ä¸” æœ«â‰¤23:00 â†’ 120 åˆ†é˜"),
    (dt.time( 8,  0, 0), dt.time(23,  0, 0), 135,"é¦–â‰¥08:00 ä¸” æœ«â‰¤23:00 â†’ 135 åˆ†é˜"),
]

# âœ… é è¨­æ’é™¤ç©ºçª—æ™‚æ®µï¼ˆå¯è¢« sidebar è¦†è“‹ï¼‰
EXCLUDE_IDLE_RANGES_DEFAULT = [
    (dt.time(10,  0, 0), dt.time(10, 15, 0)),
    (dt.time(12, 30, 0), dt.time(13, 30, 0)),
    (dt.time(15, 30, 0), dt.time(15, 45, 0)),
    (dt.time(18,  0, 0), dt.time(18, 30, 0)),
    (dt.time(20, 30, 0), dt.time(20, 45, 0)),
]

# =========================================================
# é€šç”¨ helpers
# =========================================================
def _parse_time_any(x: Any) -> Optional[dt.time]:
    if x is None:
        return None
    if isinstance(x, dt.time):
        return x
    s = str(x).strip()
    if not s:
        return None
    m = re.match(r"^(\d{1,2}):(\d{2})(?::(\d{2}))?$", s)
    if not m:
        return None
    hh = int(m.group(1))
    mm = int(m.group(2))
    ss = int(m.group(3) or 0)
    if not (0 <= hh <= 23 and 0 <= mm <= 59 and 0 <= ss <= 59):
        return None
    return dt.time(hh, mm, ss)


def _extract_zone3(s: Any) -> str:
    """å¾å­—ä¸²æŠ“ç¬¬ä¸€å€‹ 3 ç¢¼æ•¸å­—ï¼ˆ001/014/301...ï¼‰"""
    if s is None:
        return ""
    txt = str(s).strip()
    if not txt:
        return ""
    m = re.search(r"(\d{3})", txt)
    return m.group(1) if m else ""


def _map_storage_type(zone3: str) -> str:
    return ZONE3_TO_STORAGE_TYPE.get(str(zone3).strip(), "")


# =========================================================
# ä¸Šæ¶äººè¨­å®šï¼ˆsession_stateï¼‰
# =========================================================
PUTAWAY_PEOPLE_STATE_KEY = "putaway_people_settings"  # code -> {name, area}

def _get_putaway_people_settings() -> Dict[str, Dict[str, str]]:
    if PUTAWAY_PEOPLE_STATE_KEY not in st.session_state:
        st.session_state[PUTAWAY_PEOPLE_STATE_KEY] = {}
    return st.session_state[PUTAWAY_PEOPLE_STATE_KEY]

def _normalize_code(x: Any) -> str:
    return str(x).strip()

def render_putaway_people_settings_panel():
    settings = _get_putaway_people_settings()

    with st.sidebar.expander("ğŸ“¦ ä¸Šæ¶äººè¨­å®šï¼ˆå¯ä¸­æ–‡å§“åï¼‰", expanded=False):
        code = st.text_input("ä¸Šæ¶äººä»£ç¢¼ï¼ˆå¯è²¼ä¸Šï¼‰", key="putaway_person_code")
        name = st.text_input("å§“åï¼ˆä¸­æ–‡å¯è¼¸å…¥ï¼‰", key="putaway_person_name")
        area = st.selectbox("å€åŸŸ", ["ä½ç©º", "é«˜ç©º"], index=0, key="putaway_person_area")

        c1, c2 = st.columns(2)
        with c1:
            if st.button("â• æ–°å¢ / æ›´æ–°", key="putaway_person_upsert"):
                c = _normalize_code(code)
                if not c:
                    st.error("è«‹å…ˆè¼¸å…¥ä¸Šæ¶äººä»£ç¢¼")
                else:
                    settings[c] = {"name": str(name).strip(), "area": str(area).strip()}
                    st.success(f"å·²æ›´æ–°ï¼š{c}")

        with c2:
            del_code = st.selectbox("åˆªé™¤ä»£ç¢¼", [""] + sorted(list(settings.keys())), key="putaway_person_del_code")
            if st.button("ğŸ—‘ï¸ åˆªé™¤", key="putaway_person_delete", disabled=(del_code == "")):
                settings.pop(del_code, None)
                st.success(f"å·²åˆªé™¤ï¼š{del_code}")

        if settings:
            df = pd.DataFrame(
                [{"ä»£ç¢¼": k, "å§“å": v.get("name", ""), "å€åŸŸ": v.get("area", "")} for k, v in settings.items()]
            ).sort_values(["å€åŸŸ", "ä»£ç¢¼"], ascending=[True, True])
            st.dataframe(df, use_container_width=True, hide_index=True)
        else:
            st.caption("ï¼ˆå°šæœªè¨­å®šï¼‰")


# =========================================================
# sidebar_controls æ’é™¤å€é–“è§£æ
# =========================================================
def _parse_exclude_windows(val: Any) -> List[Tuple[dt.time, dt.time]]:
    if val is None:
        return EXCLUDE_IDLE_RANGES_DEFAULT

    if isinstance(val, dict):
        for k in ("exclude_windows", "exclude_windows_times", "windows", "ranges", "exclude_ranges"):
            if k in val:
                return _parse_exclude_windows(val.get(k))
        return EXCLUDE_IDLE_RANGES_DEFAULT

    if isinstance(val, str):
        raw = val.strip()
        if not raw:
            return EXCLUDE_IDLE_RANGES_DEFAULT
        parts = re.split(r"[ï¼Œ,;ï¼›\n]+", raw)
        items = []
        for p in parts:
            p = p.strip()
            if not p:
                continue
            m = re.match(r"^(\d{1,2}:\d{2}(?::\d{2})?)\s*[-~ï½]\s*(\d{1,2}:\d{2}(?::\d{2})?)$", p)
            if m:
                items.append((m.group(1), m.group(2)))
        return _parse_exclude_windows(items) if items else EXCLUDE_IDLE_RANGES_DEFAULT

    if not isinstance(val, (list, tuple)):
        return EXCLUDE_IDLE_RANGES_DEFAULT

    out: List[Tuple[dt.time, dt.time]] = []
    for item in val:
        if isinstance(item, dict):
            s = _parse_time_any(item.get("start") or item.get("s") or item.get("from"))
            e = _parse_time_any(item.get("end") or item.get("e") or item.get("to"))
        elif isinstance(item, (list, tuple)) and len(item) >= 2:
            s = _parse_time_any(item[0])
            e = _parse_time_any(item[1])
        else:
            s, e = None, None

        if s and e and (dt.datetime.combine(dt.date.today(), s) < dt.datetime.combine(dt.date.today(), e)):
            out.append((s, e))

    return out if out else EXCLUDE_IDLE_RANGES_DEFAULT


def _extract_exclude_value_from_controls(controls: Dict[str, Any]) -> Any:
    if not isinstance(controls, dict) or not controls:
        return None
    for k in (
        "exclude_windows",
        "exclude_windows_times",
        "exclude_ranges",
        "exclude_idle_ranges",
        "idle_exclude_windows",
        "idle_exclude_ranges",
    ):
        if k in controls and controls.get(k):
            return controls.get(k)

    for k, v in controls.items():
        lk = str(k).lower()
        if ("exclude" in lk) and (("window" in lk) or ("range" in lk)) and v:
            return v
    return None


# =========================================================
# è®€æª”ï¼ˆbytesï¼‰
# =========================================================
def read_excel_any_quiet_bytes(name: str, content: bytes) -> Dict[str, pd.DataFrame]:
    ext = (name.split(".")[-1] or "").lower()
    if ext in ("xlsx", "xlsm"):
        xl = pd.ExcelFile(io.BytesIO(content), engine="openpyxl")
        return {sn: pd.read_excel(xl, sheet_name=sn) for sn in xl.sheet_names}
    if ext == "xls":
        xl = pd.ExcelFile(io.BytesIO(content), engine="xlrd")
        return {sn: pd.read_excel(xl, sheet_name=sn) for sn in xl.sheet_names}
    if ext == "csv":
        for enc in ("utf-8-sig", "cp950", "big5"):
            try:
                return {"CSV": pd.read_csv(io.BytesIO(content), encoding=enc)}
            except Exception:
                continue
        raise Exception("CSV è®€å–å¤±æ•—ï¼ˆè«‹ç¢ºèªç·¨ç¢¼ï¼‰")
    raise Exception("ä¸æ”¯æ´çš„å‰¯æª”åï¼ˆåƒ…æ”¯æ´ xlsx/xlsm/xls/csvï¼‰")


def _strip_cols(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    return df


def find_first_column(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    cols = [str(c).strip() for c in df.columns]
    s = set(cols)
    for name in candidates:
        if name in s:
            return name
    norm_map = {re.sub(r"[ï¼ˆï¼‰\(\)\s]", "", c): c for c in cols}
    for name in candidates:
        key = re.sub(r"[ï¼ˆï¼‰\(\)\s]", "", name)
        if key in norm_map:
            return norm_map[key]
    return None


def normalize_to_qc(series: pd.Series) -> pd.Series:
    return series.astype(str).str.strip().str.upper().eq("QC")


def to_not_excluded_mask(series: pd.Series) -> pd.Series:
    s = series.astype(str).str.strip()
    return ~s.str.contains(TO_EXCLUDE_PATTERN, na=False)


def prepare_filtered_df(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        return pd.DataFrame()
    df = _strip_cols(df)
    if "ç”±" not in df.columns or "åˆ°" not in df.columns:
        return pd.DataFrame()
    return df[normalize_to_qc(df["ç”±"]) & to_not_excluded_mask(df["åˆ°"])].copy()


# =========================================================
# âœ… æ£šåˆ¥ä¸»æª”ï¼šå„²ä½â†’æ£šåˆ¥
# =========================================================
def load_slot_master_bytes(upload_name: str, content: bytes) -> pd.DataFrame:
    sheets = read_excel_any_quiet_bytes(upload_name, content)
    df0 = None
    for _, d in sheets.items():
        if d is not None and not d.empty:
            df0 = d
            break
    if df0 is None or df0.empty:
        return pd.DataFrame()

    df0 = _strip_cols(df0)
    if "å„²ä½" not in df0.columns or "æ£šåˆ¥" not in df0.columns:
        return pd.DataFrame()

    out = df0[["å„²ä½", "æ£šåˆ¥"]].copy()
    out["å„²ä½"] = out["å„²ä½"].astype(str).str.strip()
    out["æ£šåˆ¥"] = out["æ£šåˆ¥"].astype(str).str.strip()
    out = out[out["å„²ä½"].astype(str).str.len() > 0].copy()
    out = out.drop_duplicates(subset=["å„²ä½"], keep="last")
    return out


# =========================================================
# è¨ˆç®—ï¼šä¼‘æ¯ / ç©ºçª— / clamp + æ£šåˆ¥æ¯”å°ç­†æ•¸
# =========================================================
def break_minutes_for_span(first_dt: pd.Timestamp, last_dt: pd.Timestamp) -> Tuple[int, str]:
    if pd.isna(first_dt) or pd.isna(last_dt):
        return 0, "ç„¡æ™‚é–“è³‡æ–™"
    stt, edt = first_dt.time(), last_dt.time()
    for st_ge, ed_le, mins, tag in BREAK_RULES:
        if (stt >= st_ge) and (edt <= ed_le):
            return int(mins), str(tag)
    return 0, "æœªå‘½ä¸­è¦å‰‡"


def _subtract_exclusions(s_dt: pd.Timestamp, e_dt: pd.Timestamp, exclude_ranges):
    if s_dt >= e_dt or not exclude_ranges:
        return [(s_dt, e_dt)]
    segments = [(s_dt, e_dt)]
    for ex_s_t, ex_e_t in exclude_ranges:
        ex_s = pd.Timestamp.combine(s_dt.date(), ex_s_t)
        ex_e = pd.Timestamp.combine(s_dt.date(), ex_e_t)
        new_segments = []
        for a, b in segments:
            if b <= ex_s or a >= ex_e:
                new_segments.append((a, b))
            else:
                if a < ex_s:
                    new_segments.append((a, ex_s))
                if b > ex_e:
                    new_segments.append((ex_e, b))
        segments = [(x, y) for (x, y) in new_segments if x < y]
    return segments


def _coerce_dt_series(series_dt: pd.Series) -> pd.Series:
    if series_dt is None:
        return pd.Series([], dtype="datetime64[ns]")
    return pd.to_datetime(series_dt, errors="coerce").dropna()


def _clamp_first(first_dt: pd.Timestamp, last_dt: pd.Timestamp, clamp_dt: Optional[pd.Timestamp]) -> pd.Timestamp:
    if clamp_dt is None or pd.isna(first_dt) or pd.isna(last_dt):
        return first_dt
    if (first_dt < clamp_dt) and (clamp_dt <= last_dt):
        return clamp_dt
    return first_dt


def _compute_idle(
    series_dt: pd.Series,
    min_minutes: int,
    exclude_ranges: List[Tuple[dt.time, dt.time]],
    clamp_dt: Optional[pd.Timestamp] = None,
) -> Tuple[int, str]:
    s = _coerce_dt_series(series_dt).sort_values()
    if s.size < 2:
        return 0, ""

    if clamp_dt is not None and pd.notna(clamp_dt):
        s2 = s[s >= clamp_dt].copy()
        if s2.empty:
            return 0, ""
        if s2.iloc[0] != clamp_dt:
            s2 = pd.concat([pd.Series([clamp_dt]), s2], ignore_index=True)
        s = s2.sort_values()

    total_min, ranges_txt = 0, []
    prev = s.iloc[0]
    for cur in s.iloc[1:]:
        if cur <= prev:
            prev = cur
            continue
        for a, b in _subtract_exclusions(prev, cur, exclude_ranges or []):
            gap_min = int(round((b - a).total_seconds() / 60.0))
            if gap_min >= int(min_minutes):
                total_min += gap_min
                ranges_txt.append(f"{a.time()} ~ {b.time()}")
        prev = cur

    return int(total_min), "ï¼›".join(ranges_txt)


def _span_metrics(series_dt: pd.Series) -> Tuple[pd.Timestamp, pd.Timestamp, int]:
    s = _coerce_dt_series(series_dt)
    if s.empty:
        return pd.NaT, pd.NaT, 0
    return s.min(), s.max(), int(s.size)


def _eff(n: int, m_minutes: int) -> float:
    return round((n / m_minutes * 60.0), 2) if m_minutes and m_minutes > 0 else 0.0


def compute_am_pm_for_group(
    g: pd.DataFrame,
    idle_threshold_min: int,
    exclude_idle_ranges: List[Tuple[dt.time, dt.time]],
    start_time: Optional[dt.time] = None,
) -> pd.Series:
    times = _coerce_dt_series(g["__dt__"])
    if times.empty:
        return pd.Series({
            "ç¬¬ä¸€ç­†æ™‚é–“": pd.NaT, "æœ€å¾Œä¸€ç­†æ™‚é–“": pd.NaT, "ç•¶æ—¥ç­†æ•¸": 0,
            "ä¼‘æ¯åˆ†é˜_æ•´é«”": 0, "å‘½ä¸­è¦å‰‡": "ç„¡æ™‚é–“è³‡æ–™",
            "ç•¶æ—¥å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘": 0, "æ•ˆç‡_ä»¶æ¯å°æ™‚": 0.0,

            "ä¸Šåˆ_ç¬¬ä¸€ç­†": pd.NaT, "ä¸Šåˆ_æœ€å¾Œä¸€ç­†": pd.NaT, "ä¸Šåˆ_ç­†æ•¸": 0,
            "ä¸Šåˆ_å·¥æ™‚_åˆ†é˜": 0, "ä¸Šåˆ_æ•ˆç‡_ä»¶æ¯å°æ™‚": 0.0,
            "ä¸Šåˆ_ç©ºçª—åˆ†é˜": 0, "ä¸Šåˆ_ç©ºçª—æ™‚æ®µ": "",

            "ä¸‹åˆ_ç¬¬ä¸€ç­†": pd.NaT, "ä¸‹åˆ_æœ€å¾Œä¸€ç­†": pd.NaT, "ä¸‹åˆ_ç­†æ•¸": 0,
            "ä¸‹åˆ_ä¼‘æ¯åˆ†é˜": 0, "ä¸‹åˆ_å‘½ä¸­è¦å‰‡": "ç„¡æ™‚é–“è³‡æ–™",
            "ä¸‹åˆ_å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘": 0, "ä¸‹åˆ_æ•ˆç‡_ä»¶æ¯å°æ™‚": 0.0,
            "ä¸‹åˆ_ç©ºçª—åˆ†é˜_æ‰£ä¼‘": 0, "ä¸‹åˆ_ç©ºçª—æ™‚æ®µ": "",

            "æ¯”å°æ£šåˆ¥ç­†æ•¸": 0, "æ¯”å°æ£šåˆ¥ç‡": 0.0,
        })

    shelf_match = g.get("__shelf_match__", pd.Series([False] * len(g), index=g.index))
    shelf_match = shelf_match.fillna(False).astype(bool)
    match_whole = int(shelf_match.sum())

    clamp_dt_whole: Optional[pd.Timestamp] = None
    if isinstance(start_time, dt.time):
        clamp_dt_whole = pd.Timestamp.combine(times.min().date(), start_time)

    # ä¸Šåˆ
    t_am = times[times.dt.time.between(AM_START, AM_END)]
    am_first, am_last, am_cnt = _span_metrics(t_am)
    clamp_dt_am = None
    if clamp_dt_whole is not None and pd.notna(am_first) and pd.notna(am_last):
        if AM_START <= clamp_dt_whole.time() <= AM_END:
            clamp_dt_am = clamp_dt_whole

    am_first_adj = _clamp_first(am_first, am_last, clamp_dt_am)
    am_mins = int(round(((am_last - am_first_adj).total_seconds() / 60.0))) if am_cnt > 0 else 0
    am_mins = max(am_mins, 0)
    am_eff = _eff(am_cnt, am_mins)
    am_idle_min, am_idle_ranges = _compute_idle(
        t_am,
        min_minutes=int(idle_threshold_min),
        exclude_ranges=exclude_idle_ranges,
        clamp_dt=am_first_adj if (am_cnt > 0 and pd.notna(am_first_adj)) else None,
    )

    # ä¸‹åˆ
    t_pm = times[times.dt.time.between(PM_START, PM_END)]
    pm_first, pm_last, pm_cnt = _span_metrics(t_pm)
    clamp_dt_pm = None
    if clamp_dt_whole is not None and pd.notna(pm_first) and pd.notna(pm_last):
        if PM_START <= clamp_dt_whole.time() <= PM_END:
            clamp_dt_pm = clamp_dt_whole

    pm_first_adj = _clamp_first(pm_first, pm_last, clamp_dt_pm)

    if pm_cnt > 0 and pd.notna(pm_first_adj) and pd.notna(pm_last):
        pm_break, pm_rule = break_minutes_for_span(pm_first_adj, pm_last)
        raw_pm_mins = (pm_last - pm_first_adj).total_seconds() / 60.0
        pm_mins = max(int(round(raw_pm_mins - pm_break)), 0)
    else:
        pm_break, pm_rule, pm_mins = 0, "ç„¡æ™‚é–“è³‡æ–™", 0

    pm_eff = _eff(pm_cnt, pm_mins)
    pm_idle_min, pm_idle_ranges = _compute_idle(
        t_pm,
        min_minutes=int(idle_threshold_min),
        exclude_ranges=exclude_idle_ranges,
        clamp_dt=pm_first_adj if (pm_cnt > 0 and pd.notna(pm_first_adj)) else None,
    )

    # æ•´é«”
    whole_first, whole_last, day_cnt = _span_metrics(times)
    whole_first_adj = _clamp_first(whole_first, whole_last, clamp_dt_whole)

    if day_cnt > 0 and pd.notna(whole_first_adj) and pd.notna(whole_last):
        whole_break, br_tag_whole = break_minutes_for_span(whole_first_adj, whole_last)
        raw_whole_mins = (whole_last - whole_first_adj).total_seconds() / 60.0
        whole_mins = max(int(round(raw_whole_mins - whole_break)), 0)
    else:
        whole_break, br_tag_whole, whole_mins = 0, "ç„¡æ™‚é–“è³‡æ–™", 0

    whole_eff = _eff(day_cnt, whole_mins)
    match_rate_whole = (match_whole / int(day_cnt)) if int(day_cnt) > 0 else 0.0

    return pd.Series({
        "ç¬¬ä¸€ç­†æ™‚é–“": whole_first_adj, "æœ€å¾Œä¸€ç­†æ™‚é–“": whole_last, "ç•¶æ—¥ç­†æ•¸": int(day_cnt),
        "ä¼‘æ¯åˆ†é˜_æ•´é«”": int(whole_break), "å‘½ä¸­è¦å‰‡": br_tag_whole,
        "ç•¶æ—¥å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘": int(whole_mins), "æ•ˆç‡_ä»¶æ¯å°æ™‚": whole_eff,

        "ä¸Šåˆ_ç¬¬ä¸€ç­†": am_first_adj, "ä¸Šåˆ_æœ€å¾Œä¸€ç­†": am_last, "ä¸Šåˆ_ç­†æ•¸": int(am_cnt),
        "ä¸Šåˆ_å·¥æ™‚_åˆ†é˜": int(am_mins), "ä¸Šåˆ_æ•ˆç‡_ä»¶æ¯å°æ™‚": am_eff,
        "ä¸Šåˆ_ç©ºçª—åˆ†é˜": int(am_idle_min), "ä¸Šåˆ_ç©ºçª—æ™‚æ®µ": am_idle_ranges,

        "ä¸‹åˆ_ç¬¬ä¸€ç­†": pm_first_adj, "ä¸‹åˆ_æœ€å¾Œä¸€ç­†": pm_last, "ä¸‹åˆ_ç­†æ•¸": int(pm_cnt),
        "ä¸‹åˆ_ä¼‘æ¯åˆ†é˜": int(pm_break), "ä¸‹åˆ_å‘½ä¸­è¦å‰‡": pm_rule,
        "ä¸‹åˆ_å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘": int(pm_mins), "ä¸‹åˆ_æ•ˆç‡_ä»¶æ¯å°æ™‚": pm_eff,
        "ä¸‹åˆ_ç©ºçª—åˆ†é˜_æ‰£ä¼‘": int(pm_idle_min), "ä¸‹åˆ_ç©ºçª—æ™‚æ®µ": pm_idle_ranges,

        "æ¯”å°æ£šåˆ¥ç­†æ•¸": int(match_whole),
        "æ¯”å°æ£šåˆ¥ç‡": float(match_rate_whole),
    })


# =========================================================
# Excel åŒ¯å‡ºï¼ˆbytesï¼‰
# =========================================================
def autosize_columns(ws, df: pd.DataFrame):
    from openpyxl.utils import get_column_letter
    cols = list(df.columns) if df is not None else []
    for i, col in enumerate(cols, start=1):
        if df is not None and not df.empty:
            sample = [len(str(x)) for x in df[col].head(800).tolist()]
            max_len = max([len(str(col))] + sample)
        else:
            max_len = max(len(str(col)), 8)
        ws.column_dimensions[get_column_letter(i)].width = min(max_len + 2, 60)


def shade_rows_by_efficiency(ws, header_name="æ•ˆç‡_ä»¶æ¯å°æ™‚", green="C6EFCE", red="FFC7CE", target_eff=20):
    from openpyxl.styles import PatternFill
    eff_col = None
    for c in range(1, ws.max_column + 1):
        if str(ws.cell(row=1, column=c).value).strip() == header_name:
            eff_col = c
            break
    if eff_col is None:
        return
    green_fill = PatternFill(start_color=green, end_color=green, fill_type="solid")
    red_fill = PatternFill(start_color=red, end_color=red, fill_type="solid")
    for r in range(2, ws.max_row + 1):
        v = ws.cell(row=r, column=eff_col).value
        try:
            val = float(v) if v is not None and str(v).strip() != "" else None
        except Exception:
            val = None
        if val is None:
            continue
        fill = green_fill if val >= float(target_eff) else red_fill
        for cc in range(1, ws.max_column + 1):
            ws.cell(row=r, column=cc).fill = fill


def _fmt_ts_time(x: Any) -> str:
    if x is None or (isinstance(x, float) and pd.isna(x)):
        return ""
    if isinstance(x, pd.Timestamp):
        if pd.isna(x):
            return ""
        return x.strftime("%H:%M:%S")
    try:
        xx = pd.to_datetime(x, errors="coerce")
        if pd.isna(xx):
            return ""
        return xx.strftime("%H:%M:%S")
    except Exception:
        return ""


def _build_shift_total_df(daily: pd.DataFrame, user_col: str, shift: str) -> pd.DataFrame:
    """
    shift='AM' or 'PM'
    æ¬„ä½ï¼š
    ä»£ç¢¼ã€å§“åã€ç­†æ•¸ã€å·¥ä½œå€é–“ã€ç¸½åˆ†é˜ã€æ•ˆç‡(ä»¶/æ™‚)ã€ä¼‘æ¯åˆ†é˜ã€ç©ºçª—åˆ†é˜ã€ç©ºçª—æ™‚æ®µ
    """
    if daily is None or daily.empty:
        return pd.DataFrame(columns=["ä»£ç¢¼", "å§“å", "ç­†æ•¸", "å·¥ä½œå€é–“", "ç¸½åˆ†é˜", "æ•ˆç‡(ä»¶/æ™‚)", "ä¼‘æ¯åˆ†é˜", "ç©ºçª—åˆ†é˜", "ç©ºçª—æ™‚æ®µ"])

    d = daily.copy()

    if shift.upper() == "AM":
        cnt_col = "ä¸Šåˆ_ç­†æ•¸"
        first_col, last_col = "ä¸Šåˆ_ç¬¬ä¸€ç­†", "ä¸Šåˆ_æœ€å¾Œä¸€ç­†"
        mins_col = "ä¸Šåˆ_å·¥æ™‚_åˆ†é˜"
        eff_col = "ä¸Šåˆ_æ•ˆç‡_ä»¶æ¯å°æ™‚"
        rest_col = None
        idle_min_col = "ä¸Šåˆ_ç©ºçª—åˆ†é˜"
        idle_rng_col = "ä¸Šåˆ_ç©ºçª—æ™‚æ®µ"
    else:
        cnt_col = "ä¸‹åˆ_ç­†æ•¸"
        first_col, last_col = "ä¸‹åˆ_ç¬¬ä¸€ç­†", "ä¸‹åˆ_æœ€å¾Œä¸€ç­†"
        mins_col = "ä¸‹åˆ_å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘"
        eff_col = "ä¸‹åˆ_æ•ˆç‡_ä»¶æ¯å°æ™‚"
        rest_col = "ä¸‹åˆ_ä¼‘æ¯åˆ†é˜"
        idle_min_col = "ä¸‹åˆ_ç©ºçª—åˆ†é˜_æ‰£ä¼‘"
        idle_rng_col = "ä¸‹åˆ_ç©ºçª—æ™‚æ®µ"

    d[cnt_col] = pd.to_numeric(d.get(cnt_col, 0), errors="coerce").fillna(0).astype(int)
    d = d[d[cnt_col] > 0].copy()

    if d.empty:
        return pd.DataFrame(columns=["ä»£ç¢¼", "å§“å", "ç­†æ•¸", "å·¥ä½œå€é–“", "ç¸½åˆ†é˜", "æ•ˆç‡(ä»¶/æ™‚)", "ä¼‘æ¯åˆ†é˜", "ç©ºçª—åˆ†é˜", "ç©ºçª—æ™‚æ®µ"])

    name_series = d["å°æ‡‰å§“å"].astype(str).fillna("").str.strip()
    code_series = d[user_col].astype(str).fillna("").str.strip()
    d["_å§“åé¡¯ç¤º"] = name_series.where(name_series.ne(""), code_series)

    d["å·¥ä½œå€é–“"] = d.apply(lambda r: f"{_fmt_ts_time(r.get(first_col))} ~ {_fmt_ts_time(r.get(last_col))}".strip(), axis=1)

    out = pd.DataFrame({
        "ä»£ç¢¼": code_series,
        "å§“å": d["_å§“åé¡¯ç¤º"],
        "ç­†æ•¸": d[cnt_col].astype(int),
        "å·¥ä½œå€é–“": d["å·¥ä½œå€é–“"],
        "ç¸½åˆ†é˜": pd.to_numeric(d.get(mins_col, 0), errors="coerce").fillna(0).astype(int),
        "æ•ˆç‡(ä»¶/æ™‚)": pd.to_numeric(d.get(eff_col, 0), errors="coerce").fillna(0.0).round(2),
        "ä¼‘æ¯åˆ†é˜": (pd.to_numeric(d.get(rest_col, 0), errors="coerce").fillna(0).astype(int) if rest_col else 0),
        "ç©ºçª—åˆ†é˜": pd.to_numeric(d.get(idle_min_col, 0), errors="coerce").fillna(0).astype(int),
        "ç©ºçª—æ™‚æ®µ": d.get(idle_rng_col, "").astype(str).fillna(""),
    })

    out = out.sort_values(["æ•ˆç‡(ä»¶/æ™‚)", "ä»£ç¢¼"], ascending=[False, True]).reset_index(drop=True)
    return out


def _write_total_sheet(ws, daily: pd.DataFrame, user_col: str):
    """
    åœ¨åŒä¸€å¼µã€Œç¸½è¡¨ã€å·¥ä½œè¡¨ï¼Œä¾æ—¥æœŸè¼¸å‡ºï¼š
    [YYYY-MM-DD ä¸Šæ¶ç¸¾æ•ˆ] / ä¸Šåˆè¡¨ / ä¸‹åˆè¡¨

    âœ… æ¬„ä½Fã€Œæ•ˆç‡(ä»¶/æ™‚)ã€ï¼š
      >=20ï¼šåº•è‰² #FFC7CEã€å­—è‰² #9C0006
      <20 ï¼šåº•è‰² #C6EFCEã€å­—è‰² #006100
    """
    from openpyxl.styles import PatternFill, Font, Alignment, Border, Side
    from openpyxl.utils import get_column_letter

    EFF_THRESHOLD = 20.0

    thin = Side(style="thin", color="9CA3AF")
    border = Border(left=thin, right=thin, top=thin, bottom=thin)

    fill_title = PatternFill("solid", fgColor="FFFFFF")
    fill_header = PatternFill("solid", fgColor="E5E7EB")   # ç°
    fill_am = PatternFill("solid", fgColor="D1FAE5")       # ä¸Šåˆæ·¡ç¶ 
    fill_pm = PatternFill("solid", fgColor="FDE2E2")       # ä¸‹åˆæ·¡ç²‰

    # âœ… æ•ˆç‡æ¬„(F)æ¢ä»¶å¼æ¨£å¼ï¼ˆç…§ä½ æŒ‡å®šï¼š>=20 ç´…åº•ç´…å­—ï¼›<20 ç¶ åº•ç¶ å­—ï¼‰
    eff_bad_fill  = PatternFill("solid", fgColor="FFC7CE")  # #FFC7CE
    eff_bad_font  = Font(color="9C0006")                    # #9C0006
    eff_good_fill = PatternFill("solid", fgColor="C6EFCE")  # #C6EFCE
    eff_good_font = Font(color="006100")                    # #006100

    font_title = Font(bold=True, size=14)
    font_section = Font(bold=True, size=12)
    font_header = Font(bold=True, size=11)
    align_center = Alignment(horizontal="center", vertical="center", wrap_text=True)
    align_left = Alignment(horizontal="left", vertical="center", wrap_text=True)

    headers = ["ä»£ç¢¼", "å§“å", "ç­†æ•¸", "å·¥ä½œå€é–“", "ç¸½åˆ†é˜", "æ•ˆç‡(ä»¶/æ™‚)", "ä¼‘æ¯åˆ†é˜", "ç©ºçª—åˆ†é˜", "ç©ºçª—æ™‚æ®µ"]
    ncol = len(headers)

    # æ¬„å¯¬
    col_widths = [12, 10, 6, 22, 8, 10, 8, 8, 60]
    for i, w in enumerate(col_widths, start=1):
        ws.column_dimensions[get_column_letter(i)].width = w

    if daily is None or daily.empty or "æ—¥æœŸ" not in daily.columns:
        ws["A1"] = "ç„¡å¯ç”¨è³‡æ–™"
        return

    dates = sorted([x for x in daily["æ—¥æœŸ"].dropna().unique()])
    r = 1

    def _try_float(x):
        try:
            if x is None:
                return None
            s = str(x).strip()
            if s == "":
                return None
            return float(x)
        except Exception:
            return None

    for d0 in dates:
        day_df = daily[daily["æ—¥æœŸ"] == d0].copy()

        # Title
        title = f"{d0} ä¸Šæ¶ç¸¾æ•ˆ"
        ws.merge_cells(start_row=r, start_column=1, end_row=r, end_column=ncol)
        c = ws.cell(row=r, column=1, value=title)
        c.fill = fill_title
        c.font = font_title
        c.alignment = align_center
        r += 1

        # AM section
        ws.merge_cells(start_row=r, start_column=1, end_row=r, end_column=ncol)
        c = ws.cell(row=r, column=1, value="ä¸Šåˆ")
        c.font = font_section
        c.alignment = align_center
        r += 1

        # Header row
        for j, h in enumerate(headers, start=1):
            cell = ws.cell(row=r, column=j, value=h)
            cell.fill = fill_header
            cell.font = font_header
            cell.alignment = align_center
            cell.border = border
        r += 1

        am_tbl = _build_shift_total_df(day_df, user_col=user_col, shift="AM")
        if am_tbl.empty:
            ws.merge_cells(start_row=r, start_column=1, end_row=r, end_column=ncol)
            c = ws.cell(row=r, column=1, value="ï¼ˆä¸Šåˆç„¡è³‡æ–™ï¼‰")
            c.alignment = align_center
            r += 1
        else:
            for _, row in am_tbl.iterrows():
                for j, h in enumerate(headers, start=1):
                    v = row.get(h, "")
                    cell = ws.cell(row=r, column=j, value=v)

                    # é è¨­ï¼šä¸Šåˆåº•è‰²
                    cell.fill = fill_am

                    # âœ… åªé‡å°æ¬„ä½Fï¼šæ•ˆç‡(ä»¶/æ™‚) å¥—æ¢ä»¶è‰²/å­—è‰²
                    if h == "æ•ˆç‡(ä»¶/æ™‚)":
                        val = _try_float(v)
                        if val is not None:
                            if val >= EFF_THRESHOLD:
                                cell.fill = eff_bad_fill
                                cell.font = eff_bad_font
                            else:
                                cell.fill = eff_good_fill
                                cell.font = eff_good_font

                    cell.alignment = (align_left if h == "ç©ºçª—æ™‚æ®µ" else align_center)
                    cell.border = border
                r += 1

        r += 1  # blank

        # PM section
        ws.merge_cells(start_row=r, start_column=1, end_row=r, end_column=ncol)
        c = ws.cell(row=r, column=1, value="ä¸‹åˆ")
        c.font = font_section
        c.alignment = align_center
        r += 1

        for j, h in enumerate(headers, start=1):
            cell = ws.cell(row=r, column=j, value=h)
            cell.fill = fill_header
            cell.font = font_header
            cell.alignment = align_center
            cell.border = border
        r += 1

        pm_tbl = _build_shift_total_df(day_df, user_col=user_col, shift="PM")
        if pm_tbl.empty:
            ws.merge_cells(start_row=r, start_column=1, end_row=r, end_column=ncol)
            c = ws.cell(row=r, column=1, value="ï¼ˆä¸‹åˆç„¡è³‡æ–™ï¼‰")
            c.alignment = align_center
            r += 1
        else:
            for _, row in pm_tbl.iterrows():
                for j, h in enumerate(headers, start=1):
                    v = row.get(h, "")
                    cell = ws.cell(row=r, column=j, value=v)

                    # é è¨­ï¼šä¸‹åˆåº•è‰²
                    cell.fill = fill_pm

                    # âœ… åªé‡å°æ¬„ä½Fï¼šæ•ˆç‡(ä»¶/æ™‚) å¥—æ¢ä»¶è‰²/å­—è‰²
                    if h == "æ•ˆç‡(ä»¶/æ™‚)":
                        val = _try_float(v)
                        if val is not None:
                            if val >= EFF_THRESHOLD:
                                cell.fill = eff_bad_fill
                                cell.font = eff_bad_font
                            else:
                                cell.fill = eff_good_fill
                                cell.font = eff_good_font

                    cell.alignment = (align_left if h == "ç©ºçª—æ™‚æ®µ" else align_center)
                    cell.border = border
                r += 1

        r += 2  # blank between dates

    ws.freeze_panes = "A4"


def build_excel_bytes(
    user_col: str,
    summary_out: pd.DataFrame,
    daily: pd.DataFrame,
    shelf_person_pivot: pd.DataFrame,
    stype_person_pivot: pd.DataFrame,
    target_eff: float,
) -> bytes:
    out = io.BytesIO()
    with pd.ExcelWriter(out, engine="openpyxl", datetime_format="yyyy-mm-dd hh:mm:ss", date_format="yyyy-mm-dd") as writer:
        sum_cols = [
            user_col, "å°æ‡‰å§“å", "ç·æ—¥æ•¸",
            "ç¸½ç­†æ•¸", "ç¸½å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘", "æ•ˆç‡_ä»¶æ¯å°æ™‚",
            "ä¸Šåˆç­†æ•¸", "ä¸Šåˆå·¥æ™‚_åˆ†é˜", "ä¸Šåˆæ•ˆç‡_ä»¶æ¯å°æ™‚",
            "ä¸‹åˆç­†æ•¸", "ä¸‹åˆå·¥æ™‚_åˆ†é˜_æ‰£ä¼‘", "ä¸‹åˆæ•ˆç‡_ä»¶æ¯å°æ™‚",
            "æ¯”å°æ£šåˆ¥ç­†æ•¸", "æ¯”å°æ£šåˆ¥ç‡",
        ]
        summary_out[sum_cols].to_excel(writer, index=False, sheet_name="å½™ç¸½")
        autosize_columns(writer.sheets["å½™ç¸½"], summary_out[sum_cols])
        shade_rows_by_efficiency(writer.sheets["å½™ç¸½"], "æ•ˆç‡_ä»¶æ¯å°æ™‚", target_eff=target_eff)

        det_cols = [
            user_col, "å°æ‡‰å§“å", "æ—¥æœŸ",
            "ç¬¬ä¸€ç­†æ™‚é–“", "æœ€å¾Œä¸€ç­†æ™‚é–“", "ç•¶æ—¥ç­†æ•¸",
            "ä¼‘æ¯åˆ†é˜_æ•´é«”", "ç•¶æ—¥å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘", "æ•ˆç‡_ä»¶æ¯å°æ™‚",
            "ä¸Šåˆ_ç¬¬ä¸€ç­†", "ä¸Šåˆ_æœ€å¾Œä¸€ç­†", "ä¸Šåˆ_ç­†æ•¸", "ä¸Šåˆ_å·¥æ™‚_åˆ†é˜", "ä¸Šåˆ_æ•ˆç‡_ä»¶æ¯å°æ™‚",
            "ä¸Šåˆ_ç©ºçª—åˆ†é˜", "ä¸Šåˆ_ç©ºçª—æ™‚æ®µ",
            "ä¸‹åˆ_ç¬¬ä¸€ç­†", "ä¸‹åˆ_æœ€å¾Œä¸€ç­†", "ä¸‹åˆ_ç­†æ•¸", "ä¸‹åˆ_ä¼‘æ¯åˆ†é˜",
            "ä¸‹åˆ_å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘", "ä¸‹åˆ_æ•ˆç‡_ä»¶æ¯å°æ™‚",
            "ä¸‹åˆ_ç©ºçª—åˆ†é˜_æ‰£ä¼‘", "ä¸‹åˆ_ç©ºçª—æ™‚æ®µ",
            "æ¯”å°æ£šåˆ¥ç­†æ•¸", "æ¯”å°æ£šåˆ¥ç‡",
        ]
        daily.sort_values([user_col, "æ—¥æœŸ", "ç¬¬ä¸€ç­†æ™‚é–“"])[det_cols].to_excel(writer, index=False, sheet_name="æ˜ç´°")
        autosize_columns(writer.sheets["æ˜ç´°"], daily[det_cols])
        shade_rows_by_efficiency(writer.sheets["æ˜ç´°"], "æ•ˆç‡_ä»¶æ¯å°æ™‚", target_eff=target_eff)

        if stype_person_pivot is not None and not stype_person_pivot.empty:
            stype_person_pivot.to_excel(writer, index=False, sheet_name="å„²ä½é¡å‹_äººå“¡_æ¨ç´")
            autosize_columns(writer.sheets["å„²ä½é¡å‹_äººå“¡_æ¨ç´"], stype_person_pivot)

        if shelf_person_pivot is not None and not shelf_person_pivot.empty:
            shelf_person_pivot.to_excel(writer, index=False, sheet_name="æ£šåˆ¥_äººå“¡_æ¨ç´")
            autosize_columns(writer.sheets["æ£šåˆ¥_äººå“¡_æ¨ç´"], shelf_person_pivot)

        rules_rows = []
        for i, (st_ge, ed_le, mins, tag) in enumerate(BREAK_RULES, start=1):
            rules_rows.append({
                "å„ªå…ˆåº": i,
                "é¦–æ™‚é–“æ¢ä»¶(>=)": st_ge.strftime("%H:%M:%S"),
                "æœ«æ™‚é–“æ¢ä»¶(<=)": ed_le.strftime("%H:%M:%S"),
                "ä¼‘æ¯åˆ†é˜": int(mins),
                "è¦å‰‡èªªæ˜": str(tag),
            })
        rules_df = pd.DataFrame(rules_rows)
        rules_df.to_excel(writer, index=False, sheet_name="ä¼‘æ¯è¦å‰‡")
        autosize_columns(writer.sheets["ä¼‘æ¯è¦å‰‡"], rules_df)

        # âœ… æ–°å¢ï¼šç¸½è¡¨ï¼ˆç¬¦åˆä½ æˆªåœ– AM/PM åˆ†æ®µ + Fæ¬„æ•ˆç‡å¥—è‰²ï¼‰
        ws_total = writer.book.create_sheet("ç¸½è¡¨")
        writer.sheets["ç¸½è¡¨"] = ws_total
        _write_total_sheet(ws_total, daily=daily, user_col=user_col)

    return out.getvalue()


# =========================================================
# Streamlit Page
# =========================================================
def main():
    inject_logistics_theme()
    set_page(
        "ä¸Šæ¶ç”¢èƒ½åˆ†æï¼ˆPutaway KPIï¼‰",
        icon="ğŸ“¦",
        subtitle="ä¸»ç•«é¢é¡¯ç¤ºï¼šå„²ä½é¡å‹æ¨ç´è¡¨ + æ£šåˆ¥æ¨ç´è¡¨ï¼›Excel åŒ¯å‡ºå«ï¼šå½™ç¸½/æ˜ç´°/ç¸½è¡¨"
    )

    if "putaway_last" not in st.session_state:
        st.session_state.putaway_last = None

    # Sidebarï¼šä¸Šæ¶äººè¨­å®š
    render_putaway_people_settings_panel()

    # Sidebarï¼šçµ±ä¸€æ¢ä»¶
    controls = sidebar_controls(default_top_n=30, enable_exclude_windows=True, state_key_prefix="putaway")
    top_n = int(controls.get("top_n", 30))

    exclude_raw = _extract_exclude_value_from_controls(controls)
    exclude_idle_ranges = _parse_exclude_windows(exclude_raw)

    with st.sidebar:
        st.markdown("---")
        target_eff = st.number_input("é”æ¨™é–€æª»ï¼ˆæ•ˆç‡ â‰¥ï¼‰", min_value=1, max_value=999, value=int(TARGET_EFF_DEFAULT), step=1)
        idle_threshold = st.number_input("ç©ºçª—é–€æª»ï¼ˆåˆ†é˜ â‰¥ æ‰ç®—ï¼‰", min_value=1, max_value=240, value=int(IDLE_MIN_THRESHOLD_DEFAULT), step=1)

        start_time_raw = st.text_input("èµ·å§‹æ™‚é–“ï¼ˆclamp ç¬¬ä¸€ç­†ï¼›HH:MM:SSï¼‰", value="08:05:00", key="putaway_global_start_time")
        global_start_time = _parse_time_any(start_time_raw)
        if global_start_time is None:
            st.warning("âš ï¸ èµ·å§‹æ™‚é–“æ ¼å¼ä¸æ­£ç¢ºï¼Œå°‡ä¸é€²è¡Œ clampï¼ˆè«‹ç”¨ HH:MM æˆ– HH:MM:SSï¼‰")
        else:
            st.caption(f"âœ… clamp èµ·å§‹æ™‚é–“ï¼š{global_start_time.strftime('%H:%M:%S')}")

        preview = "ã€".join([f"{a.strftime('%H:%M')}~{b.strftime('%H:%M')}" for a, b in exclude_idle_ranges]) if exclude_idle_ranges else "ï¼ˆç„¡ï¼‰"
        st.caption(f"âœ… å·²è®€å–æ’é™¤ç©ºçª—æ™‚æ®µï¼š{preview}")
        st.caption("âš ï¸ è‹¥ä½ æ”¹äº†æ¢ä»¶/æ£šåˆ¥ä¸»æª”ï¼Œéœ€å†æŒ‰ä¸€æ¬¡ã€ŒğŸš€ ç”¢å‡º KPIã€æ‰æœƒé‡æ–°è¨ˆç®—ã€‚")
        st.caption("æç¤ºï¼šä¸Šå‚³ .xls éœ€ requirements å®‰è£ xlrd==2.0.1")

    # âœ… æ£šåˆ¥ä¸»æª”åœ¨ä¸»ç•«é¢ï¼ˆåªä¸Šå‚³ï¼Œä¸å±•ç¤ºè¡¨æ ¼ï¼‰
    card_open("ğŸ“š æ£šåˆ¥ä¸»æª”ï¼ˆå„²ä½æ˜ç´°ï¼‰")
    slot_master_file = st.file_uploader(
        "ä¸Šå‚³æ£šåˆ¥ä¸»æª”ï¼ˆéœ€å«æ¬„ä½ï¼šã€å„²ä½ã€ã€æ£šåˆ¥ã€ï¼‰",
        type=["xlsx", "xlsm", "xls", "csv"],
        key="putaway_slot_master_main",
        help="æ¯”å°ï¼šæ˜ç´°æ¬„ä½ã€åˆ°ã€(å„²ä½) â†’ ä¸»æª”ã€å„²ä½ã€å°æ‡‰å‡ºã€æ£šåˆ¥ã€ï¼›æŸ¥å¾—åˆ°æ£šåˆ¥å³ç®—æ¯”å°æˆåŠŸã€‚",
    )
    card_close()

    # ä¸Šå‚³ä½œæ¥­åŸå§‹è³‡æ–™
    card_open("ğŸ“¤ ä¸Šå‚³ä½œæ¥­åŸå§‹è³‡æ–™ï¼ˆä¸Šæ¶ï¼‰")
    uploaded = st.file_uploader(
        "ä¸Šå‚³ Excel / CSVï¼ˆéœ€åŒ…å«ï¼šç”±ã€åˆ°ã€ä¿®è¨‚æ—¥æœŸ/æ™‚é–“ã€è¨˜éŒ„è¼¸å…¥äººï¼‰",
        type=["xlsx", "xlsm", "xls", "csv"],
        label_visibility="collapsed",
        key="putaway_raw",
    )
    run_clicked = st.button("ğŸš€ ç”¢å‡º KPI", type="primary", disabled=uploaded is None)
    card_close()

    # âœ… æ¢ä»¶è®Šæ›´æé†’
    last = st.session_state.putaway_last
    people_settings_snapshot = _get_putaway_people_settings()
    people_hash = str(sorted([(k, v.get("name", ""), v.get("area", "")) for k, v in people_settings_snapshot.items()]))

    slot_hash = ""
    if slot_master_file is not None:
        slot_hash = f"{slot_master_file.name}:{len(slot_master_file.getvalue())}"

    current_params = {
        "target_eff": int(target_eff),
        "idle_threshold": int(idle_threshold),
        "exclude_idle_ranges": [(a.strftime("%H:%M:%S"), b.strftime("%H:%M:%S")) for a, b in exclude_idle_ranges],
        "top_n": int(top_n),
        "people_hash": people_hash,
        "global_start_time": global_start_time.strftime("%H:%M:%S") if global_start_time else "",
        "slot_hash": slot_hash,
    }
    if last and last.get("params") and last.get("params") != current_params:
        st.warning("âš ï¸ ä½ å·²è®Šæ›´æ¢ä»¶ï¼ˆå«æ£šåˆ¥ä¸»æª”ï¼‰ï¼Œè«‹å†æŒ‰ä¸€æ¬¡ã€ŒğŸš€ ç”¢å‡º KPIã€æ‰æœƒå¥—ç”¨æ–°æ¢ä»¶ã€‚")

    # âœ… è¨ˆç®—
    if run_clicked:
        with st.spinner("è¨ˆç®—ä¸­ï¼Œè«‹ç¨å€™..."):
            sheets = read_excel_any_quiet_bytes(uploaded.name, uploaded.getvalue())

            kept_all = []
            for sn, df in sheets.items():
                k = prepare_filtered_df(df)
                if not k.empty:
                    k["__sheet__"] = sn
                    kept_all.append(k)

            if not kept_all:
                st.error("ç„¡ç¬¦åˆè³‡æ–™ï¼ˆå¯èƒ½ç¼ºã€ç”±/åˆ°ã€æ¬„æˆ–éæ¿¾å¾Œç‚ºç©ºï¼‰ã€‚")
                st.session_state.putaway_last = None
                return

            data = pd.concat(kept_all, ignore_index=True)

            user_col = find_first_column(data, INPUT_USER_CANDIDATES)
            revdt_col = find_first_column(data, REV_DT_CANDIDATES)
            if user_col is None:
                st.error("æ‰¾ä¸åˆ°ã€è¨˜éŒ„è¼¸å…¥äººã€æ¬„ä½ï¼ˆå€™é¸ï¼šè¨˜éŒ„è¼¸å…¥äºº/è¨˜éŒ„è¼¸å…¥è€…/å»ºç«‹äºº/è¼¸å…¥äººï¼‰ã€‚")
                st.session_state.putaway_last = None
                return
            if revdt_col is None:
                st.error("æ‰¾ä¸åˆ°ã€ä¿®è¨‚æ—¥æœŸ/æ™‚é–“ã€æ¬„ä½ï¼ˆå€™é¸ï¼šä¿®è¨‚æ—¥æœŸ/ä¿®è¨‚æ™‚é–“/ä¿®è¨‚æ—¥/ç•°å‹•æ™‚é–“/ä¿®æ”¹æ™‚é–“ï¼‰ã€‚")
                st.session_state.putaway_last = None
                return

            data["__dt__"] = pd.to_datetime(data[revdt_col], errors="coerce")
            data["__code__"] = data[user_col].astype(str).str.strip()

            # âœ… ä¸Šæ¶äººå§“å
            people_settings = _get_putaway_people_settings()
            custom_name_map = {k: v.get("name", "") for k, v in people_settings.items() if v.get("name")}
            merged_name_map = {**NAME_MAP, **custom_name_map}
            data["å°æ‡‰å§“å"] = data["__code__"].map(merged_name_map).fillna("")

            # âœ… æ£šåˆ¥æ¯”å°ï¼ˆåˆ°â†’æ£šåˆ¥ï¼‰
            data["__to_loc__"] = data["åˆ°"].astype(str).str.strip()

            slot_map_shelf = {}
            if slot_master_file is not None:
                try:
                    slot_master_df = load_slot_master_bytes(slot_master_file.name, slot_master_file.getvalue())
                    if not slot_master_df.empty:
                        slot_map_shelf = dict(zip(slot_master_df["å„²ä½"], slot_master_df["æ£šåˆ¥"]))
                    else:
                        st.warning("âš ï¸ æ£šåˆ¥ä¸»æª”è®€å–æˆåŠŸä½†ç¼ºå¿…è¦æ¬„ä½ï¼ˆéœ€å«ï¼šå„²ä½ã€æ£šåˆ¥ï¼‰ï¼Œå°‡ä¸è¨ˆç®—æ£šåˆ¥ã€‚")
                except Exception as e:
                    st.warning(f"âš ï¸ æ£šåˆ¥ä¸»æª”è®€å–å¤±æ•—ï¼š{e}ï¼Œå°‡ä¸è¨ˆç®—æ£šåˆ¥ã€‚")

            if slot_map_shelf:
                data["æ£šåˆ¥"] = data["__to_loc__"].map(slot_map_shelf).fillna("")
            else:
                data["æ£šåˆ¥"] = ""

            data["__shelf_match__"] = data["æ£šåˆ¥"].astype(str).str.strip().ne("")

            # âœ… å„²ä½é¡å‹ï¼šæ£šåˆ¥æŠ“å€ç¢¼3ï¼ŒæŠ“ä¸åˆ°ç”¨ åˆ°(å„²ä½)
            data["æ£šåˆ¥_å€ç¢¼3"] = data["æ£šåˆ¥"].apply(_extract_zone3)
            fallback_zone3 = data["__to_loc__"].apply(_extract_zone3)
            data["æ£šåˆ¥_å€ç¢¼3"] = data["æ£šåˆ¥_å€ç¢¼3"].where(data["æ£šåˆ¥_å€ç¢¼3"].ne(""), fallback_zone3)
            data["å„²ä½é¡å‹"] = data["æ£šåˆ¥_å€ç¢¼3"].apply(_map_storage_type).fillna("")

            dt_data = data.dropna(subset=["__dt__"]).copy()
            if dt_data.empty:
                st.error("è³‡æ–™æ²’æœ‰å¯ç”¨çš„ä¿®è¨‚æ—¥æœŸæ™‚é–“ï¼Œç„¡æ³•è¨ˆç®—ã€‚")
                st.session_state.putaway_last = None
                return

            dt_data["æ—¥æœŸ"] = dt_data["__dt__"].dt.date

            # âœ… æ—¥å½™ç¸½ï¼ˆå«æ£šåˆ¥æ¯”å°ç­†æ•¸/ç‡ï¼‰
            daily = (
                dt_data.groupby([user_col, "å°æ‡‰å§“å", "æ—¥æœŸ"], dropna=False)
                .apply(lambda g: compute_am_pm_for_group(
                    g,
                    idle_threshold_min=int(idle_threshold),
                    exclude_idle_ranges=exclude_idle_ranges,
                    start_time=global_start_time,
                ))
                .reset_index()
            )

            # âœ… å€‹äººç¸½å½™ç¸½
            summary = (
                daily.groupby([user_col, "å°æ‡‰å§“å"], dropna=False, as_index=False)
                .agg(
                    ç·æ—¥æ•¸=("æ—¥æœŸ", "nunique"),
                    ç¸½ç­†æ•¸=("ç•¶æ—¥ç­†æ•¸", "sum"),
                    ç¸½å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘=("ç•¶æ—¥å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘", "sum"),
                    ä¸Šåˆç­†æ•¸=("ä¸Šåˆ_ç­†æ•¸", "sum"),
                    ä¸Šåˆå·¥æ™‚_åˆ†é˜=("ä¸Šåˆ_å·¥æ™‚_åˆ†é˜", "sum"),
                    ä¸‹åˆç­†æ•¸=("ä¸‹åˆ_ç­†æ•¸", "sum"),
                    ä¸‹åˆå·¥æ™‚_åˆ†é˜_æ‰£ä¼‘=("ä¸‹åˆ_å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘", "sum"),
                    æ¯”å°æ£šåˆ¥ç­†æ•¸=("æ¯”å°æ£šåˆ¥ç­†æ•¸", "sum"),
                )
            )

            summary["ä¸Šåˆæ•ˆç‡_ä»¶æ¯å°æ™‚"] = summary.apply(lambda r: _eff(int(r["ä¸Šåˆç­†æ•¸"]), int(r["ä¸Šåˆå·¥æ™‚_åˆ†é˜"])), axis=1)
            summary["ä¸‹åˆæ•ˆç‡_ä»¶æ¯å°æ™‚"] = summary.apply(lambda r: _eff(int(r["ä¸‹åˆç­†æ•¸"]), int(r["ä¸‹åˆå·¥æ™‚_åˆ†é˜_æ‰£ä¼‘"])), axis=1)
            summary["ç¸½å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘"] = summary["ä¸Šåˆå·¥æ™‚_åˆ†é˜"].fillna(0).astype(int) + summary["ä¸‹åˆå·¥æ™‚_åˆ†é˜_æ‰£ä¼‘"].fillna(0).astype(int)
            summary["æ•ˆç‡_ä»¶æ¯å°æ™‚"] = summary.apply(lambda r: _eff(int(r["ç¸½ç­†æ•¸"]), int(r["ç¸½å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘"])), axis=1)

            for c in ["ç¸½ç­†æ•¸", "ç¸½å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘", "ä¸Šåˆç­†æ•¸", "ä¸Šåˆå·¥æ™‚_åˆ†é˜", "ä¸‹åˆç­†æ•¸", "ä¸‹åˆå·¥æ™‚_åˆ†é˜_æ‰£ä¼‘", "æ¯”å°æ£šåˆ¥ç­†æ•¸"]:
                summary[c] = summary[c].fillna(0).astype(int)

            summary["æ¯”å°æ£šåˆ¥ç‡"] = summary.apply(
                lambda r: (int(r["æ¯”å°æ£šåˆ¥ç­†æ•¸"]) / int(r["ç¸½ç­†æ•¸"])) if int(r["ç¸½ç­†æ•¸"]) > 0 else 0.0,
                axis=1,
            )

            total_people = int(summary[user_col].nunique())
            met_people = int((summary["æ•ˆç‡_ä»¶æ¯å°æ™‚"] >= float(target_eff)).sum())
            rate = (met_people / total_people) if total_people > 0 else 0.0

            total_match = int(summary["æ¯”å°æ£šåˆ¥ç­†æ•¸"].sum())
            total_cnt = int(summary["ç¸½ç­†æ•¸"].sum())
            match_rate_all = (total_match / total_cnt) if total_cnt > 0 else 0.0

            total_row = {
                user_col: "æ•´é«”åˆè¨ˆ",
                "å°æ‡‰å§“å": "",
                "ç·æ—¥æ•¸": int(summary["ç·æ—¥æ•¸"].sum()),
                "ç¸½ç­†æ•¸": int(summary["ç¸½ç­†æ•¸"].sum()),
                "ç¸½å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘": int(summary["ç¸½å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘"].sum()),
                "ä¸Šåˆç­†æ•¸": int(summary["ä¸Šåˆç­†æ•¸"].sum()),
                "ä¸Šåˆå·¥æ™‚_åˆ†é˜": int(summary["ä¸Šåˆå·¥æ™‚_åˆ†é˜"].sum()),
                "ä¸‹åˆç­†æ•¸": int(summary["ä¸‹åˆç­†æ•¸"].sum()),
                "ä¸‹åˆå·¥æ™‚_åˆ†é˜_æ‰£ä¼‘": int(summary["ä¸‹åˆå·¥æ™‚_åˆ†é˜_æ‰£ä¼‘"].sum()),
                "æ•ˆç‡_ä»¶æ¯å°æ™‚": _eff(int(summary["ç¸½ç­†æ•¸"].sum()), int(summary["ç¸½å·¥æ™‚_åˆ†é˜_æ‰£ä¼‘"].sum())),
                "ä¸Šåˆæ•ˆç‡_ä»¶æ¯å°æ™‚": _eff(int(summary["ä¸Šåˆç­†æ•¸"].sum()), int(summary["ä¸Šåˆå·¥æ™‚_åˆ†é˜"].sum())),
                "ä¸‹åˆæ•ˆç‡_ä»¶æ¯å°æ™‚": _eff(int(summary["ä¸‹åˆç­†æ•¸"].sum()), int(summary["ä¸‹åˆå·¥æ™‚_åˆ†é˜_æ‰£ä¼‘"].sum())),
                "æ¯”å°æ£šåˆ¥ç­†æ•¸": int(total_match),
                "æ¯”å°æ£šåˆ¥ç‡": float(match_rate_all),
            }
            summary_out = pd.concat([summary, pd.DataFrame([total_row])], ignore_index=True)

            # âœ… æ¨ç´ï¼šæ¯äººæ¯æ£šåˆ¥
            shelf_for_group = dt_data["æ£šåˆ¥"].astype(str).str.strip()
            shelf_for_group = shelf_for_group.where(shelf_for_group.ne(""), "æœªæ¯”å°")
            shelf_person_long = (
                dt_data.assign(_æ£šåˆ¥åˆ†é¡=shelf_for_group)
                .groupby([user_col, "å°æ‡‰å§“å", "_æ£šåˆ¥åˆ†é¡"], dropna=False)
                .size()
                .reset_index(name="ç­†æ•¸")
                .rename(columns={"_æ£šåˆ¥åˆ†é¡": "æ£šåˆ¥"})
            )
            if not shelf_person_long.empty:
                shelf_person_pivot = (
                    shelf_person_long.pivot_table(
                        index=[user_col, "å°æ‡‰å§“å"],
                        columns="æ£šåˆ¥",
                        values="ç­†æ•¸",
                        aggfunc="sum",
                        fill_value=0,
                    )
                    .reset_index()
                )
                cols = [c for c in shelf_person_pivot.columns if c not in (user_col, "å°æ‡‰å§“å")]
                cols_sorted = [c for c in cols if c != "æœªæ¯”å°"] + (["æœªæ¯”å°"] if "æœªæ¯”å°" in cols else [])
                shelf_person_pivot = shelf_person_pivot[[user_col, "å°æ‡‰å§“å"] + cols_sorted]
            else:
                shelf_person_pivot = pd.DataFrame()

            # âœ… æ¨ç´ï¼šæ¯äººæ¯å„²ä½é¡å‹
            stype_for_group = dt_data["å„²ä½é¡å‹"].astype(str).str.strip()
            stype_for_group = stype_for_group.where(stype_for_group.ne(""), "æœªåˆ†é¡")
            stype_person_long = (
                dt_data.assign(_å„²ä½é¡å‹åˆ†é¡=stype_for_group)
                .groupby([user_col, "å°æ‡‰å§“å", "_å„²ä½é¡å‹åˆ†é¡"], dropna=False)
                .size()
                .reset_index(name="ç­†æ•¸")
                .rename(columns={"_å„²ä½é¡å‹åˆ†é¡": "å„²ä½é¡å‹"})
            )
            if not stype_person_long.empty:
                stype_person_pivot = (
                    stype_person_long.pivot_table(
                        index=[user_col, "å°æ‡‰å§“å"],
                        columns="å„²ä½é¡å‹",
                        values="ç­†æ•¸",
                        aggfunc="sum",
                        fill_value=0,
                    )
                    .reset_index()
                )
                prefer = ["è¼•å‹æ–™æ¶", "é‡å‹ä½ç©º", "è½åœ°å„²", "é«˜ç©ºå„²", "æœªåˆ†é¡"]
                cols = [c for c in stype_person_pivot.columns if c not in (user_col, "å°æ‡‰å§“å")]
                ordered = [c for c in prefer if c in cols] + [c for c in cols if c not in prefer]
                stype_person_pivot = stype_person_pivot[[user_col, "å°æ‡‰å§“å"] + ordered]
            else:
                stype_person_pivot = pd.DataFrame()

            xlsx_bytes = build_excel_bytes(
                user_col=user_col,
                summary_out=summary_out,
                daily=daily,
                shelf_person_pivot=shelf_person_pivot,
                stype_person_pivot=stype_person_pivot,
                target_eff=float(target_eff),
            )
            xlsx_name = f"{uploaded.name.rsplit('.', 1)[0]}_ä¸Šæ¶ç¸¾æ•ˆ.xlsx"

            st.session_state.putaway_last = {
                "params": current_params,
                "user_col": user_col,
                "summary": summary,
                "target_eff": float(target_eff),
                "top_n": int(top_n),
                "total_people": int(total_people),
                "met_people": int(met_people),
                "rate": float(rate),
                "xlsx_bytes": xlsx_bytes,
                "xlsx_name": xlsx_name,
                "total_match": int(total_match),
                "match_rate_all": float(match_rate_all),
                "shelf_person_pivot": shelf_person_pivot,
                "stype_person_pivot": stype_person_pivot,
            }

    # ======================
    # âœ… é¡¯ç¤ºï¼ˆä¸»ç•«é¢ï¼šåªé¡¯ç¤ºå…©å€‹æ¨ç´è¡¨ï¼‰
    # ======================
    last = st.session_state.putaway_last
    if not last:
        st.info("è«‹å…ˆä¸Šå‚³ä¸Šæ¶ä½œæ¥­åŸå§‹è³‡æ–™ä¸¦é»é¸ã€ŒğŸš€ ç”¢å‡º KPIã€")
        return

    user_col = last["user_col"]
    summary = last["summary"]
    target_eff_show = float(last["target_eff"])
    top_n_show = int(controls.get("top_n", last.get("top_n", 30)))
    total_people = int(last["total_people"])
    met_people = int(last["met_people"])
    rate = float(last["rate"])
    xlsx_bytes = last["xlsx_bytes"]
    xlsx_name = last["xlsx_name"]
    total_match = int(last.get("total_match", 0))
    match_rate_all = float(last.get("match_rate_all", 0.0))

    shelf_person_pivot = last.get("shelf_person_pivot", pd.DataFrame())
    stype_person_pivot = last.get("stype_person_pivot", pd.DataFrame())

    # KPIï¼ˆä¸æ˜¯è¡¨æ ¼ï¼‰
    card_open("ğŸ“Œ ç¸½è¦½ KPI")
    render_kpis([
        KPI("ç¸½äººæ•¸", f"{total_people:,}"),
        KPI("é”æ¨™äººæ•¸", f"{met_people:,}"),
        KPI("é”æ¨™ç‡", f"{rate:.1%}"),
        KPI("é”æ¨™é–€æª»", f"æ•ˆç‡ â‰¥ {int(target_eff_show)}"),
        KPI("æ£šåˆ¥æ¯”å°ç­†æ•¸", f"{total_match:,}"),
        KPI("æ£šåˆ¥æ¯”å°ç‡", f"{match_rate_all:.1%}"),
    ])
    card_close()

    # âœ… åªé¡¯ç¤ºå…©å¼µè¡¨ï¼šå„²ä½é¡å‹æ¨ç´ + æ£šåˆ¥æ¨ç´
    card_open("ğŸ“¦ æ¨ç´è¡¨ï¼ˆæ¯äººä¸€åˆ—ã€æ¯å„²ä½é¡å‹ä¸€æ¬„ï¼‰")
    if stype_person_pivot is None or stype_person_pivot.empty:
        st.info("å°šæœªç”¢ç”Ÿå„²ä½é¡å‹æ¨ç´è¡¨ï¼ˆå¯èƒ½ç„¡æ³•æ“·å–å€ç¢¼3æˆ–è³‡æ–™ç‚ºç©ºï¼‰ã€‚")
    else:
        st.dataframe(stype_person_pivot, use_container_width=True, hide_index=True)
    card_close()

    card_open("ğŸ·ï¸ æ¨ç´è¡¨ï¼ˆæ¯äººä¸€åˆ—ã€æ¯æ£šåˆ¥ä¸€æ¬„ï¼‰")
    if shelf_person_pivot is None or shelf_person_pivot.empty:
        st.info("å°šæœªç”¢ç”Ÿæ£šåˆ¥æ¨ç´è¡¨ï¼ˆå¯èƒ½æœªä¸Šå‚³æ£šåˆ¥ä¸»æª”ï¼Œæˆ–æ¯”å°çµæœç‚ºç©ºï¼‰ã€‚")
    else:
        st.dataframe(shelf_person_pivot, use_container_width=True, hide_index=True)
    card_close()

    # AM/PM åœ–è¡¨ï¼ˆä¸æ˜¯è¡¨æ ¼ï¼‰
    col_l, col_r = st.columns(2)

    with col_l:
        card_open(f"ğŸŒ“ AMï¼ˆä¸Šåˆï¼‰æ•ˆç‡æ’è¡Œï¼ˆTop {top_n_show}ï¼‰")
        am_rank = summary[[user_col, "å°æ‡‰å§“å", "ä¸Šåˆç­†æ•¸", "ä¸Šåˆå·¥æ™‚_åˆ†é˜", "ä¸Šåˆæ•ˆç‡_ä»¶æ¯å°æ™‚"]].copy()
        am_rank = am_rank.rename(columns={"ä¸Šåˆæ•ˆç‡_ä»¶æ¯å°æ™‚": "æ•ˆç‡", "ä¸Šåˆç­†æ•¸": "ç­†æ•¸", "ä¸Šåˆå·¥æ™‚_åˆ†é˜": "å·¥æ™‚"})
        am_rank["å§“å"] = am_rank["å°æ‡‰å§“å"].where(am_rank["å°æ‡‰å§“å"].astype(str).str.len() > 0, am_rank[user_col].astype(str))
        bar_topN(
            am_rank[["å§“å", "æ•ˆç‡", "ç­†æ•¸", "å·¥æ™‚"]],
            x_col="å§“å",
            y_col="æ•ˆç‡",
            hover_cols=["ç­†æ•¸", "å·¥æ™‚"],
            top_n=top_n_show,
            target=float(target_eff_show),
        )
        card_close()

    with col_r:
        card_open(f"ğŸŒ™ PMï¼ˆä¸‹åˆï¼‰æ•ˆç‡æ’è¡Œï¼ˆTop {top_n_show}ï¼‰")
        pm_rank = summary[[user_col, "å°æ‡‰å§“å", "ä¸‹åˆç­†æ•¸", "ä¸‹åˆå·¥æ™‚_åˆ†é˜_æ‰£ä¼‘", "ä¸‹åˆæ•ˆç‡_ä»¶æ¯å°æ™‚"]].copy()
        pm_rank = pm_rank.rename(columns={"ä¸‹åˆæ•ˆç‡_ä»¶æ¯å°æ™‚": "æ•ˆç‡", "ä¸‹åˆç­†æ•¸": "ç­†æ•¸", "ä¸‹åˆå·¥æ™‚_åˆ†é˜_æ‰£ä¼‘": "å·¥æ™‚"})
        pm_rank["å§“å"] = pm_rank["å°æ‡‰å§“å"].where(pm_rank["å°æ‡‰å§“å"].astype(str).str.len() > 0, pm_rank[user_col].astype(str))
        bar_topN(
            pm_rank[["å§“å", "æ•ˆç‡", "ç­†æ•¸", "å·¥æ™‚"]],
            x_col="å§“å",
            y_col="æ•ˆç‡",
            hover_cols=["ç­†æ•¸", "å·¥æ™‚"],
            top_n=top_n_show,
            target=float(target_eff_show),
        )
        card_close()

    download_excel_card(
        xlsx_bytes,
        xlsx_name,
        label="â¬‡ï¸ åŒ¯å‡º KPI å ±è¡¨ï¼ˆExcelï¼šå«ã€ç¸½è¡¨ã€ï¼‰",
    )


if __name__ == "__main__":
    main()
