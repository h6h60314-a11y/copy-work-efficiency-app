# pages/12_è¶Šåº«è¨‚å–®åˆ†æ.py
import io
import re
import pandas as pd
import streamlit as st

from common_ui import inject_logistics_theme, set_page, card_open, card_close

st.set_page_config(page_title="è¶Šåº«è¨‚å–®åˆ†æ", page_icon="ğŸ§¾", layout="wide")
inject_logistics_theme()

# =========================
# Robust reader (Excel/CSV/HTML + å‡ .xls: PROVIDER...)
# =========================
def _decode_text(b: bytes) -> str:
    for enc in ("utf-8-sig", "utf-16", "cp950", "big5", "latin1"):
        try:
            return b.decode(enc)
        except Exception:
            continue
    return b.decode("utf-8", errors="ignore")


def _read_as_html(text: str) -> pd.DataFrame:
    tables = pd.read_html(text)
    if not tables:
        raise ValueError("HTML å…§æ²’æœ‰å¯è¾¨è­˜çš„è¡¨æ ¼")
    return tables[0]


def _read_as_csv(text: str) -> pd.DataFrame:
    # å…ˆçŒœå¸¸è¦‹åˆ†éš”ï¼ˆtab > comma > semicolonï¼‰
    for sep in ("\t", ",", ";"):
        try:
            df = pd.read_csv(io.StringIO(text), sep=sep, engine="python")
            if df.shape[1] >= 2:
                return df
        except Exception:
            pass
    return pd.read_csv(io.StringIO(text), sep=None, engine="python")


def robust_read_upload(uploaded) -> pd.DataFrame:
    """
    è®€å–ä¸Šå‚³æª”ï¼ˆxls/xlsx/csv/htmlï¼‰
    - å…ˆç”¨ Excel è®€
    - è‹¥é‡åˆ°ã€ŒExpected BOF record; found b'PROVIDER'ã€é€™ç¨®å‡ xlsï¼Œ
      æœƒæ”¹ç”¨æ–‡å­—è§£æï¼ˆHTML / CSV / TSVï¼‰
    """
    name = (uploaded.name or "").lower()
    raw_bytes = uploaded.getvalue() if hasattr(uploaded, "getvalue") else uploaded.read()

    # xlsx / xlsm
    if name.endswith((".xlsx", ".xlsm", ".xltx", ".xltm")):
        return pd.read_excel(io.BytesIO(raw_bytes), engine="openpyxl")

    # xls
    if name.endswith(".xls"):
        try:
            return pd.read_excel(io.BytesIO(raw_bytes), engine="xlrd")
        except Exception:
            text = _decode_text(raw_bytes)
            low = text.lower()
            if "<html" in low or "<table" in low:
                return _read_as_html(text)
            return _read_as_csv(text)

    # csv
    if name.endswith(".csv"):
        return _read_as_csv(_decode_text(raw_bytes))

    # html
    if name.endswith((".html", ".htm")):
        return _read_as_html(_decode_text(raw_bytes))

    # å…¶ä»–ï¼šç”¨å…§å®¹çŒœ
    text = _decode_text(raw_bytes)
    low = text.lower()
    if "<html" in low or "<table" in low:
        return _read_as_html(text)
    return _read_as_csv(text)


# =========================
# Business logic
# =========================
NEED_COLS_1 = ["å–®è™Ÿ", "å–®æ“šé¡å‹", "ä½œæ¥­é¡å‹", "æ‡‰ä½œé‡", "å¯¦ä½œé‡"]
NEED_COLS_2 = ["SONO", "CLOSE_USER"]

PATTERN_EXCLUDE = re.compile(r"FT0[3-9]|FT1[0-1]", re.IGNORECASE)


def _normalize_cols(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = df.columns.astype(str).str.strip()
    return df


def _ensure_cols(df: pd.DataFrame, need: list, who: str):
    missing = [c for c in need if c not in df.columns]
    if missing:
        raise KeyError(f"âŒã€Œ{who}ã€ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{missing}")


def compute_crossdock(df1: pd.DataFrame, df2: pd.DataFrame):
    """
    å°é½Šä½ åŸæœ¬ Tkinter è…³æœ¬é‚è¼¯ï¼š
    1) df2: SONO->CLOSE_USER æ˜ å°„åˆ° df1 å–®è™Ÿï¼Œç”Ÿæˆ æ¯”å°å‚™è¨»
    2) å‰”é™¤ æ¯”å°å‚™è¨» å« FT03~FT11
    3) å–®è™Ÿæ¸…ç†ï¼šç§»é™¤ B / C
    4) åªé‡å° å–®æ“šé¡å‹ == 'è¶Šåº«' çµ±è¨ˆï¼š
       - é›¶æ•£/æˆç®±ï¼šæ‡‰ä½œé‡ã€å¯¦ä½œé‡ç¸½å’Œ
       - è¨‚å–®ç­†æ•¸ï¼ˆå–®è™Ÿä¸é‡è¤‡ï¼‰
    """
    df1 = _normalize_cols(df1)
    df2 = _normalize_cols(df2)

    _ensure_cols(df1, NEED_COLS_1, "æª”æ¡ˆâ‘ ï¼ˆå–®æ“šæ˜ç´°ï¼‰")
    _ensure_cols(df2, NEED_COLS_2, "æª”æ¡ˆâ‘¡ï¼ˆå·²çµæ¡ˆæŸ¥è©¢ï¼‰")

    # types
    df1 = df1.copy()
    df2 = df2.copy()

    df1["å–®è™Ÿ"] = df1["å–®è™Ÿ"].astype(str).str.strip()
    df2["SONO"] = df2["SONO"].astype(str).str.strip()

    # map CLOSE_USER
    close_map = df2.set_index("SONO")["CLOSE_USER"]
    df1["æ¯”å°å‚™è¨»"] = df1["å–®è™Ÿ"].map(close_map).fillna("ç„¡å°æ‡‰").astype(str)

    # å‰”é™¤ FT03~FT11
    mask_ex = df1["æ¯”å°å‚™è¨»"].str.contains(PATTERN_EXCLUDE, na=False)
    df1 = df1[~mask_ex].copy()

    # æ¸…ç† B/Cï¼ˆä¸€å®šè¦åœ¨ä¸é‡è¤‡å‰ï¼‰
    df1["å–®è™Ÿ"] = df1["å–®è™Ÿ"].astype(str).str.replace("B", "", regex=False).str.replace("C", "", regex=False)

    # æ•¸å€¼æ¬„ä½è½‰ numeric
    df1["æ‡‰ä½œé‡"] = pd.to_numeric(df1["æ‡‰ä½œé‡"], errors="coerce").fillna(0)
    df1["å¯¦ä½œé‡"] = pd.to_numeric(df1["å¯¦ä½œé‡"], errors="coerce").fillna(0)

    # è¶Šåº«ç¯©é¸
    cond = df1["å–®æ“šé¡å‹"].astype(str).str.strip().eq("è¶Šåº«")
    dfx = df1.loc[cond].copy()

    # çµ±è¨ˆ
    scatter = dfx["ä½œæ¥­é¡å‹"].astype(str).str.strip().eq("é›¶æ•£")
    box = dfx["ä½œæ¥­é¡å‹"].astype(str).str.strip().eq("æˆç®±")

    stats = {
        "è¶Šåº«_é›¶æ•£_æ‡‰ä½œé‡": float(dfx.loc[scatter, "æ‡‰ä½œé‡"].sum()),
        "è¶Šåº«_æˆç®±_æ‡‰ä½œé‡": float(dfx.loc[box, "æ‡‰ä½œé‡"].sum()),
        "è¶Šåº«_é›¶æ•£_å¯¦ä½œé‡": float(dfx.loc[scatter, "å¯¦ä½œé‡"].sum()),
        "è¶Šåº«_æˆç®±_å¯¦ä½œé‡": float(dfx.loc[box, "å¯¦ä½œé‡"].sum()),
        "è¨‚å–®ç­†æ•¸": int(dfx["å–®è™Ÿ"].nunique()),
        "å‰”é™¤ç­†æ•¸_FT03_FT11": int(mask_ex.sum()),
        "è¶Šåº«ç­†æ•¸": int(len(dfx)),
    }

    # æ’å…¥ã€Œæ¯”å°å‚™è¨»ã€åˆ°ç¬¬18æ¬„ï¼ˆ0-based index 17ï¼‰
    cols = list(df1.columns)
    if "æ¯”å°å‚™è¨»" in cols:
        cols.remove("æ¯”å°å‚™è¨»")
        insert_at = 17 if len(cols) >= 17 else len(cols)
        cols.insert(insert_at, "æ¯”å°å‚™è¨»")
        df1 = df1[cols]

    return stats, df1, dfx


def _fmt_num(x: float) -> str:
    try:
        return f"{x:,.0f}" if abs(x - round(x)) < 1e-9 else f"{x:,.2f}"
    except Exception:
        return str(x)


def _to_excel_bytes(df: pd.DataFrame, sheet_name: str = "çµæœ"):
    bio = io.BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name=sheet_name)
    return bio.getvalue()


# =========================
# UI
# =========================
def main():
    set_page("è¶Šåº«è¨‚å–®åˆ†æ", icon="ğŸ§¾", subtitle="ä¸Šå‚³å…©ä»½å ±è¡¨ï½œå‰”é™¤ FT03~FT11ï½œè¶Šåº«(é›¶æ•£/æˆç®±) æ‡‰ä½œ/å¯¦ä½œï½œè¨‚å–®ç­†æ•¸")

    tab_up, tab_res, tab_detail = st.tabs(["ğŸ“Œ ä¸Šå‚³æª”æ¡ˆ", "ğŸ“Š è¨ˆç®—çµæœ", "ğŸ§¾ æ˜ç´°é è¦½/åŒ¯å‡º"])

    with tab_up:
        card_open("ğŸ“Œ ä¸Šå‚³æª”æ¡ˆ")
        st.caption("æª”æ¡ˆâ‘ ï¼šå–®æ“šæ˜ç´°ï¼ˆéœ€å«ï¼šå–®è™Ÿã€å–®æ“šé¡å‹ã€ä½œæ¥­é¡å‹ã€æ‡‰ä½œé‡ã€å¯¦ä½œé‡ï¼‰")
        f1 = st.file_uploader(
            "é¸æ“‡æª”æ¡ˆâ‘ ï¼ˆå–®æ“šæ˜ç´°ï¼‰",
            type=["xlsx", "xlsm", "xls", "csv", "html", "htm"],
            key="f1",
        )
        st.caption("æª”æ¡ˆâ‘¡ï¼šå·²çµæ¡ˆæŸ¥è©¢ï¼ˆéœ€å«ï¼šSONOã€CLOSE_USERï¼‰")
        f2 = st.file_uploader(
            "é¸æ“‡æª”æ¡ˆâ‘¡ï¼ˆå·²çµæ¡ˆæŸ¥è©¢ï¼‰",
            type=["xlsx", "xlsm", "xls", "csv", "html", "htm"],
            key="f2",
        )

        st.markdown("---")
        st.info("è‹¥ä½ çš„ .xls å‡ºç¾ã€ŒPROVIDERã€éŒ¯èª¤ï¼Œä»£è¡¨å®ƒæ˜¯ã€å‡ xlsã€ï¼Œæ­¤é å·²æ”¯æ´è‡ªå‹•æ”¹ç”¨æ–‡å­—/HTML è§£æã€‚")
        card_close()

    # è®€æª”èˆ‡è¨ˆç®—ï¼ˆæœ‰æª”æ‰è·‘ï¼‰
    stats = None
    df_out = None
    dfx = None
    err = None

    if f1 and f2:
        try:
            df1 = robust_read_upload(f1)
            df2 = robust_read_upload(f2)
            stats, df_out, dfx = compute_crossdock(df1, df2)
        except Exception as e:
            err = e

    with tab_res:
        card_open("ğŸ“Š è¨ˆç®—çµæœ")
        if err:
            st.error(f"è®€å–æˆ–è¨ˆç®—å¤±æ•—ï¼š{err}")
        elif not (f1 and f2):
            st.warning("è«‹å…ˆåˆ°ã€Œä¸Šå‚³æª”æ¡ˆã€ä¸Šå‚³å…©ä»½æª”æ¡ˆã€‚")
        else:
            # ç›´å‘å‘ˆç¾ï¼ˆä½ è¦çš„ï¼šæ¯çµ„å…©å€‹æŒ‡æ¨™ç›´å‘ï¼‰
            left, right = st.columns([1, 1], gap="large")

            with left:
                st.markdown("### è¶Šåº«è¨‚å–®é‡")
                st.metric("è¶Šåº«ï¼‹é›¶æ•£ï½œæ‡‰ä½œé‡ç¸½å’Œ", _fmt_num(stats["è¶Šåº«_é›¶æ•£_æ‡‰ä½œé‡"]))
                st.metric("è¶Šåº«ï¼‹æˆç®±ï½œæ‡‰ä½œé‡ç¸½å’Œ", _fmt_num(stats["è¶Šåº«_æˆç®±_æ‡‰ä½œé‡"]))
                st.metric("è¨‚å–®ç­†æ•¸ï¼ˆè¶Šåº«/å–®è™Ÿä¸é‡è¤‡ï¼‰", _fmt_num(stats["è¨‚å–®ç­†æ•¸"]))

            with right:
                st.markdown("### å¯¦ä½œ/æ¸…ç†ç‹€æ…‹")
                st.metric("è¶Šåº«ï¼‹é›¶æ•£ï½œå¯¦ä½œé‡ç¸½å’Œ", _fmt_num(stats["è¶Šåº«_é›¶æ•£_å¯¦ä½œé‡"]))
                st.metric("è¶Šåº«ï¼‹æˆç®±ï½œå¯¦ä½œé‡ç¸½å’Œ", _fmt_num(stats["è¶Šåº«_æˆç®±_å¯¦ä½œé‡"]))
                st.metric("å·²å‰”é™¤ç­†æ•¸ï¼ˆFT03~FT11ï¼‰", _fmt_num(stats["å‰”é™¤ç­†æ•¸_FT03_FT11"]))

            st.caption(f"è¶Šåº«æ˜ç´°ç­†æ•¸ï¼š{stats['è¶Šåº«ç­†æ•¸']:,}ï¼ˆå‰”é™¤å¾Œï¼‰")

        card_close()

    with tab_detail:
        card_open("ğŸ§¾ æ˜ç´°é è¦½/åŒ¯å‡º")
        if err:
            st.error(f"è®€å–æˆ–è¨ˆç®—å¤±æ•—ï¼š{err}")
        elif not (f1 and f2):
            st.warning("è«‹å…ˆåˆ°ã€Œä¸Šå‚³æª”æ¡ˆã€ä¸Šå‚³å…©ä»½æª”æ¡ˆã€‚")
        else:
            st.markdown("#### âœ… å‰”é™¤å¾Œæ˜ç´°ï¼ˆå·²åŠ å…¥ï¼šæ¯”å°å‚™è¨»ï¼‰")
            st.dataframe(df_out, use_container_width=True, height=420)

            c1, c2 = st.columns([1, 1], gap="large")
            with c1:
                st.markdown("#### âœ… åªçœ‹ã€è¶Šåº«ã€æ˜ç´°")
                st.dataframe(dfx, use_container_width=True, height=420)

            with c2:
                st.markdown("#### ğŸ’¾ åŒ¯å‡º Excel")
                excel_bytes = _to_excel_bytes(df_out, sheet_name="å‰”é™¤å¾Œæ˜ç´°")
                st.download_button(
                    "ä¸‹è¼‰ï¼šå‰”é™¤å¾Œæ˜ç´°.xlsx",
                    data=excel_bytes,
                    file_name="è¶Šåº«è¨‚å–®åˆ†æ_å‰”é™¤å¾Œæ˜ç´°.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                )

        card_close()


if __name__ == "__main__":
    main()
