# pages/20_é€²è²¨èª²é©—æ”¶é‡é«”.py
# -*- coding: utf-8 -*-
from __future__ import annotations

import os
from io import BytesIO
from typing import Dict, Tuple, Optional, List

import pandas as pd
import streamlit as st

from common_ui import inject_logistics_theme, set_page, card_open, card_close

pd.options.display.max_columns = 200

PRODUCT_COL_CANDIDATES = ["å•†å“", "å•†å“ä»£è™Ÿ", "å•†å“ç·¨è™Ÿ", "å“è™Ÿ", "å“å", "å“è™Ÿå“å"]


def _safe_sheet_name(name: str) -> str:
    n = str(name).replace("/", "_").replace("\\", "_").strip()
    return (n[:31] if len(n) > 31 else n) or "Sheet"


def find_product_col(columns) -> Optional[str]:
    cols = [str(c).strip() for c in columns]
    for cand in PRODUCT_COL_CANDIDATES:
        if cand in cols:
            return cand
    for c in cols:
        if ("å•†å“" in c) or ("å“è™Ÿ" in c):
            return c
    return None


def _read_excel_sheets_from_bytes(file_bytes: bytes, ext: str) -> Dict[str, pd.DataFrame]:
    bio = BytesIO(file_bytes)

    if ext in (".xlsx", ".xlsm", ".xltx", ".xltm"):
        try:
            return pd.read_excel(bio, sheet_name=None, engine="openpyxl")
        except Exception:
            bio.seek(0)
            return pd.read_excel(bio, sheet_name=None)

    if ext == ".xls":
        try:
            return pd.read_excel(bio, sheet_name=None, engine="xlrd")
        except Exception as e:
            raise RuntimeError("ç›®å‰ç’°å¢ƒå¯èƒ½æœªå®‰è£ xlrdï¼Œå°è‡´ .xls ç„¡æ³•è®€å–ï¼›è«‹å…ˆå¦å­˜ç‚º .xlsx å†ä¸Šå‚³ã€‚") from e

    try:
        return pd.read_excel(bio, sheet_name=None, engine="openpyxl")
    except Exception:
        bio.seek(0)
        return pd.read_excel(bio, sheet_name=None)


def _read_csv_from_bytes_auto(file_bytes: bytes) -> pd.DataFrame:
    last_err = None
    for enc in ("utf-8-sig", "utf-8", "cp950", "big5"):
        try:
            return pd.read_csv(BytesIO(file_bytes), encoding=enc, low_memory=False)
        except Exception as e:
            last_err = e
    raise RuntimeError(f"CSV/TXT è®€å–å¤±æ•—ï¼Œå·²å˜—è©¦ utf-8-sig/utf-8/cp950/big5ï¼š{last_err}")


def process_tables(
    tables: Dict[str, pd.DataFrame]
) -> Tuple[Dict[str, pd.DataFrame], pd.DataFrame, pd.DataFrame, dict]:
    filtered: Dict[str, pd.DataFrame] = {}

    total_before = 0
    total_after = 0

    per_sheet_unique: List[dict] = []
    all_products: List[pd.Series] = []

    for name, df in tables.items():
        df = df.copy()
        df.columns = [str(c).strip() for c in df.columns]

        if "åˆ°" not in df.columns:
            filtered[name] = df.iloc[0:0].copy()
            per_sheet_unique.append(
                {
                    "å·¥ä½œè¡¨": _safe_sheet_name(name),
                    "ä½¿ç”¨å•†å“æ¬„ä½": "",
                    "åŸå§‹ç­†æ•¸": int(len(df)),
                    "ä¿ç•™ç­†æ•¸(åˆ°=QC)": 0,
                    "å”¯ä¸€å•†å“æ•¸": 0,
                }
            )
            continue

        total_before += len(df)

        mask = df["åˆ°"].astype(str).str.strip().str.upper().eq("QC")
        out_df = df.loc[mask].reset_index(drop=True)

        total_after += len(out_df)
        filtered[name] = out_df

        prod_col = find_product_col(out_df.columns)
        if prod_col and not out_df.empty:
            s = out_df[prod_col].astype(str).str.strip()
            uniq_cnt = int(s.nunique(dropna=True))
            all_products.append(s)
        else:
            uniq_cnt = 0

        per_sheet_unique.append(
            {
                "å·¥ä½œè¡¨": _safe_sheet_name(name),
                "ä½¿ç”¨å•†å“æ¬„ä½": prod_col or "",
                "åŸå§‹ç­†æ•¸": int(len(df)),
                "ä¿ç•™ç­†æ•¸(åˆ°=QC)": int(len(out_df)),
                "å”¯ä¸€å•†å“æ•¸": int(uniq_cnt),
            }
        )

    if all_products:
        overall_unique_products = int(pd.concat(all_products, ignore_index=True).nunique(dropna=True))
    else:
        overall_unique_products = 0

    summary_df = pd.DataFrame(
        {
            "é …ç›®": ["åŸå§‹ç­†æ•¸", "ä¿ç•™ç­†æ•¸(åˆ°=QC)", "åˆªé™¤ç­†æ•¸", "å…¨æª”å”¯ä¸€å•†å“ç¸½æ•¸"],
            "æ•¸é‡": [
                int(total_before),
                int(total_after),
                int(total_before - total_after),
                int(overall_unique_products),
            ],
        }
    )

    per_sheet_df = pd.DataFrame(per_sheet_unique)[
        ["å·¥ä½œè¡¨", "ä½¿ç”¨å•†å“æ¬„ä½", "åŸå§‹ç­†æ•¸", "ä¿ç•™ç­†æ•¸(åˆ°=QC)", "å”¯ä¸€å•†å“æ•¸"]
    ]

    stats = {
        "total_before": int(total_before),
        "total_after": int(total_after),  # ITEM
        "overall_unique_products": int(overall_unique_products),  # SKU
    }
    return filtered, summary_df, per_sheet_df, stats


def build_output_excel_bytes(
    original_tables: Dict[str, pd.DataFrame],
    filtered_tables: Dict[str, pd.DataFrame],
    summary_df: pd.DataFrame,
    per_sheet_df: pd.DataFrame,
) -> bytes:
    out = BytesIO()
    with pd.ExcelWriter(out, engine="openpyxl") as writer:
        for name, fdf in filtered_tables.items():
            safe_name = _safe_sheet_name(name)
            orig_cols = list(original_tables[name].columns) if name in original_tables else list(fdf.columns)
            if fdf.empty:
                pd.DataFrame(columns=orig_cols).to_excel(writer, sheet_name=safe_name, index=False)
            else:
                fdf.to_excel(writer, sheet_name=safe_name, index=False)

        summary_df.to_excel(writer, sheet_name="éæ¿¾çµ±è¨ˆ", index=False)
        per_sheet_df.to_excel(writer, sheet_name="å”¯ä¸€å•†å“çµ±è¨ˆ", index=False)

    out.seek(0)
    return out.read()


def _kpi_text(title: str, value: int):
    # âœ… ç´”æ–‡å­—ã€ç„¡å¡ç‰‡ã€ç›´å‘
    st.markdown(f"**{title}**")
    st.markdown(f"<div style='font-size:24px; font-weight:900; line-height:1.1; margin-top:2px; margin-bottom:12px;'>{value:,}</div>", unsafe_allow_html=True)


# =========================
# UI
# =========================
inject_logistics_theme()
set_page("é€²è²¨èª²ï½œé©—æ”¶é‡é«”", icon="âœ…", subtitle="åªä¿ç•™ã€Œåˆ°=QCã€ï½œSKU(å”¯ä¸€å•†å“)ï½œITEM(ç­†æ•¸)ï½œè¼¸å‡ºExcel")

card_open("âœ… é©—æ”¶é‡é«”ï¼ˆåˆ°=QCï¼‰")

up = st.file_uploader(
    "ä¸Šå‚³æª”æ¡ˆï¼ˆExcel / CSV / TXTï¼‰",
    type=["xlsx", "xlsm", "xltx", "xltm", "xls", "csv", "txt"],
    accept_multiple_files=False,
)

st.markdown("---")

if up is None:
    st.info("è«‹å…ˆä¸Šå‚³æª”æ¡ˆã€‚")
    card_close()
    st.stop()

filename = up.name
base, ext = os.path.splitext(filename)
ext = ext.lower()

run = st.button("é–‹å§‹ç”¢å‡º", type="primary")

if not run:
    card_close()
    st.stop()

# è®€æª”
try:
    file_bytes = up.getvalue()
    if ext in (".csv", ".txt"):
        df = _read_csv_from_bytes_auto(file_bytes)
        tables = {"CSV": df}
    else:
        tables = _read_excel_sheets_from_bytes(file_bytes, ext)
except Exception as e:
    st.error(f"è®€æª”å¤±æ•—ï¼š{e}")
    card_close()
    st.stop()

# è™•ç†
try:
    filtered, summary_df, per_sheet_df, stats = process_tables(tables)
except Exception as e:
    st.error(f"è™•ç†å¤±æ•—ï¼š{e}")
    card_close()
    st.stop()

# âœ… KPIï¼šä¸è¦å¡ç‰‡æ¨¡å¼ï¼Œç´”æ–‡å­—ç›´å‘
st.markdown("### é©—æ”¶é‡é«”")
_kpi_text("SKUï¼ˆå…¨æª”å”¯ä¸€å•†å“ï¼‰", stats["overall_unique_products"])
_kpi_text("ITEMï¼ˆåˆ°=QC ç­†æ•¸ï¼‰", stats["total_after"])
_kpi_text("åŸå§‹ç¸½ç­†æ•¸", stats["total_before"])

st.markdown("### éæ¿¾çµ±è¨ˆ")
st.dataframe(summary_df, use_container_width=True, hide_index=True)

st.markdown("### å”¯ä¸€å•†å“çµ±è¨ˆï¼ˆé€è¡¨ï¼‰")
st.dataframe(per_sheet_df, use_container_width=True, hide_index=True)

with st.expander("ğŸ” é è¦½ï¼šéæ¿¾å¾Œæ˜ç´°ï¼ˆæ¯å¼µè¡¨å‰ 200 ç­†ï¼‰", expanded=False):
    for sheet_name, df in filtered.items():
        st.markdown(f"**{_safe_sheet_name(sheet_name)}**ï¼ˆ{len(df):,} ç­†ï¼‰")
        st.dataframe(df.head(200), use_container_width=True, hide_index=True)

# è¼¸å‡º
try:
    out_bytes = build_output_excel_bytes(tables, filtered, summary_df, per_sheet_df)
except Exception as e:
    st.error(f"å¯«æª”å¤±æ•—ï¼š{e}")
    card_close()
    st.stop()

out_name = f"{base}_åªä¿ç•™åˆ°QC.xlsx"
st.download_button(
    "â¬‡ï¸ ä¸‹è¼‰è¼¸å‡º Excel",
    data=out_bytes,
    file_name=out_name,
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
)

card_close()
