# pages/20_é€²è²¨èª²é©—æ”¶é‡é«”.py
# -*- coding: utf-8 -*-
"""
åŠŸèƒ½ï¼š
1) åªä¿ç•™æ¬„ä½ã€Œåˆ°ã€=ã€ŒQCã€çš„è³‡æ–™ï¼ˆå¤šå·¥ä½œè¡¨æ”¯æ´ï¼‰
2) è¨ˆç®—ä¸é‡è¤‡çš„å•†å“æ•¸ï¼ˆå„å·¥ä½œè¡¨èˆ‡å…¨æª”åˆè¨ˆï¼‰
3) è¼¸å‡ºæ–°æª”ï¼šå„è¡¨éæ¿¾å¾Œæ˜ç´° +ã€Œéæ¿¾çµ±è¨ˆã€+ã€Œå”¯ä¸€å•†å“çµ±è¨ˆã€

éƒ¨ç½²ç‰ˆä½¿ç”¨æ–¹å¼ï¼š
- ä¸Šå‚³ Excel/CSV/TXT â†’ ç”¢å‡º â†’ ä¸‹è¼‰
"""

from __future__ import annotations

import os
from io import BytesIO
from typing import Dict, Tuple, Optional, List

import pandas as pd
import streamlit as st

from common_ui import inject_logistics_theme, set_page, card_open, card_close

pd.options.display.max_columns = 200

# ä½ å¸¸è¦‹çš„å•†å“æ¬„ä½åç¨±å€™é¸ï¼ˆä¾åºå˜—è©¦ï¼‰
PRODUCT_COL_CANDIDATES = ["å•†å“", "å•†å“ä»£è™Ÿ", "å•†å“ç·¨è™Ÿ", "å“è™Ÿ", "å“å", "å“è™Ÿå“å"]


def _safe_sheet_name(name: str) -> str:
    n = str(name).replace("/", "_").replace("\\", "_").strip()
    return (n[:31] if len(n) > 31 else n) or "Sheet"


def find_product_col(columns) -> Optional[str]:
    cols = [str(c).strip() for c in columns]
    for cand in PRODUCT_COL_CANDIDATES:
        if cand in cols:
            return cand
    # å¯¬é¬†ï¼šæ‰¾å«ã€Œå•†å“ã€ã€Œå“è™Ÿã€é—œéµå­—
    for c in cols:
        if ("å•†å“" in c) or ("å“è™Ÿ" in c):
            return c
    return None


def _read_excel_sheets_from_bytes(file_bytes: bytes, ext: str) -> Dict[str, pd.DataFrame]:
    """
    å›å‚³ï¼š{sheet_name: DataFrame}
    """
    bio = BytesIO(file_bytes)

    if ext in (".xlsx", ".xlsm", ".xltx", ".xltm"):
        try:
            return pd.read_excel(bio, sheet_name=None, engine="openpyxl")
        except Exception:
            bio.seek(0)
            return pd.read_excel(bio, sheet_name=None)

    if ext == ".xls":
        # éƒ¨ç½²ç’°å¢ƒå¸¸è¦‹æ²’æœ‰ xlrdï¼›çµ¦æ¸…æ¥šæç¤º
        try:
            return pd.read_excel(bio, sheet_name=None, engine="xlrd")
        except Exception as e:
            raise RuntimeError("ç›®å‰ç’°å¢ƒå¯èƒ½æœªå®‰è£ xlrdï¼Œå°è‡´ .xls ç„¡æ³•è®€å–ï¼›è«‹å…ˆå¦å­˜ç‚º .xlsx å†ä¸Šå‚³ã€‚") from e

    # å…¶ä»–å°±å…ˆç•¶ excel è©¦
    try:
        return pd.read_excel(bio, sheet_name=None, engine="openpyxl")
    except Exception:
        bio.seek(0)
        return pd.read_excel(bio, sheet_name=None)


def _read_csv_from_bytes_auto(file_bytes: bytes) -> pd.DataFrame:
    """
    ä¸é¡¯ç¤ºç·¨ç¢¼é¸æ“‡ï¼Œæ”¹ç”¨è‡ªå‹•å˜—è©¦å¸¸è¦‹ç·¨ç¢¼ã€‚
    """
    last_err = None
    for enc in ("utf-8-sig", "utf-8", "cp950", "big5"):
        try:
            return pd.read_csv(BytesIO(file_bytes), encoding=enc, low_memory=False)
        except Exception as e:
            last_err = e
            continue
    raise RuntimeError(f"CSV/TXT è®€å–å¤±æ•—ï¼Œå·²å˜—è©¦ utf-8-sig/utf-8/cp950/big5ï¼š{last_err}")


def process_tables(
    tables: Dict[str, pd.DataFrame]
) -> Tuple[Dict[str, pd.DataFrame], pd.DataFrame, pd.DataFrame, dict]:
    """
    tables: {sheet_name: df}
    å›å‚³ï¼š
      filtered_tables: {sheet_name: filtered_df}
      summary_df: éæ¿¾çµ±è¨ˆ
      per_sheet_df: å”¯ä¸€å•†å“çµ±è¨ˆ
      stats: dict(total_before, total_after, overall_unique_products)
    """
    filtered: Dict[str, pd.DataFrame] = {}

    total_before = 0
    total_after = 0

    per_sheet_unique: List[dict] = []
    all_products: List[pd.Series] = []

    for name, df in tables.items():
        df = df.copy()
        df.columns = [str(c).strip() for c in df.columns]

        # æ²’æœ‰ã€Œåˆ°ã€æ¬„ä½ï¼šç•¶ä½œ 0 ç­†ï¼ˆä»è¼¸å‡ºåŒæ¬„ä½çš„ç©ºè¡¨ï¼‰
        if "åˆ°" not in df.columns:
            filtered[name] = df.iloc[0:0].copy()
            per_sheet_unique.append(
                {
                    "å·¥ä½œè¡¨": _safe_sheet_name(name),
                    "ä½¿ç”¨å•†å“æ¬„ä½": "",
                    "åŸå§‹ç­†æ•¸": int(len(df)),
                    "ä¿ç•™ç­†æ•¸(åˆ°=QC)": 0,
                    "å”¯ä¸€å•†å“æ•¸": 0,
                }
            )
            continue

        total_before += len(df)

        mask = df["åˆ°"].astype(str).str.strip().str.upper().eq("QC")
        out_df = df.loc[mask].reset_index(drop=True)

        total_after += len(out_df)
        filtered[name] = out_df

        prod_col = find_product_col(out_df.columns)
        if prod_col and not out_df.empty:
            s = out_df[prod_col].astype(str).str.strip()
            uniq_cnt = int(s.nunique(dropna=True))
            all_products.append(s)
        else:
            uniq_cnt = 0

        per_sheet_unique.append(
            {
                "å·¥ä½œè¡¨": _safe_sheet_name(name),
                "ä½¿ç”¨å•†å“æ¬„ä½": prod_col or "",
                "åŸå§‹ç­†æ•¸": int(len(df)),
                "ä¿ç•™ç­†æ•¸(åˆ°=QC)": int(len(out_df)),
                "å”¯ä¸€å•†å“æ•¸": int(uniq_cnt),
            }
        )

    if all_products:
        overall_unique_products = int(pd.concat(all_products, ignore_index=True).nunique(dropna=True))
    else:
        overall_unique_products = 0

    summary_df = pd.DataFrame(
        {
            "é …ç›®": ["åŸå§‹ç­†æ•¸", "ä¿ç•™ç­†æ•¸(åˆ°=QC)", "åˆªé™¤ç­†æ•¸", "å…¨æª”å”¯ä¸€å•†å“ç¸½æ•¸"],
            "æ•¸é‡": [
                int(total_before),
                int(total_after),
                int(total_before - total_after),
                int(overall_unique_products),
            ],
        }
    )

    per_sheet_df = pd.DataFrame(per_sheet_unique)[
        ["å·¥ä½œè¡¨", "ä½¿ç”¨å•†å“æ¬„ä½", "åŸå§‹ç­†æ•¸", "ä¿ç•™ç­†æ•¸(åˆ°=QC)", "å”¯ä¸€å•†å“æ•¸"]
    ]

    stats = {
        "total_before": int(total_before),
        "total_after": int(total_after),  # ITEM
        "overall_unique_products": int(overall_unique_products),  # SKU
    }
    return filtered, summary_df, per_sheet_df, stats


def build_output_excel_bytes(
    original_tables: Dict[str, pd.DataFrame],
    filtered_tables: Dict[str, pd.DataFrame],
    summary_df: pd.DataFrame,
    per_sheet_df: pd.DataFrame,
) -> bytes:
    """
    ç”¢å‡º Excel bytesï¼ˆå„sheetéæ¿¾å¾Œ + éæ¿¾çµ±è¨ˆ + å”¯ä¸€å•†å“çµ±è¨ˆï¼‰
    """
    out = BytesIO()
    with pd.ExcelWriter(out, engine="openpyxl") as writer:
        for name, fdf in filtered_tables.items():
            safe_name = _safe_sheet_name(name)

            orig_cols = list(original_tables[name].columns) if name in original_tables else list(fdf.columns)
            if fdf.empty:
                pd.DataFrame(columns=orig_cols).to_excel(writer, sheet_name=safe_name, index=False)
            else:
                fdf.to_excel(writer, sheet_name=safe_name, index=False)

        summary_df.to_excel(writer, sheet_name="éæ¿¾çµ±è¨ˆ", index=False)
        per_sheet_df.to_excel(writer, sheet_name="å”¯ä¸€å•†å“çµ±è¨ˆ", index=False)

    out.seek(0)
    return out.read()


def _kpi_stack(title: str, value: int):
    st.markdown(
        f"""
<div style="
  padding: 10px 12px;
  border: 1px solid rgba(15,23,42,0.12);
  border-radius: 12px;
  background: rgba(255,255,255,0.75);
  margin: 8px 0;
">
  <div style="font-weight: 850; color: rgba(15,23,42,0.70); font-size: 13px; line-height: 1.2;">
    {title}
  </div>
  <div style="font-weight: 950; color: rgba(15,23,42,0.92); font-size: 22px; margin-top: 6px; line-height: 1;">
    {value:,}
  </div>
</div>
""",
        unsafe_allow_html=True,
    )


# =========================
# Page UI
# =========================
inject_logistics_theme()
set_page("é€²è²¨èª²ï½œé©—æ”¶é‡é«”", icon="âœ…", subtitle="åªä¿ç•™ã€Œåˆ°=QCã€ï½œSKU(å”¯ä¸€å•†å“)ï½œITEM(ç­†æ•¸)ï½œè¼¸å‡ºExcel")

card_open("âœ… é©—æ”¶é‡é«”ï¼ˆåˆ°=QCï¼‰")

up = st.file_uploader(
    "ä¸Šå‚³æª”æ¡ˆï¼ˆExcel / CSV / TXTï¼‰",
    type=["xlsx", "xlsm", "xltx", "xltm", "xls", "csv", "txt"],
    accept_multiple_files=False,
)

st.markdown("---")

if up is None:
    st.info("è«‹å…ˆä¸Šå‚³æª”æ¡ˆã€‚")
    card_close()
    st.stop()

filename = up.name
base, ext = os.path.splitext(filename)
ext = ext.lower()

run = st.button("é–‹å§‹ç”¢å‡º", type="primary")  # âœ… æ”¹å­—

if not run:
    card_close()
    st.stop()

# 1) è®€æª”
try:
    file_bytes = up.getvalue()
    if ext in (".csv", ".txt"):
        df = _read_csv_from_bytes_auto(file_bytes)  # âœ… è‡ªå‹•ç·¨ç¢¼ï¼Œä¸é¡¯ç¤ºé¸æ“‡
        tables = {"CSV": df}
    else:
        tables = _read_excel_sheets_from_bytes(file_bytes, ext)
except Exception as e:
    st.error(f"è®€æª”å¤±æ•—ï¼š{e}")
    card_close()
    st.stop()

# 2) è™•ç†
try:
    filtered, summary_df, per_sheet_df, stats = process_tables(tables)
except Exception as e:
    st.error(f"è™•ç†å¤±æ•—ï¼š{e}")
    card_close()
    st.stop()

# 3) KPI ç›´å‘é¡¯ç¤ºï¼ˆä½ è¦çš„æ¨£å¼ï¼‰
_kpi_stack("SKUï¼ˆå…¨æª”å”¯ä¸€å•†å“ï¼‰", stats["overall_unique_products"])
_kpi_stack("ITEMï¼ˆåˆ°=QC ç­†æ•¸ï¼‰", stats["total_after"])
_kpi_stack("åŸå§‹ç¸½ç­†æ•¸", stats["total_before"])

st.markdown("### éæ¿¾çµ±è¨ˆ")
st.dataframe(summary_df, use_container_width=True, hide_index=True)

st.markdown("### å”¯ä¸€å•†å“çµ±è¨ˆï¼ˆé€è¡¨ï¼‰")
st.dataframe(per_sheet_df, use_container_width=True, hide_index=True)

with st.expander("ğŸ” é è¦½ï¼šéæ¿¾å¾Œæ˜ç´°ï¼ˆæ¯å¼µè¡¨å‰ 200 ç­†ï¼‰", expanded=False):
    for sheet_name, df in filtered.items():
        st.markdown(f"**{_safe_sheet_name(sheet_name)}**ï¼ˆ{len(df):,} ç­†ï¼‰")
        st.dataframe(df.head(200), use_container_width=True, hide_index=True)

# 4) ç”¢å‡º Excel
try:
    out_bytes = build_output_excel_bytes(tables, filtered, summary_df, per_sheet_df)
except Exception as e:
    st.error(f"å¯«æª”å¤±æ•—ï¼š{e}")
    card_close()
    st.stop()

out_name = f"{base}_åªä¿ç•™åˆ°QC.xlsx"
st.download_button(
    "â¬‡ï¸ ä¸‹è¼‰è¼¸å‡º Excel",
    data=out_bytes,
    file_name=out_name,
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
)

card_close()
