# pages/4_å„²ä½ä½¿ç”¨ç‡.py
# -*- coding: utf-8 -*-
"""
4_å„²ä½ä½¿ç”¨ç‡ï¼ˆéƒ¨ç½²ç‰ˆ / Streamlitï¼‰

âœ… æœ¬ç‰ˆèª¿æ•´ï¼ˆä¾ä½ æœ€æ–°è¦æ±‚ï¼‰ï¼š
- âŒ ä¸å†åš å€(æº«å±¤) å¤§/ä¸­/å°
- âœ… åªè¨ˆç®— 4 é¡ï¼šè¼•å‹æ–™æ¶ã€é‡å‹ä½ç©ºã€è½åœ°å„²ã€é«˜ç©ºå„²ï¼ˆå€ç¢¼ â†’ å„²ä½é¡å‹ï¼‰
- âœ… åˆ†é¡å”¯ä¸€ä½¿ç”¨ STORAGE_TYPE_ZONES
"""

import io
import os
import re
import warnings

import pandas as pd
import streamlit as st

warnings.filterwarnings("ignore")

# ---- å¥—ç”¨å¹³å°é¢¨æ ¼ï¼ˆæœ‰å°±ç”¨ï¼Œæ²’æœ‰å°±é€€å›åŸç”Ÿï¼‰----
try:
    from common_ui import inject_logistics_theme, set_page, card_open, card_close

    HAS_COMMON_UI = True
except Exception:
    HAS_COMMON_UI = False


# =========================================================
# âœ… å”¯ä¸€åˆ†é¡é‚è¼¯ï¼šå€ç¢¼ â†’ å„²ä½é¡å‹ï¼ˆä½ æŒ‡å®šï¼‰
# =========================================================
STORAGE_TYPE_ZONES = {
    "è¼•å‹æ–™æ¶": ["001", "002", "003", "017", "016"],
    "è½åœ°å„²": ["014", "018", "019", "020", "010", "081", "401", "402", "403", "015"],
    "é‡å‹ä½ç©º": ["011", "012", "013", "031", "032", "033", "034", "035", "036", "037", "038"],
    "é«˜ç©ºå„²": [
        "021", "022", "023",
        "041", "042", "043",
        "051", "052", "053", "054", "055", "056", "057",
        "301", "302", "303", "304", "305", "306",
    ],
}
_STORAGE_TYPE_SETS = {k: set(v) for k, v in STORAGE_TYPE_ZONES.items()}
TYPE_ORDER = ["è¼•å‹æ–™æ¶", "è½åœ°å„²", "é‡å‹ä½ç©º", "é«˜ç©ºå„²", "æœªçŸ¥"]


# =========================
# UIï¼šç¸®å°ç‰ˆï¼ˆæ¯”ç…§ 18ï¼‰
# =========================
def inject_compact_css():
    st.markdown(
        r"""
<style>
html, body, [class*="css"]{ font-size: 14px !important; }
.block-container{ padding-top: .85rem !important; padding-bottom: 1.15rem !important; }
h1{ font-size: 1.50rem !important; margin: .15rem 0 .35rem !important; }
h2{ font-size: 1.12rem !important; margin: .35rem 0 .20rem !important; }
h3{ font-size: 1.00rem !important; margin: .28rem 0 .12rem !important; }
p, li{ line-height: 1.45 !important; }
div[data-testid="stMetric"]{ padding: 6px 10px !important; }
div[data-testid="stMetric"] label{ font-size: 12px !important; }
div[data-testid="stMetric"] div{ font-size: 20px !important; }
div[data-testid="stDataFrame"]{ margin-top: .15rem !important; }
</style>
""",
        unsafe_allow_html=True,
    )


def _spacer(px: int = 10):
    st.markdown(f"<div style='height:{px}px'></div>", unsafe_allow_html=True)


# =========================
# è®€æª”ï¼šæ”¯æ´ xlsb
# =========================
def detect_sheet_for_column(xls: pd.ExcelFile, must_have: str, engine: str | None = None) -> str:
    for name in xls.sheet_names:
        try:
            df0 = pd.read_excel(xls, sheet_name=name, nrows=0, engine=engine)
            if must_have in df0.columns:
                return name
        except Exception:
            continue
    return xls.sheet_names[0]


def robust_read_uploaded(uploaded) -> tuple[pd.DataFrame, str]:
    filename = uploaded.name
    ext = os.path.splitext(filename)[1].lower()
    data = uploaded.getvalue()
    bio = io.BytesIO(data)

    if ext == ".csv":
        df = pd.read_csv(bio, encoding="utf-8-sig")
        return df, "CSV"

    if ext == ".xlsb":
        xls = pd.ExcelFile(bio, engine="pyxlsb")
        sheet = None
        for key in ["æ£šåˆ¥", "å€(æº«å±¤)"]:
            candidate = detect_sheet_for_column(xls, key, engine="pyxlsb")
            try:
                cols = pd.read_excel(xls, sheet_name=candidate, nrows=0, engine="pyxlsb").columns
                if key in cols:
                    sheet = candidate
                    break
            except Exception:
                pass
        if sheet is None:
            sheet = xls.sheet_names[0]
        df = pd.read_excel(xls, sheet_name=sheet, engine="pyxlsb")
        return df, sheet

    if ext in (".xlsx", ".xlsm", ".xltx", ".xltm"):
        engine = "openpyxl"
    elif ext == ".xls":
        engine = "xlrd"
    else:
        raise ValueError(f"ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼ï¼š{ext}")

    xls = pd.ExcelFile(bio, engine=engine)
    sheet = None
    for key in ["æ£šåˆ¥", "å€(æº«å±¤)"]:
        candidate = detect_sheet_for_column(xls, key, engine=None)
        try:
            cols = pd.read_excel(xls, sheet_name=candidate, nrows=0).columns
            if key in cols:
                sheet = candidate
                break
        except Exception:
            pass

    if sheet is None:
        sheet = xls.sheet_names[0]

    df = pd.read_excel(xls, sheet_name=sheet)
    return df, sheet


# =========================
# é€šç”¨ï¼šæŠ“ 3 ç¢¼å€ç¢¼ + åˆ†é¡
# =========================
def _to_zone3(x) -> str:
    if x is None or (isinstance(x, float) and pd.isna(x)):
        return ""
    s = str(x).strip()
    m = re.search(r"\d{3}", s)
    if m:
        return m.group(0)
    s = re.sub(r"\D", "", s)
    return s.zfill(3) if s else ""


def classify_storage_type(zone_like_value) -> str:
    """å€ç¢¼ â†’ å„²ä½é¡å‹ï¼ˆå”¯ä¸€é‚è¼¯ï¼šSTORAGE_TYPE_ZONESï¼‰"""
    z = _to_zone3(zone_like_value)
    if not z:
        return "æœªçŸ¥"
    for k in ["è¼•å‹æ–™æ¶", "è½åœ°å„²", "é‡å‹ä½ç©º", "é«˜ç©ºå„²"]:
        if z in _STORAGE_TYPE_SETS[k]:
            return k
    return "æœªçŸ¥"


# =========================
# è¨ˆç®—ï¼šä¾ 4 é¡å„²ä½é¡å‹å½™ç¸½ï¼ˆæœ‰æ•ˆ/å·²ç”¨/æœªç”¨/ä½¿ç”¨ç‡ï¼‰
# =========================
def _safe_sum(s: pd.Series) -> float:
    return pd.to_numeric(s, errors="coerce").fillna(0).sum()


def calc_util_by_storage_type(df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    """
    å›å‚³ï¼š
    - df_utilï¼šå››é¡ + ç¸½è¨ˆï¼ˆæœ‰æ•ˆè²¨ä½/å·²ä½¿ç”¨/æœªä½¿ç”¨/ä½¿ç”¨ç‡ï¼‰
    - df_detailï¼šæ˜ç´° + å€ç¢¼3 + å„²ä½é¡å‹
    - df_unknownï¼šæœªçŸ¥æ˜ç´°
    """
    df2 = df.copy()

    # ä¾†æºæ¬„ä½ï¼šå„ªå…ˆæ£šåˆ¥ï¼Œå…¶æ¬¡å€(æº«å±¤)
    src_col = None
    if "æ£šåˆ¥" in df2.columns:
        src_col = "æ£šåˆ¥"
    elif "å€(æº«å±¤)" in df2.columns:
        src_col = "å€(æº«å±¤)"
    else:
        raise KeyError("ç¼ºå°‘ã€æ£šåˆ¥ã€æˆ–ã€å€(æº«å±¤)ã€æ¬„ä½ï¼Œç„¡æ³•åšå„²ä½é¡å‹åˆ†é¡ã€‚")

    df2[src_col] = df2[src_col].astype(str).str.strip()
    df2["å€ç¢¼3"] = df2[src_col].apply(_to_zone3)
    df2["å„²ä½é¡å‹"] = df2["å€ç¢¼3"].apply(classify_storage_type)

    if "æœ‰æ•ˆè²¨ä½" not in df2.columns:
        df2["æœ‰æ•ˆè²¨ä½"] = 0
    if "å·²ä½¿ç”¨è²¨ä½" not in df2.columns:
        df2["å·²ä½¿ç”¨è²¨ä½"] = 0

    def _row(kind: str) -> dict:
        part = df2[df2["å„²ä½é¡å‹"] == kind]
        eff = float(_safe_sum(part["æœ‰æ•ˆè²¨ä½"]))
        used = float(_safe_sum(part["å·²ä½¿ç”¨è²¨ä½"]))
        unused = max(eff - used, 0.0)
        rate = (used / eff * 100.0) if eff else 0.0
        return {
            "å„²ä½é¡å‹": kind,
            "æœ‰æ•ˆè²¨ä½": int(round(eff)),
            "å·²ä½¿ç”¨è²¨ä½": int(round(used)),
            "æœªä½¿ç”¨è²¨ä½": int(round(unused)),
            "ä½¿ç”¨ç‡(%)": round(rate, 2),
        }

    rows = [
        _row("è¼•å‹æ–™æ¶"),
        _row("è½åœ°å„²"),
        _row("é‡å‹ä½ç©º"),
        _row("é«˜ç©ºå„²"),
    ]

    eff_total = float(_safe_sum(df2["æœ‰æ•ˆè²¨ä½"]))
    used_total = float(_safe_sum(df2["å·²ä½¿ç”¨è²¨ä½"]))
    unused_total = max(eff_total - used_total, 0.0)
    rate_total = (used_total / eff_total * 100.0) if eff_total else 0.0

    rows.append(
        {
            "å„²ä½é¡å‹": "ç¸½è¨ˆ",
            "æœ‰æ•ˆè²¨ä½": int(round(eff_total)),
            "å·²ä½¿ç”¨è²¨ä½": int(round(used_total)),
            "æœªä½¿ç”¨è²¨ä½": int(round(unused_total)),
            "ä½¿ç”¨ç‡(%)": round(rate_total, 2),
        }
    )

    df_util = pd.DataFrame(rows)

    df_unknown = df2[df2["å„²ä½é¡å‹"] == "æœªçŸ¥"].copy()
    return df_util, df2, df_unknown


def render_util_block(title: str, r: dict):
    st.markdown(f"### {title}")
    st.markdown(f"**æœ‰æ•ˆè²¨ä½ï¼š** {int(r.get('æœ‰æ•ˆè²¨ä½', 0)):,}")
    st.markdown(f"**å·²ä½¿ç”¨è²¨ä½ï¼š** {int(r.get('å·²ä½¿ç”¨è²¨ä½', 0)):,}")
    st.markdown(f"**æœªä½¿ç”¨è²¨ä½ï¼š** {int(r.get('æœªä½¿ç”¨è²¨ä½', 0)):,}")
    st.markdown(f"**ä½¿ç”¨ç‡(%)ï¼š** {float(r.get('ä½¿ç”¨ç‡(%)', 0)):.2f}")


# =========================
# åŒ¯å‡º Excel
# =========================
def build_output_excel_bytes(
    base_name: str,
    df_util: pd.DataFrame,
    df_detail: pd.DataFrame,
    df_shelf: pd.DataFrame,
    df_type: pd.DataFrame,
    df_unknown: pd.DataFrame,
) -> tuple[str, bytes]:
    out = io.BytesIO()
    with pd.ExcelWriter(out, engine="xlsxwriter") as writer:
        df_util.to_excel(writer, sheet_name="å„²ä½é¡å‹ä½¿ç”¨ç‡", index=False)
        df_detail.to_excel(writer, sheet_name="æ˜ç´°(å«å„²ä½é¡å‹)", index=False)
        df_shelf.to_excel(writer, sheet_name="æ£šåˆ¥çµ±è¨ˆ", index=False)
        df_type.to_excel(writer, sheet_name="å„²ä½é¡å‹çµ±è¨ˆ", index=False)
        df_unknown.to_excel(writer, sheet_name="æœªçŸ¥æ˜ç´°", index=False)
    out.seek(0)
    return f"{base_name}_4_å„²ä½ä½¿ç”¨ç‡_è¼¸å‡º.xlsx", out.getvalue()


# =========================
# Main
# =========================
def main():
    st.set_page_config(page_title="å„²ä½ä½¿ç”¨ç‡", page_icon="ğŸ§Š", layout="wide")

    if HAS_COMMON_UI:
        inject_logistics_theme()
        set_page("å„²ä½ä½¿ç”¨ç‡", icon="ğŸ§Š", subtitle="ä¾å€ç¢¼åˆ†é¡ï¼šè¼•å‹æ–™æ¶/è½åœ°å„²/é‡å‹ä½ç©º/é«˜ç©ºå„²ï¼ˆæ”¯æ´ xlsbï¼‰")
    else:
        st.title("ğŸ§Š å„²ä½ä½¿ç”¨ç‡")

    inject_compact_css()

    if HAS_COMMON_UI:
        card_open("ğŸ“¤ ä¸Šå‚³ Excelï¼ˆå„²ä½æ˜ç´°ï¼‰")
    uploaded = st.file_uploader(
        "è«‹ä¸Šå‚³æª”æ¡ˆï¼ˆxlsx/xls/xlsm/xlsb/csvï¼‰",
        type=["xlsx", "xls", "xlsm", "xlsb", "csv"],
        label_visibility="collapsed",
    )
    if HAS_COMMON_UI:
        card_close()

    if not uploaded:
        st.info("è«‹å…ˆä¸Šå‚³å„²ä½æ˜ç´°æª”æ¡ˆã€‚")
        return

    # è®€æª”
    try:
        df, sheet_used = robust_read_uploaded(uploaded)
    except Exception as e:
        st.error(f"è®€å–å¤±æ•—ï¼š{e}")
        return

    df.columns = df.columns.astype(str).str.strip()
    st.caption(f"ä½¿ç”¨åˆ†é ï¼š{sheet_used}")

    # è¨ˆç®—ï¼ˆå››é¡ + ç¸½è¨ˆï¼‰
    try:
        df_util, df_detail, df_unknown = calc_util_by_storage_type(df)
    except Exception as e:
        st.error(f"è¨ˆç®—å¤±æ•—ï¼š{e}")
        return

    util_rows = {r["å„²ä½é¡å‹"]: r for _, r in df_util.iterrows()}

    # -------------------------
    # ä¸Šæ–¹ï¼šå››é¡å¡ç‰‡ï¼ˆå…©åˆ—å…©æ¬„ï¼‰+ ç¸½è¨ˆ
    # -------------------------
    left, right = st.columns(2, gap="large")

    with left:
        if HAS_COMMON_UI:
            card_open("ğŸ“Œ å„²ä½é¡å‹ä½¿ç”¨ç‡ï¼ˆKPIï¼‰")

        r1c1, r1c2 = st.columns(2, gap="large")
        with r1c1:
            render_util_block("è¼•å‹æ–™æ¶", util_rows.get("è¼•å‹æ–™æ¶", {}))
        with r1c2:
            render_util_block("è½åœ°å„²", util_rows.get("è½åœ°å„²", {}))

        _spacer(6)

        r2c1, r2c2 = st.columns(2, gap="large")
        with r2c1:
            render_util_block("é‡å‹ä½ç©º", util_rows.get("é‡å‹ä½ç©º", {}))
        with r2c2:
            render_util_block("é«˜ç©ºå„²", util_rows.get("é«˜ç©ºå„²", {}))

        _spacer(6)
        render_util_block("ç¸½è¨ˆ", util_rows.get("ç¸½è¨ˆ", {}))

        if HAS_COMMON_UI:
            card_close()

    # -------------------------
    # å³æ¬„ï¼šçµ±è¨ˆè¡¨ + åŒ¯å‡º
    # -------------------------
    with right:
        if HAS_COMMON_UI:
            card_open("ğŸ“Š çµ±è¨ˆ")

        # å„²ä½é¡å‹çµ±è¨ˆï¼ˆç­†æ•¸ï¼‰
        df_type = (
            df_detail.groupby(["å„²ä½é¡å‹"], dropna=False)
            .size()
            .reset_index(name="ç­†æ•¸")
        )
        df_type["__ord"] = df_type["å„²ä½é¡å‹"].apply(lambda x: TYPE_ORDER.index(x) if x in TYPE_ORDER else 999)
        df_type = df_type.sort_values(["__ord", "å„²ä½é¡å‹"]).drop(columns="__ord")

        st.markdown("### å„²ä½é¡å‹çµ±è¨ˆï¼ˆç­†æ•¸ï¼‰")
        st.dataframe(df_type, use_container_width=True, hide_index=True, height=220)

        # æ£šåˆ¥çµ±è¨ˆ Top50ï¼ˆè‹¥æœ‰æ£šåˆ¥ï¼‰
        if "æ£šåˆ¥" in df_detail.columns:
            df_shelf = (
                df_detail.groupby(["æ£šåˆ¥"], dropna=False)
                .size()
                .reset_index(name="ç­†æ•¸")
                .sort_values(["ç­†æ•¸", "æ£šåˆ¥"], ascending=[False, True])
            )
        else:
            df_shelf = pd.DataFrame(columns=["æ£šåˆ¥", "ç­†æ•¸"])

        base = os.path.splitext(uploaded.name)[0]
        out_name, out_bytes = build_output_excel_bytes(
            base_name=base,
            df_util=df_util,
            df_detail=df_detail,
            df_shelf=df_shelf,
            df_type=df_type,
            df_unknown=df_unknown,
        )

        _spacer(8)
        st.download_button(
            "â¬‡ï¸ åŒ¯å‡ºï¼ˆå„²ä½ä½¿ç”¨ç‡ Excelï¼‰",
            data=out_bytes,
            file_name=out_name,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )

        if HAS_COMMON_UI:
            card_close()

    # -------------------------
    # ä¸‹æ–¹ï¼šæ£šåˆ¥çµ±è¨ˆ Top50ï¼ˆå…¨å¯¬ï¼‰
    # -------------------------
    if "æ£šåˆ¥" in df_detail.columns and not df_shelf.empty:
        _spacer(10)
        if HAS_COMMON_UI:
            card_open("ğŸ“‹ æ£šåˆ¥çµ±è¨ˆï¼ˆTop 50ï¼‰")
        st.dataframe(df_shelf.head(50), use_container_width=True, hide_index=True)
        if HAS_COMMON_UI:
            card_close()

    # -------------------------
    # ä¸‹æ–¹ï¼šæœªçŸ¥æ˜ç´°ï¼ˆå…¨å¯¬ï¼‰
    # -------------------------
    unknown_cnt = len(df_unknown)
    _spacer(8)
    with st.expander(f"ğŸ“Œ æœªçŸ¥æ˜ç´°ï¼ˆ{unknown_cnt:,} ç­†ï¼‰", expanded=False):
        if unknown_cnt == 0:
            st.success("æœªçŸ¥ï¼š0 ç­†")
        else:
            st.dataframe(df_unknown, use_container_width=True, hide_index=True)


if __name__ == "__main__":
    main()
